{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bienvenue Bienvenue sur mon r\u00e9f\u00e9rentiel de documentations et de m\u00e9mos professionnels. Ce site regroupe des fiches techniques, des guides pratiques et des notes personnelles sur des technologies, des outils DevOps, des concepts de d\u00e9veloppement, des bonnes pratiques et des retours d\u2019exp\u00e9rience. L\u2019objectif est de centraliser l\u2019information utile pour gagner du temps au quotidien et faciliter la mont\u00e9e en comp\u00e9tence. Organisation du site Backend : guides sur Go, Java, bonnes pratiques d\u2019API, conteneurisation, d\u00e9ploiement, etc. DevOps : outils d\u2019infrastructure (Terraform, AWS, Kubernetes), CI/CD, s\u00e9curit\u00e9, monitoring, packaging, etc. Data : m\u00e9mos SQL, gestion de bases de donn\u00e9es, requ\u00eates avanc\u00e9es. Front : frameworks, architectures CSS, outils modernes du web. Environnement de travail : configuration d\u2019\u00e9diteurs, terminaux, outils de productivit\u00e9. Techniques de travail : m\u00e9thodes d\u2019organisation, gestion du temps, r\u00e9solution de probl\u00e8mes. Utilisation Utilisez la barre de recherche ou le sommaire pour naviguer rapidement. Les exemples sont pens\u00e9s pour \u00eatre copi\u00e9s/coll\u00e9s et adapt\u00e9s \u00e0 vos besoins. Les documentations sont r\u00e9guli\u00e8rement mises \u00e0 jour selon mes d\u00e9couvertes et retours d\u2019exp\u00e9rience. Contribuer ou corriger Dans chaque section, vous trouverez des liens pour contribuer ou corriger les fiches. Que ce soit pour ajouter une nouvelle ressource, corriger une erreur ou proposer une am\u00e9lioration, votre aide est la bienvenue. Vos retours sont pr\u00e9cieux pour am\u00e9liorer la qualit\u00e9 de ce r\u00e9f\u00e9rentiel. Si vous rep\u00e9rez une erreur, souhaitez sugg\u00e9rer une am\u00e9lioration ou partager une ressource, n\u2019h\u00e9sitez pas \u00e0 me contacter. Vous pouvez me joindre par mail : hello@arthurrichard.fr","title":"Accueil"},{"location":"#bienvenue","text":"Bienvenue sur mon r\u00e9f\u00e9rentiel de documentations et de m\u00e9mos professionnels. Ce site regroupe des fiches techniques, des guides pratiques et des notes personnelles sur des technologies, des outils DevOps, des concepts de d\u00e9veloppement, des bonnes pratiques et des retours d\u2019exp\u00e9rience. L\u2019objectif est de centraliser l\u2019information utile pour gagner du temps au quotidien et faciliter la mont\u00e9e en comp\u00e9tence.","title":"Bienvenue"},{"location":"#organisation-du-site","text":"Backend : guides sur Go, Java, bonnes pratiques d\u2019API, conteneurisation, d\u00e9ploiement, etc. DevOps : outils d\u2019infrastructure (Terraform, AWS, Kubernetes), CI/CD, s\u00e9curit\u00e9, monitoring, packaging, etc. Data : m\u00e9mos SQL, gestion de bases de donn\u00e9es, requ\u00eates avanc\u00e9es. Front : frameworks, architectures CSS, outils modernes du web. Environnement de travail : configuration d\u2019\u00e9diteurs, terminaux, outils de productivit\u00e9. Techniques de travail : m\u00e9thodes d\u2019organisation, gestion du temps, r\u00e9solution de probl\u00e8mes.","title":"Organisation du site"},{"location":"#utilisation","text":"Utilisez la barre de recherche ou le sommaire pour naviguer rapidement. Les exemples sont pens\u00e9s pour \u00eatre copi\u00e9s/coll\u00e9s et adapt\u00e9s \u00e0 vos besoins. Les documentations sont r\u00e9guli\u00e8rement mises \u00e0 jour selon mes d\u00e9couvertes et retours d\u2019exp\u00e9rience.","title":"Utilisation"},{"location":"#contribuer-ou-corriger","text":"Dans chaque section, vous trouverez des liens pour contribuer ou corriger les fiches. Que ce soit pour ajouter une nouvelle ressource, corriger une erreur ou proposer une am\u00e9lioration, votre aide est la bienvenue. Vos retours sont pr\u00e9cieux pour am\u00e9liorer la qualit\u00e9 de ce r\u00e9f\u00e9rentiel. Si vous rep\u00e9rez une erreur, souhaitez sugg\u00e9rer une am\u00e9lioration ou partager une ressource, n\u2019h\u00e9sitez pas \u00e0 me contacter. Vous pouvez me joindre par mail : hello@arthurrichard.fr","title":"Contribuer ou corriger"},{"location":"DevOps/apm/","text":"Mise en place d'une stack de monitoring ELK Introduction La stack ELK (Elasticsearch, Logstash, Kibana) permet de centraliser, visualiser et analyser les logs et m\u00e9triques d\u2019applications, particuli\u00e8rement utile dans un environnement Kubernetes o\u00f9 les logs sont \u00e9ph\u00e9m\u00e8res et distribu\u00e9s. Elasticsearch Elasticsearch est le moteur de recherche et d\u2019indexation. Dans Kubernetes, il est recommand\u00e9 de le d\u00e9ployer via l\u2019 Elastic Operator : apiVersion: elasticsearch.k8s.elastic.co/v1 kind: Elasticsearch metadata: name: elk-cluster spec: version: 8.13.0 nodeSets: - name: default count: 3 config: node.store.allow_mmap: false Utilisez des volumes persistants pour la durabilit\u00e9 des donn\u00e9es. S\u00e9curisez l\u2019acc\u00e8s avec des secrets et des NetworkPolicies. Kibana Kibana permet de visualiser les donn\u00e9es stock\u00e9es dans Elasticsearch. D\u00e9ploiement via Operator : apiVersion: kibana.k8s.elastic.co/v1 kind: Kibana metadata: name: kibana spec: version: 8.13.0 count: 1 elasticsearchRef: name: elk-cluster Alertes & notifications Configurez les alertes dans Kibana (Stack Management > Rules and Connectors). Exemple : alerte sur le nombre d\u2019erreurs applicatives : Cr\u00e9ez une r\u00e8gle de type \"Log threshold\" sur le champ log.level: error . Ajoutez un connecteur (email, Slack, webhook). Dashboards Utilisez les dashboards pr\u00e9d\u00e9finis de Filebeat/Metricbeat ou cr\u00e9ez les v\u00f4tres. Exemple : dashboard de suivi des erreurs HTTP 5xx, latence des requ\u00eates, etc. Logstash Logstash permet de transformer et router les logs. Dans Kubernetes, il peut \u00eatre utilis\u00e9 pour enrichir les logs avant ingestion dans Elasticsearch. Exemple de pipeline : input { beats { port => 5044 } } filter { grok { match => { \"message\" => \"%{COMBINEDAPACHELOG}\" } } } output { elasticsearch { hosts => [\"http://elasticsearch:9200\"] } } Metricbeat Metricbeat collecte les m\u00e9triques syst\u00e8me et applicatives. D\u00e9ploiement en DaemonSet : apiVersion: apps/v1 kind: DaemonSet metadata: name: metricbeat spec: selector: matchLabels: app: metricbeat template: metadata: labels: app: metricbeat spec: containers: - name: metricbeat image: docker.elastic.co/beats/metricbeat:8.13.0 env: - name: ELASTICSEARCH_HOSTS value: \"http://elasticsearch:9200\" volumeMounts: - name: proc mountPath: /hostfs/proc readOnly: true - name: sys mountPath: /hostfs/sys readOnly: true volumes: - name: proc hostPath: path: /proc - name: sys hostPath: path: /sys Metricbeat peut \u00eatre configur\u00e9 pour monitorer les pods, nodes, et services Kubernetes. Filebeat Filebeat collecte et exp\u00e9die les logs des pods vers Logstash ou Elasticsearch. D\u00e9ploiement en DaemonSet : apiVersion: apps/v1 kind: DaemonSet metadata: name: filebeat spec: selector: matchLabels: app: filebeat template: metadata: labels: app: filebeat spec: containers: - name: filebeat image: docker.elastic.co/beats/filebeat:8.13.0 env: - name: ELASTICSEARCH_HOSTS value: \"http://elasticsearch:9200\" volumeMounts: - name: varlog mountPath: /var/log readOnly: true volumes: - name: varlog hostPath: path: /var/log Filebeat peut parser les logs Kubernetes (stdout/stderr des pods). APM Elastic APM permet de tracer les transactions, requ\u00eates et erreurs applicatives. D\u00e9ployez l\u2019APM Server dans le cluster : apiVersion: apm.k8s.elastic.co/v1 kind: ApmServer metadata: name: apm-server spec: version: 8.13.0 count: 1 elasticsearchRef: name: elk-cluster kibanaRef: name: kibana Int\u00e9grez l\u2019agent APM dans votre application (Java, Python, Node.js, etc) : Ajoutez les variables d\u2019environnement pour pointer vers l\u2019APM Server. Exemple (Java) : -Delastic.apm.server_urls=http://apm-server:8200 -Delastic.apm.service_name=mon-app Visualisez les traces et transactions dans Kibana (menu APM). Universal profiling Universal Profiling (Elastic) permet de profiler le code natif et les performances CPU de toutes les applications du cluster, sans instrumentation. D\u00e9ployez l\u2019agent Universal Profiling via DaemonSet (voir doc officielle ). Visualisez les flamegraphs et les hotspots dans Kibana. Bonnes pratiques Utilisez des namespaces d\u00e9di\u00e9s pour la stack ELK. Prot\u00e9gez l\u2019acc\u00e8s \u00e0 Kibana et Elasticsearch (authentification, RBAC, NetworkPolicy). Surveillez la volum\u00e9trie des logs pour \u00e9viter la saturation du cluster. Automatisez le d\u00e9ploiement avec Helm ou l\u2019Elastic Operator. Ressources utiles Elastic Cloud on Kubernetes (ECK) Elastic APM sur Kubernetes Dashboards Kibana","title":"APM & ELK"},{"location":"DevOps/apm/#mise-en-place-dune-stack-de-monitoring-elk","text":"","title":"Mise en place d'une stack de monitoring ELK"},{"location":"DevOps/apm/#introduction","text":"La stack ELK (Elasticsearch, Logstash, Kibana) permet de centraliser, visualiser et analyser les logs et m\u00e9triques d\u2019applications, particuli\u00e8rement utile dans un environnement Kubernetes o\u00f9 les logs sont \u00e9ph\u00e9m\u00e8res et distribu\u00e9s.","title":"Introduction"},{"location":"DevOps/apm/#elasticsearch","text":"Elasticsearch est le moteur de recherche et d\u2019indexation. Dans Kubernetes, il est recommand\u00e9 de le d\u00e9ployer via l\u2019 Elastic Operator : apiVersion: elasticsearch.k8s.elastic.co/v1 kind: Elasticsearch metadata: name: elk-cluster spec: version: 8.13.0 nodeSets: - name: default count: 3 config: node.store.allow_mmap: false Utilisez des volumes persistants pour la durabilit\u00e9 des donn\u00e9es. S\u00e9curisez l\u2019acc\u00e8s avec des secrets et des NetworkPolicies.","title":"Elasticsearch"},{"location":"DevOps/apm/#kibana","text":"Kibana permet de visualiser les donn\u00e9es stock\u00e9es dans Elasticsearch. D\u00e9ploiement via Operator : apiVersion: kibana.k8s.elastic.co/v1 kind: Kibana metadata: name: kibana spec: version: 8.13.0 count: 1 elasticsearchRef: name: elk-cluster","title":"Kibana"},{"location":"DevOps/apm/#alertes-notifications","text":"Configurez les alertes dans Kibana (Stack Management > Rules and Connectors). Exemple : alerte sur le nombre d\u2019erreurs applicatives : Cr\u00e9ez une r\u00e8gle de type \"Log threshold\" sur le champ log.level: error . Ajoutez un connecteur (email, Slack, webhook).","title":"Alertes &amp; notifications"},{"location":"DevOps/apm/#dashboards","text":"Utilisez les dashboards pr\u00e9d\u00e9finis de Filebeat/Metricbeat ou cr\u00e9ez les v\u00f4tres. Exemple : dashboard de suivi des erreurs HTTP 5xx, latence des requ\u00eates, etc.","title":"Dashboards"},{"location":"DevOps/apm/#logstash","text":"Logstash permet de transformer et router les logs. Dans Kubernetes, il peut \u00eatre utilis\u00e9 pour enrichir les logs avant ingestion dans Elasticsearch. Exemple de pipeline : input { beats { port => 5044 } } filter { grok { match => { \"message\" => \"%{COMBINEDAPACHELOG}\" } } } output { elasticsearch { hosts => [\"http://elasticsearch:9200\"] } }","title":"Logstash"},{"location":"DevOps/apm/#metricbeat","text":"Metricbeat collecte les m\u00e9triques syst\u00e8me et applicatives. D\u00e9ploiement en DaemonSet : apiVersion: apps/v1 kind: DaemonSet metadata: name: metricbeat spec: selector: matchLabels: app: metricbeat template: metadata: labels: app: metricbeat spec: containers: - name: metricbeat image: docker.elastic.co/beats/metricbeat:8.13.0 env: - name: ELASTICSEARCH_HOSTS value: \"http://elasticsearch:9200\" volumeMounts: - name: proc mountPath: /hostfs/proc readOnly: true - name: sys mountPath: /hostfs/sys readOnly: true volumes: - name: proc hostPath: path: /proc - name: sys hostPath: path: /sys Metricbeat peut \u00eatre configur\u00e9 pour monitorer les pods, nodes, et services Kubernetes.","title":"Metricbeat"},{"location":"DevOps/apm/#filebeat","text":"Filebeat collecte et exp\u00e9die les logs des pods vers Logstash ou Elasticsearch. D\u00e9ploiement en DaemonSet : apiVersion: apps/v1 kind: DaemonSet metadata: name: filebeat spec: selector: matchLabels: app: filebeat template: metadata: labels: app: filebeat spec: containers: - name: filebeat image: docker.elastic.co/beats/filebeat:8.13.0 env: - name: ELASTICSEARCH_HOSTS value: \"http://elasticsearch:9200\" volumeMounts: - name: varlog mountPath: /var/log readOnly: true volumes: - name: varlog hostPath: path: /var/log Filebeat peut parser les logs Kubernetes (stdout/stderr des pods).","title":"Filebeat"},{"location":"DevOps/apm/#apm","text":"Elastic APM permet de tracer les transactions, requ\u00eates et erreurs applicatives. D\u00e9ployez l\u2019APM Server dans le cluster : apiVersion: apm.k8s.elastic.co/v1 kind: ApmServer metadata: name: apm-server spec: version: 8.13.0 count: 1 elasticsearchRef: name: elk-cluster kibanaRef: name: kibana Int\u00e9grez l\u2019agent APM dans votre application (Java, Python, Node.js, etc) : Ajoutez les variables d\u2019environnement pour pointer vers l\u2019APM Server. Exemple (Java) : -Delastic.apm.server_urls=http://apm-server:8200 -Delastic.apm.service_name=mon-app Visualisez les traces et transactions dans Kibana (menu APM).","title":"APM"},{"location":"DevOps/apm/#universal-profiling","text":"Universal Profiling (Elastic) permet de profiler le code natif et les performances CPU de toutes les applications du cluster, sans instrumentation. D\u00e9ployez l\u2019agent Universal Profiling via DaemonSet (voir doc officielle ). Visualisez les flamegraphs et les hotspots dans Kibana.","title":"Universal profiling"},{"location":"DevOps/apm/#bonnes-pratiques","text":"Utilisez des namespaces d\u00e9di\u00e9s pour la stack ELK. Prot\u00e9gez l\u2019acc\u00e8s \u00e0 Kibana et Elasticsearch (authentification, RBAC, NetworkPolicy). Surveillez la volum\u00e9trie des logs pour \u00e9viter la saturation du cluster. Automatisez le d\u00e9ploiement avec Helm ou l\u2019Elastic Operator.","title":"Bonnes pratiques"},{"location":"DevOps/apm/#ressources-utiles","text":"Elastic Cloud on Kubernetes (ECK) Elastic APM sur Kubernetes Dashboards Kibana","title":"Ressources utiles"},{"location":"DevOps/aws/","text":"AWS AWS est une plateforme regroupant de nombreux services d'h\u00e9bergement (CPU, Base de donn\u00e9es, Fichiers statiques). C'est une IaaS (Infrastructure as a Service). Avantages Agilit\u00e9, augmente l'agilit\u00e9 de l'entreprise Mod\u00e8le de paiement \u00e0 l'utilisation, echange de l'argent contre du CPU Facilite l'agrandissement d'une infrastructure IT d'une entreprise Permet d'\u00eatre atteignable depuis le monde entier en quelques minutes S\u00e9curit\u00e9, \u00e0 travers le mod\u00e8le de responsabilit\u00e9 partag\u00e9 R\u00e9silience et disponible, performe comme promis par AWS Elasticit\u00e9, permet d'ajouter ou de supprimer rapidement des ressources automatiquement Mode d'acc\u00e8s Chaque mode d'acc\u00e8s d\u00e9pend de l'utilisation. Le site est excellent pour prendre en main les services AWS et configurer les budgets comme il le faut. L'interface en ligne de commande, permet de gagner du temps en faisant abstraction de la terrible navigation du site. C'est utile si nous voulons aller droit au but. C'est en g\u00e9n\u00e9ral utilis\u00e9 pour automatiser des actions/d\u00e9ploiement r\u00e9p\u00e9titifs. Cependant, cela demande de la configuration en amont et il faut faire attention o\u00f9 nous persistons notre configuration AWS sur notre machine locale. Le SDK pr\u00e9sente les m\u00eames avantages & inconv\u00e9nients que le CLI. Il en va de m\u00eame pour l'utilisation avec Terraform. CLI Pour int\u00e9ragir avec AWS depuis le terminal. Il faut r\u00e9cup\u00e9rer un cl\u00e9 d'acc\u00e8s depuis notre session connect\u00e9e sur le site. Il faut cliquer sur notre compte en haut \u00e0 droite et aller dans Informations d'identification de s\u00e9curit\u00e9 ou dans le service IAM . Ensuite, il vous reste plus qu'\u00e0 installer le CLI $ curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip sudo ./aws/install Si vous l'avez d\u00e9j\u00e0 sur votre machine locale mais que le client n'est pas \u00e0 jour, vous pouvez le mettre \u00e0 jour comme ceci $ sudo ./aws/install --bin-dir /usr/local/bin --install-dir /usr/local/aws-cli --update Puis, v\u00e9rifiez que le client est bien install\u00e9 et trouvable dans le terminal $ aws --version Enfin, on configure avec la cl\u00e9 d'acc\u00e8s g\u00e9n\u00e9r\u00e9e. $ aws configure Si vous rencontrez des soucis de configuration et qui vous avez un besoin urgent d'utiliser le CLI, vous pouvez regarder le service CloudShell qui pr\u00e9-configur\u00e9 et poss\u00e8de m\u00eame des langages de programmation install\u00e9. Si vous avez besoin d'informations plus pouss\u00e9s concernant le CLI d'AWS, je vous encourage \u00e0 aller visiter la documentation d\u00e9crivant chaque commande et sous-commande ici . Il existe une autocompl\u00e9tion possible dans votre terminal, la configuration est expliqu\u00e9e ici . Terraform Terraform permet de d\u00e9crire et provisionner des ressources AWS de fa\u00e7on d\u00e9clarative. Exemple de cr\u00e9ation d'un bucket S3 : provider \"aws\" { region = \"eu-west-1\" } resource \"aws_s3_bucket\" \"bucket\" { bucket = \"mon-bucket-exemple\" } Initialisez et appliquez : terraform init terraform apply IAM IAM (Identity and Access Management) permet de g\u00e9rer les utilisateurs, groupes, r\u00f4les et permissions. Cr\u00e9ez des utilisateurs avec des permissions minimales. Utilisez des groupes pour g\u00e9rer les droits par \u00e9quipe. Privil\u00e9giez les r\u00f4les IAM pour les applications et services (ex : EC2, Lambda). Exemple de cr\u00e9ation d\u2019un utilisateur via CLI : aws iam create-user --user-name dev-user aws iam attach-user-policy --user-name dev-user --policy-arn arn:aws:iam::aws:policy/ReadOnlyAccess S3 S3 est un serveur de fichiers qui permet de stocker \u00e0 distance des fichiers plats. On peut copier, d\u00e9placer et supprimer de mani\u00e8re bidirectionnel. Il est tr\u00e8s souvent utilis\u00e9 pour stocker des fichiers m\u00e9dia en tout genre ou des configurations. $ aws s3api create-bucket --bucket arichard --region us-east-1 # (1) { \"Location\": \"/arichard\" } $ aws s3 cp mkdocs.yml s3://arichard/mkdocs.yml # (2) upload: ./mkdocs.yml to s3://arichard/mkdocs.yml $ aws s3 cp s3://arichard/mkdocs.yml mkdocs2.yml # (3) download: s3://arichard/mkdocs.yml to ./mkdocs2.yml $ rm mkdocs2.yml && aws s3 rm s3://arichard/mkdocs.yml # (4) delete: s3://arichard/mkdocs.yml $ aws s3api delete-bucket --bucket arichard # (5) On cr\u00e9er un bucket S3 en lui fournissant le nom. Il n'y que la r\u00e9gion us-east-1 qui supporte les buckets s3 pour le moment. On copie un fichier local vers le S3 en lui fournissant le chemin cible. On t\u00e9l\u00e9charge un fichier sur le S3 avec son chemin et l'endroit o\u00f9 nous voulons le persister sur la machine locale. On supprime le fichier local t\u00e9l\u00e9charg\u00e9 et le fichier distant. On supprime le S3 en lui fournissant le nom. EC2 EC2 est un service de cr\u00e9ation de machine virtuelle en cloud (Elastic Compute Cloud). Cr\u00e9er une instance aws ec2 run-instances --image-id ami-0abcdef1234567890 --count 1 --instance-type t2.micro --key-name my-key --security-group-ids sg-0123456789abcdef0 --subnet-id subnet-6e7f829e Afficher les m\u00e9ta-donn\u00e9es des instances aws ec2 describe-instances Modifier une instance d\u00e9j\u00e0 cr\u00e9\u00e9e Exemple : changer le type d\u2019instance : aws ec2 stop-instances --instance-ids i-1234567890abcdef0 aws ec2 modify-instance-attribute --instance-id i-1234567890abcdef0 --instance-type \"t2.small\" aws ec2 start-instances --instance-ids i-1234567890abcdef0 Faire communiquer deux instances entre-elles Placez-les dans le m\u00eame VPC et le m\u00eame groupe de s\u00e9curit\u00e9. Ouvrez les ports n\u00e9cessaires dans le Security Group. Nettoyer les ressources aws ec2 terminate-instances --instance-ids i-1234567890abcdef0 Scaling AWS propose deux mani\u00e8res du supporter la charge entrante. Il y a : Auto scaling groups, ELB (Elastic Load Balancer) Auto scaling groups Un groupe \u00e9chelonne horizontalement les ressources en fonction d'un crit\u00e8re donn\u00e9 (exemple: cr\u00e9er une nouvelle instance si le CPU d\u00e9passe 80% d'utilisation). Un groupe permet de d\u00e9finir un nombre minimum, d\u00e9sir\u00e9 et maximum d'instances r\u00e9pliqu\u00e9es. EJB Un EJB absorbe la charge la r\u00e9partissant afin d'obtenir la plus faible latence. Il existe deux types de load balancer: applicatif et r\u00e9seau. l'EJB applicatif sert \u00e0 r\u00e9partir le traffic sur plusieurs EC2 tandis que l'EJB R\u00e9seau absorbe en amont le traffic r\u00e9seau. TODO EBS EBS (Elastic Block Store) fournit des volumes de stockage persistant pour EC2. Cr\u00e9ez un volume : aws ec2 create-volume --availability-zone eu-west-1a --size 10 --volume-type gp2 Attachez-le \u00e0 une instance : aws ec2 attach-volume --volume-id vol-1234567890abcdef0 --instance-id i-1234567890abcdef0 --device /dev/xvdf RDS RDS (Relational Database Service) permet de d\u00e9ployer des bases de donn\u00e9es manag\u00e9es (MySQL, PostgreSQL, etc). Cr\u00e9ez une instance : aws rds create-db-instance --db-instance-identifier mydb --db-instance-class db.t3.micro --engine postgres --master-username admin --master-user-password password --allocated-storage 20 Supprimez une instance : aws rds delete-db-instance --db-instance-identifier mydb --skip-final-snapshot DynamoDB DynamoDB est une base NoSQL manag\u00e9e, scalable et performante. Cr\u00e9ez une table : aws dynamodb create-table --table-name MaTable --attribute-definitions AttributeName=Id,AttributeType=S --key-schema AttributeName=Id,KeyType=HASH --provisioned-throughput ReadCapacityUnits=1,WriteCapacityUnits=1 Lambda Lambda permet d\u2019ex\u00e9cuter du code sans g\u00e9rer de serveur (serverless). D\u00e9ployer une Lambda sous forme de conteneur Docker Construisez l\u2019image Docker avec votre code et un Dockerfile compatible Lambda. Publiez l\u2019image sur ECR. Cr\u00e9ez la fonction Lambda en sp\u00e9cifiant l\u2019URL de l\u2019image. Param\u00e9trer les autorisations de la fonction Attribuez un r\u00f4le IAM \u00e0 la Lambda pour acc\u00e9der \u00e0 d\u2019autres services (S3, DynamoDB, etc). Nettoyer les ressources aws lambda delete-function --function-name ma-fonction SQS & SNS SQS (Simple Queue Service) : file d\u2019attente pour la communication asynchrone. SNS (Simple Notification Service) : notifications push/pub-sub. Exemple : cr\u00e9er une file SQS aws sqs create-queue --queue-name MaFile CloudWatch CloudWatch permet la collecte de logs, la cr\u00e9ation d\u2019alarmes et le monitoring des ressources. Cr\u00e9er un groupe de log aws logs create-log-group --log-group-name MonGroupe Cr\u00e9er ses propres KPI Utilisez les m\u00e9triques personnalis\u00e9es : aws cloudwatch put-metric-data --metric-name MaMetrice --namespace MonApp --value 42 Cr\u00e9er des alarmes aws cloudwatch put-metric-alarm --alarm-name CPUHigh --metric-name CPUUtilization --namespace AWS/EC2 --statistic Average --period 300 --threshold 80 --comparison-operator GreaterThanThreshold --dimension Name=InstanceId,Value=i-1234567890abcdef0 --evaluation-periods 2 --alarm-actions arn:aws:sns:... --unit Percent Mettre en place un workflow de monitoring Utilisez CloudWatch Events pour d\u00e9clencher des actions (ex : Lambda) sur alarme. Nettoyer les ressources aws logs delete-log-group --log-group-name MonGroupe API Gateway API Gateway permet d\u2019exposer des APIs REST ou WebSocket manag\u00e9es, avec int\u00e9gration Lambda, authentification, throttling, etc. Cr\u00e9ez une API : aws apigateway create-rest-api --name \"MonAPI\" ECR ECR (Elastic Container Registry) est un registre Docker manag\u00e9. Cr\u00e9ez un repo : aws ecr create-repository --repository-name mon-repo Pushez une image : aws ecr get-login-password | docker login --username AWS --password-stdin <account-id>.dkr.ecr.<region>.amazonaws.com docker tag mon-image:latest <account-id>.dkr.ecr.<region>.amazonaws.com/mon-repo:latest docker push <account-id>.dkr.ecr.<region>.amazonaws.com/mon-repo:latest Kubernetes AWS propose EKS (Elastic Kubernetes Service) pour d\u00e9ployer des clusters Kubernetes manag\u00e9s. Cr\u00e9ez un cluster avec l\u2019outil eksctl : eksctl create cluster --name mon-cluster --region eu-west-1 --nodes 2 D\u00e9ployez vos applications comme sur n\u2019importe quel cluster Kubernetes. Bonnes pratiques Utilisez IAM pour contr\u00f4ler finement les acc\u00e8s. Activez la MFA sur les comptes sensibles. Surveillez vos co\u00fbts avec AWS Budgets. Automatisez vos d\u00e9ploiements avec CI/CD (CodePipeline, GitHub Actions, GitLab CI). Nettoyez r\u00e9guli\u00e8rement les ressources inutilis\u00e9es. Ressources utiles Documentation AWS AWS CLI Reference AWS Well-Architected Framework AWS Free Tier","title":"AWS"},{"location":"DevOps/aws/#aws","text":"AWS est une plateforme regroupant de nombreux services d'h\u00e9bergement (CPU, Base de donn\u00e9es, Fichiers statiques). C'est une IaaS (Infrastructure as a Service).","title":"AWS"},{"location":"DevOps/aws/#avantages","text":"Agilit\u00e9, augmente l'agilit\u00e9 de l'entreprise Mod\u00e8le de paiement \u00e0 l'utilisation, echange de l'argent contre du CPU Facilite l'agrandissement d'une infrastructure IT d'une entreprise Permet d'\u00eatre atteignable depuis le monde entier en quelques minutes S\u00e9curit\u00e9, \u00e0 travers le mod\u00e8le de responsabilit\u00e9 partag\u00e9 R\u00e9silience et disponible, performe comme promis par AWS Elasticit\u00e9, permet d'ajouter ou de supprimer rapidement des ressources automatiquement","title":"Avantages"},{"location":"DevOps/aws/#mode-dacces","text":"Chaque mode d'acc\u00e8s d\u00e9pend de l'utilisation. Le site est excellent pour prendre en main les services AWS et configurer les budgets comme il le faut. L'interface en ligne de commande, permet de gagner du temps en faisant abstraction de la terrible navigation du site. C'est utile si nous voulons aller droit au but. C'est en g\u00e9n\u00e9ral utilis\u00e9 pour automatiser des actions/d\u00e9ploiement r\u00e9p\u00e9titifs. Cependant, cela demande de la configuration en amont et il faut faire attention o\u00f9 nous persistons notre configuration AWS sur notre machine locale. Le SDK pr\u00e9sente les m\u00eames avantages & inconv\u00e9nients que le CLI. Il en va de m\u00eame pour l'utilisation avec Terraform.","title":"Mode d'acc\u00e8s"},{"location":"DevOps/aws/#cli","text":"Pour int\u00e9ragir avec AWS depuis le terminal. Il faut r\u00e9cup\u00e9rer un cl\u00e9 d'acc\u00e8s depuis notre session connect\u00e9e sur le site. Il faut cliquer sur notre compte en haut \u00e0 droite et aller dans Informations d'identification de s\u00e9curit\u00e9 ou dans le service IAM . Ensuite, il vous reste plus qu'\u00e0 installer le CLI $ curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip sudo ./aws/install Si vous l'avez d\u00e9j\u00e0 sur votre machine locale mais que le client n'est pas \u00e0 jour, vous pouvez le mettre \u00e0 jour comme ceci $ sudo ./aws/install --bin-dir /usr/local/bin --install-dir /usr/local/aws-cli --update Puis, v\u00e9rifiez que le client est bien install\u00e9 et trouvable dans le terminal $ aws --version Enfin, on configure avec la cl\u00e9 d'acc\u00e8s g\u00e9n\u00e9r\u00e9e. $ aws configure Si vous rencontrez des soucis de configuration et qui vous avez un besoin urgent d'utiliser le CLI, vous pouvez regarder le service CloudShell qui pr\u00e9-configur\u00e9 et poss\u00e8de m\u00eame des langages de programmation install\u00e9. Si vous avez besoin d'informations plus pouss\u00e9s concernant le CLI d'AWS, je vous encourage \u00e0 aller visiter la documentation d\u00e9crivant chaque commande et sous-commande ici . Il existe une autocompl\u00e9tion possible dans votre terminal, la configuration est expliqu\u00e9e ici .","title":"CLI"},{"location":"DevOps/aws/#terraform","text":"Terraform permet de d\u00e9crire et provisionner des ressources AWS de fa\u00e7on d\u00e9clarative. Exemple de cr\u00e9ation d'un bucket S3 : provider \"aws\" { region = \"eu-west-1\" } resource \"aws_s3_bucket\" \"bucket\" { bucket = \"mon-bucket-exemple\" } Initialisez et appliquez : terraform init terraform apply","title":"Terraform"},{"location":"DevOps/aws/#iam","text":"IAM (Identity and Access Management) permet de g\u00e9rer les utilisateurs, groupes, r\u00f4les et permissions. Cr\u00e9ez des utilisateurs avec des permissions minimales. Utilisez des groupes pour g\u00e9rer les droits par \u00e9quipe. Privil\u00e9giez les r\u00f4les IAM pour les applications et services (ex : EC2, Lambda). Exemple de cr\u00e9ation d\u2019un utilisateur via CLI : aws iam create-user --user-name dev-user aws iam attach-user-policy --user-name dev-user --policy-arn arn:aws:iam::aws:policy/ReadOnlyAccess","title":"IAM"},{"location":"DevOps/aws/#s3","text":"S3 est un serveur de fichiers qui permet de stocker \u00e0 distance des fichiers plats. On peut copier, d\u00e9placer et supprimer de mani\u00e8re bidirectionnel. Il est tr\u00e8s souvent utilis\u00e9 pour stocker des fichiers m\u00e9dia en tout genre ou des configurations. $ aws s3api create-bucket --bucket arichard --region us-east-1 # (1) { \"Location\": \"/arichard\" } $ aws s3 cp mkdocs.yml s3://arichard/mkdocs.yml # (2) upload: ./mkdocs.yml to s3://arichard/mkdocs.yml $ aws s3 cp s3://arichard/mkdocs.yml mkdocs2.yml # (3) download: s3://arichard/mkdocs.yml to ./mkdocs2.yml $ rm mkdocs2.yml && aws s3 rm s3://arichard/mkdocs.yml # (4) delete: s3://arichard/mkdocs.yml $ aws s3api delete-bucket --bucket arichard # (5) On cr\u00e9er un bucket S3 en lui fournissant le nom. Il n'y que la r\u00e9gion us-east-1 qui supporte les buckets s3 pour le moment. On copie un fichier local vers le S3 en lui fournissant le chemin cible. On t\u00e9l\u00e9charge un fichier sur le S3 avec son chemin et l'endroit o\u00f9 nous voulons le persister sur la machine locale. On supprime le fichier local t\u00e9l\u00e9charg\u00e9 et le fichier distant. On supprime le S3 en lui fournissant le nom.","title":"S3"},{"location":"DevOps/aws/#ec2","text":"EC2 est un service de cr\u00e9ation de machine virtuelle en cloud (Elastic Compute Cloud).","title":"EC2"},{"location":"DevOps/aws/#creer-une-instance","text":"aws ec2 run-instances --image-id ami-0abcdef1234567890 --count 1 --instance-type t2.micro --key-name my-key --security-group-ids sg-0123456789abcdef0 --subnet-id subnet-6e7f829e","title":"Cr\u00e9er une instance"},{"location":"DevOps/aws/#afficher-les-meta-donnees-des-instances","text":"aws ec2 describe-instances","title":"Afficher les m\u00e9ta-donn\u00e9es des instances"},{"location":"DevOps/aws/#modifier-une-instance-deja-creee","text":"Exemple : changer le type d\u2019instance : aws ec2 stop-instances --instance-ids i-1234567890abcdef0 aws ec2 modify-instance-attribute --instance-id i-1234567890abcdef0 --instance-type \"t2.small\" aws ec2 start-instances --instance-ids i-1234567890abcdef0","title":"Modifier une instance d\u00e9j\u00e0 cr\u00e9\u00e9e"},{"location":"DevOps/aws/#faire-communiquer-deux-instances-entre-elles","text":"Placez-les dans le m\u00eame VPC et le m\u00eame groupe de s\u00e9curit\u00e9. Ouvrez les ports n\u00e9cessaires dans le Security Group.","title":"Faire communiquer deux instances entre-elles"},{"location":"DevOps/aws/#nettoyer-les-ressources","text":"aws ec2 terminate-instances --instance-ids i-1234567890abcdef0","title":"Nettoyer les ressources"},{"location":"DevOps/aws/#scaling","text":"AWS propose deux mani\u00e8res du supporter la charge entrante. Il y a : Auto scaling groups, ELB (Elastic Load Balancer)","title":"Scaling"},{"location":"DevOps/aws/#auto-scaling-groups","text":"Un groupe \u00e9chelonne horizontalement les ressources en fonction d'un crit\u00e8re donn\u00e9 (exemple: cr\u00e9er une nouvelle instance si le CPU d\u00e9passe 80% d'utilisation). Un groupe permet de d\u00e9finir un nombre minimum, d\u00e9sir\u00e9 et maximum d'instances r\u00e9pliqu\u00e9es.","title":"Auto scaling groups"},{"location":"DevOps/aws/#ejb","text":"Un EJB absorbe la charge la r\u00e9partissant afin d'obtenir la plus faible latence. Il existe deux types de load balancer: applicatif et r\u00e9seau. l'EJB applicatif sert \u00e0 r\u00e9partir le traffic sur plusieurs EC2 tandis que l'EJB R\u00e9seau absorbe en amont le traffic r\u00e9seau. TODO","title":"EJB"},{"location":"DevOps/aws/#ebs","text":"EBS (Elastic Block Store) fournit des volumes de stockage persistant pour EC2. Cr\u00e9ez un volume : aws ec2 create-volume --availability-zone eu-west-1a --size 10 --volume-type gp2 Attachez-le \u00e0 une instance : aws ec2 attach-volume --volume-id vol-1234567890abcdef0 --instance-id i-1234567890abcdef0 --device /dev/xvdf","title":"EBS"},{"location":"DevOps/aws/#rds","text":"RDS (Relational Database Service) permet de d\u00e9ployer des bases de donn\u00e9es manag\u00e9es (MySQL, PostgreSQL, etc). Cr\u00e9ez une instance : aws rds create-db-instance --db-instance-identifier mydb --db-instance-class db.t3.micro --engine postgres --master-username admin --master-user-password password --allocated-storage 20 Supprimez une instance : aws rds delete-db-instance --db-instance-identifier mydb --skip-final-snapshot","title":"RDS"},{"location":"DevOps/aws/#dynamodb","text":"DynamoDB est une base NoSQL manag\u00e9e, scalable et performante. Cr\u00e9ez une table : aws dynamodb create-table --table-name MaTable --attribute-definitions AttributeName=Id,AttributeType=S --key-schema AttributeName=Id,KeyType=HASH --provisioned-throughput ReadCapacityUnits=1,WriteCapacityUnits=1","title":"DynamoDB"},{"location":"DevOps/aws/#lambda","text":"Lambda permet d\u2019ex\u00e9cuter du code sans g\u00e9rer de serveur (serverless).","title":"Lambda"},{"location":"DevOps/aws/#deployer-une-lambda-sous-forme-de-conteneur-docker","text":"Construisez l\u2019image Docker avec votre code et un Dockerfile compatible Lambda. Publiez l\u2019image sur ECR. Cr\u00e9ez la fonction Lambda en sp\u00e9cifiant l\u2019URL de l\u2019image.","title":"D\u00e9ployer une Lambda sous forme de conteneur Docker"},{"location":"DevOps/aws/#parametrer-les-autorisations-de-la-fonction","text":"Attribuez un r\u00f4le IAM \u00e0 la Lambda pour acc\u00e9der \u00e0 d\u2019autres services (S3, DynamoDB, etc).","title":"Param\u00e9trer les autorisations de la fonction"},{"location":"DevOps/aws/#nettoyer-les-ressources_1","text":"aws lambda delete-function --function-name ma-fonction","title":"Nettoyer les ressources"},{"location":"DevOps/aws/#sqs-sns","text":"SQS (Simple Queue Service) : file d\u2019attente pour la communication asynchrone. SNS (Simple Notification Service) : notifications push/pub-sub. Exemple : cr\u00e9er une file SQS aws sqs create-queue --queue-name MaFile","title":"SQS &amp; SNS"},{"location":"DevOps/aws/#cloudwatch","text":"CloudWatch permet la collecte de logs, la cr\u00e9ation d\u2019alarmes et le monitoring des ressources.","title":"CloudWatch"},{"location":"DevOps/aws/#creer-un-groupe-de-log","text":"aws logs create-log-group --log-group-name MonGroupe","title":"Cr\u00e9er un groupe de log"},{"location":"DevOps/aws/#creer-ses-propres-kpi","text":"Utilisez les m\u00e9triques personnalis\u00e9es : aws cloudwatch put-metric-data --metric-name MaMetrice --namespace MonApp --value 42","title":"Cr\u00e9er ses propres KPI"},{"location":"DevOps/aws/#creer-des-alarmes","text":"aws cloudwatch put-metric-alarm --alarm-name CPUHigh --metric-name CPUUtilization --namespace AWS/EC2 --statistic Average --period 300 --threshold 80 --comparison-operator GreaterThanThreshold --dimension Name=InstanceId,Value=i-1234567890abcdef0 --evaluation-periods 2 --alarm-actions arn:aws:sns:... --unit Percent","title":"Cr\u00e9er des alarmes"},{"location":"DevOps/aws/#mettre-en-place-un-workflow-de-monitoring","text":"Utilisez CloudWatch Events pour d\u00e9clencher des actions (ex : Lambda) sur alarme.","title":"Mettre en place un workflow de monitoring"},{"location":"DevOps/aws/#nettoyer-les-ressources_2","text":"aws logs delete-log-group --log-group-name MonGroupe","title":"Nettoyer les ressources"},{"location":"DevOps/aws/#api-gateway","text":"API Gateway permet d\u2019exposer des APIs REST ou WebSocket manag\u00e9es, avec int\u00e9gration Lambda, authentification, throttling, etc. Cr\u00e9ez une API : aws apigateway create-rest-api --name \"MonAPI\"","title":"API Gateway"},{"location":"DevOps/aws/#ecr","text":"ECR (Elastic Container Registry) est un registre Docker manag\u00e9. Cr\u00e9ez un repo : aws ecr create-repository --repository-name mon-repo Pushez une image : aws ecr get-login-password | docker login --username AWS --password-stdin <account-id>.dkr.ecr.<region>.amazonaws.com docker tag mon-image:latest <account-id>.dkr.ecr.<region>.amazonaws.com/mon-repo:latest docker push <account-id>.dkr.ecr.<region>.amazonaws.com/mon-repo:latest","title":"ECR"},{"location":"DevOps/aws/#kubernetes","text":"AWS propose EKS (Elastic Kubernetes Service) pour d\u00e9ployer des clusters Kubernetes manag\u00e9s. Cr\u00e9ez un cluster avec l\u2019outil eksctl : eksctl create cluster --name mon-cluster --region eu-west-1 --nodes 2 D\u00e9ployez vos applications comme sur n\u2019importe quel cluster Kubernetes.","title":"Kubernetes"},{"location":"DevOps/aws/#bonnes-pratiques","text":"Utilisez IAM pour contr\u00f4ler finement les acc\u00e8s. Activez la MFA sur les comptes sensibles. Surveillez vos co\u00fbts avec AWS Budgets. Automatisez vos d\u00e9ploiements avec CI/CD (CodePipeline, GitHub Actions, GitLab CI). Nettoyez r\u00e9guli\u00e8rement les ressources inutilis\u00e9es.","title":"Bonnes pratiques"},{"location":"DevOps/aws/#ressources-utiles","text":"Documentation AWS AWS CLI Reference AWS Well-Architected Framework AWS Free Tier","title":"Ressources utiles"},{"location":"DevOps/gitlab/","text":"Gitlab GitLab est une plateforme DevOps compl\u00e8te qui propose la gestion du code source, l\u2019int\u00e9gration continue (CI), le d\u00e9ploiement continu (CD), l\u2019h\u00e9bergement de pages statiques et de registres Docker priv\u00e9s. Int\u00e9gration continue avec Gitlab CI GitLab CI permet d\u2019automatiser les tests, la construction et le d\u00e9ploiement de vos applications via un fichier .gitlab-ci.yml \u00e0 la racine du d\u00e9p\u00f4t. Exemple minimal : stages: - test test_job: stage: test script: - echo \"Lancement des tests\" - pytest Chaque job s\u2019ex\u00e9cute dans un runner GitLab. Les \u00e9tapes ( stages ) d\u00e9finissent l\u2019ordre d\u2019ex\u00e9cution (ex : build, test, deploy). Les variables d\u2019environnement peuvent \u00eatre d\u00e9finies dans l\u2019interface GitLab ou dans le fichier YAML. D\u00e9ploiement continu de documentation avec Gitlab Pages GitLab Pages permet d\u2019h\u00e9berger des sites statiques (documentation, blogs, etc.) directement depuis un d\u00e9p\u00f4t GitLab. Exemple de pipeline pour MkDocs : pages: image: python:3.11 stage: deploy script: - pip install mkdocs - mkdocs build - mv site public artifacts: paths: - public only: - main Le dossier public est publi\u00e9 automatiquement. L\u2019URL du site est du type : https://<namespace>.gitlab.io/<project> H\u00e9bergement de livrables docker avec Gitlab Registry GitLab propose un registre Docker priv\u00e9 int\u00e9gr\u00e9 \u00e0 chaque projet. Exemple de pipeline pour builder et pousser une image : build-image: image: docker:latest services: - docker:dind stage: build script: - docker login -u \"$CI_REGISTRY_USER\" -p \"$CI_REGISTRY_PASSWORD\" $CI_REGISTRY - docker build -t $CI_REGISTRY_IMAGE:latest . - docker push $CI_REGISTRY_IMAGE:latest $CI_REGISTRY_IMAGE est une variable pr\u00e9d\u00e9finie pointant vers le registre du projet. Les identifiants sont inject\u00e9s automatiquement par GitLab CI. Bonnes pratiques Versionnez vos pipelines avec .gitlab-ci.yml . Utilisez des variables de projet pour les secrets. S\u00e9parez les \u00e9tapes (build, test, deploy) pour plus de clart\u00e9. Nettoyez r\u00e9guli\u00e8rement les images Docker inutilis\u00e9es dans le Registry. Ressources utiles Documentation GitLab CI/CD GitLab Pages GitLab Container Registry","title":"GitLab"},{"location":"DevOps/gitlab/#gitlab","text":"GitLab est une plateforme DevOps compl\u00e8te qui propose la gestion du code source, l\u2019int\u00e9gration continue (CI), le d\u00e9ploiement continu (CD), l\u2019h\u00e9bergement de pages statiques et de registres Docker priv\u00e9s.","title":"Gitlab"},{"location":"DevOps/gitlab/#integration-continue-avec-gitlab-ci","text":"GitLab CI permet d\u2019automatiser les tests, la construction et le d\u00e9ploiement de vos applications via un fichier .gitlab-ci.yml \u00e0 la racine du d\u00e9p\u00f4t. Exemple minimal : stages: - test test_job: stage: test script: - echo \"Lancement des tests\" - pytest Chaque job s\u2019ex\u00e9cute dans un runner GitLab. Les \u00e9tapes ( stages ) d\u00e9finissent l\u2019ordre d\u2019ex\u00e9cution (ex : build, test, deploy). Les variables d\u2019environnement peuvent \u00eatre d\u00e9finies dans l\u2019interface GitLab ou dans le fichier YAML.","title":"Int\u00e9gration continue avec Gitlab CI"},{"location":"DevOps/gitlab/#deploiement-continu-de-documentation-avec-gitlab-pages","text":"GitLab Pages permet d\u2019h\u00e9berger des sites statiques (documentation, blogs, etc.) directement depuis un d\u00e9p\u00f4t GitLab. Exemple de pipeline pour MkDocs : pages: image: python:3.11 stage: deploy script: - pip install mkdocs - mkdocs build - mv site public artifacts: paths: - public only: - main Le dossier public est publi\u00e9 automatiquement. L\u2019URL du site est du type : https://<namespace>.gitlab.io/<project>","title":"D\u00e9ploiement continu de documentation avec Gitlab Pages"},{"location":"DevOps/gitlab/#hebergement-de-livrables-docker-avec-gitlab-registry","text":"GitLab propose un registre Docker priv\u00e9 int\u00e9gr\u00e9 \u00e0 chaque projet. Exemple de pipeline pour builder et pousser une image : build-image: image: docker:latest services: - docker:dind stage: build script: - docker login -u \"$CI_REGISTRY_USER\" -p \"$CI_REGISTRY_PASSWORD\" $CI_REGISTRY - docker build -t $CI_REGISTRY_IMAGE:latest . - docker push $CI_REGISTRY_IMAGE:latest $CI_REGISTRY_IMAGE est une variable pr\u00e9d\u00e9finie pointant vers le registre du projet. Les identifiants sont inject\u00e9s automatiquement par GitLab CI.","title":"H\u00e9bergement de livrables docker avec Gitlab Registry"},{"location":"DevOps/gitlab/#bonnes-pratiques","text":"Versionnez vos pipelines avec .gitlab-ci.yml . Utilisez des variables de projet pour les secrets. S\u00e9parez les \u00e9tapes (build, test, deploy) pour plus de clart\u00e9. Nettoyez r\u00e9guli\u00e8rement les images Docker inutilis\u00e9es dans le Registry.","title":"Bonnes pratiques"},{"location":"DevOps/gitlab/#ressources-utiles","text":"Documentation GitLab CI/CD GitLab Pages GitLab Container Registry","title":"Ressources utiles"},{"location":"DevOps/helm/","text":"Regrouper ses manifestes dans un chart Helm Helm est le gestionnaire de packages de Kubernetes. Il permet de regrouper, param\u00e9trer et d\u00e9ployer facilement des manifestes Kubernetes sous forme de \"charts\" r\u00e9utilisables et versionn\u00e9s. Installer Helm Sous Linux : curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash V\u00e9rifiez l\u2019installation : helm version Cr\u00e9er un chart Helm Pour g\u00e9n\u00e9rer la structure d\u2019un nouveau chart : helm create mon-chart Cela cr\u00e9e un dossier mon-chart/ avec la structure suivante : - Chart.yaml : m\u00e9tadonn\u00e9es du chart - values.yaml : valeurs par d\u00e9faut - templates/ : manifestes Kubernetes templates Ajouter des manifestes Placez vos fichiers YAML Kubernetes dans le dossier templates/ du chart. Exemple : - deployment.yaml - service.yaml Vous pouvez utiliser la syntaxe Go templating pour rendre les manifestes dynamiques. Ajouter des valeurs D\u00e9finissez les variables dans values.yaml : replicaCount: 2 image: repository: nginx tag: latest Dans vos templates : spec: replicas: {{ .Values.replicaCount }} containers: - image: \"{{ .Values.image.repository }}:{{ .Values.image.tag }}\" Ajouter des templates Utilisez la syntaxe Helm ( {{ ... }} ) pour param\u00e9trer vos manifestes. Exemple : metadata: name: {{ include \"mon-chart.fullname\" . }} Vous pouvez cr\u00e9er des helpers dans _helpers.tpl pour factoriser du code. Ajouter des d\u00e9pendances D\u00e9clarez les d\u00e9pendances dans Chart.yaml : dependencies: - name: redis version: 18.0.0 repository: https://charts.bitnami.com/bitnami Installez les d\u00e9pendances : helm dependency update mon-chart Installer un chart Helm helm install mon-app ./mon-chart -n mon-namespace Pour passer des valeurs personnalis\u00e9es : helm install mon-app ./mon-chart -f valeurs-persos.yaml Mettre \u00e0 jour un chart Helm helm upgrade mon-app ./mon-chart Supprimer un chart Helm helm uninstall mon-app Ajouter des hooks Les hooks permettent d\u2019ex\u00e9cuter des jobs avant/apr\u00e8s certaines \u00e9tapes (pre-install, post-upgrade, etc). Exemple dans un template : apiVersion: batch/v1 kind: Job metadata: name: migration-job annotations: \"helm.sh/hook\": pre-install spec: ... Ajouter des tests Helm permet d\u2019ajouter des tests automatis\u00e9s (pods qui doivent r\u00e9ussir). Placez-les dans templates/tests/ : apiVersion: v1 kind: Pod metadata: name: \"test-connection\" annotations: \"helm.sh/hook\": test spec: containers: - name: curl image: curlimages/curl command: ['curl', '--fail', 'http://mon-service:80'] restartPolicy: Never Lancez les tests : helm test mon-app Bonnes pratiques Versionnez vos charts et documentez les valeurs dans values.yaml . Utilisez des helpers pour factoriser les noms et labels. Testez vos charts en local avec helm template . Utilisez des sch\u00e9mas de validation ( values.schema.json ). Publiez vos charts sur un repository Helm pour les partager. Ressources utiles Documentation officielle Helm Helm Hub (charts) Best practices Helm","title":"Helm"},{"location":"DevOps/helm/#regrouper-ses-manifestes-dans-un-chart-helm","text":"Helm est le gestionnaire de packages de Kubernetes. Il permet de regrouper, param\u00e9trer et d\u00e9ployer facilement des manifestes Kubernetes sous forme de \"charts\" r\u00e9utilisables et versionn\u00e9s.","title":"Regrouper ses manifestes dans un chart Helm"},{"location":"DevOps/helm/#installer-helm","text":"Sous Linux : curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash V\u00e9rifiez l\u2019installation : helm version","title":"Installer Helm"},{"location":"DevOps/helm/#creer-un-chart-helm","text":"Pour g\u00e9n\u00e9rer la structure d\u2019un nouveau chart : helm create mon-chart Cela cr\u00e9e un dossier mon-chart/ avec la structure suivante : - Chart.yaml : m\u00e9tadonn\u00e9es du chart - values.yaml : valeurs par d\u00e9faut - templates/ : manifestes Kubernetes templates","title":"Cr\u00e9er un chart Helm"},{"location":"DevOps/helm/#ajouter-des-manifestes","text":"Placez vos fichiers YAML Kubernetes dans le dossier templates/ du chart. Exemple : - deployment.yaml - service.yaml Vous pouvez utiliser la syntaxe Go templating pour rendre les manifestes dynamiques.","title":"Ajouter des manifestes"},{"location":"DevOps/helm/#ajouter-des-valeurs","text":"D\u00e9finissez les variables dans values.yaml : replicaCount: 2 image: repository: nginx tag: latest Dans vos templates : spec: replicas: {{ .Values.replicaCount }} containers: - image: \"{{ .Values.image.repository }}:{{ .Values.image.tag }}\"","title":"Ajouter des valeurs"},{"location":"DevOps/helm/#ajouter-des-templates","text":"Utilisez la syntaxe Helm ( {{ ... }} ) pour param\u00e9trer vos manifestes. Exemple : metadata: name: {{ include \"mon-chart.fullname\" . }} Vous pouvez cr\u00e9er des helpers dans _helpers.tpl pour factoriser du code.","title":"Ajouter des templates"},{"location":"DevOps/helm/#ajouter-des-dependances","text":"D\u00e9clarez les d\u00e9pendances dans Chart.yaml : dependencies: - name: redis version: 18.0.0 repository: https://charts.bitnami.com/bitnami Installez les d\u00e9pendances : helm dependency update mon-chart","title":"Ajouter des d\u00e9pendances"},{"location":"DevOps/helm/#installer-un-chart-helm","text":"helm install mon-app ./mon-chart -n mon-namespace Pour passer des valeurs personnalis\u00e9es : helm install mon-app ./mon-chart -f valeurs-persos.yaml","title":"Installer un chart Helm"},{"location":"DevOps/helm/#mettre-a-jour-un-chart-helm","text":"helm upgrade mon-app ./mon-chart","title":"Mettre \u00e0 jour un chart Helm"},{"location":"DevOps/helm/#supprimer-un-chart-helm","text":"helm uninstall mon-app","title":"Supprimer un chart Helm"},{"location":"DevOps/helm/#ajouter-des-hooks","text":"Les hooks permettent d\u2019ex\u00e9cuter des jobs avant/apr\u00e8s certaines \u00e9tapes (pre-install, post-upgrade, etc). Exemple dans un template : apiVersion: batch/v1 kind: Job metadata: name: migration-job annotations: \"helm.sh/hook\": pre-install spec: ...","title":"Ajouter des hooks"},{"location":"DevOps/helm/#ajouter-des-tests","text":"Helm permet d\u2019ajouter des tests automatis\u00e9s (pods qui doivent r\u00e9ussir). Placez-les dans templates/tests/ : apiVersion: v1 kind: Pod metadata: name: \"test-connection\" annotations: \"helm.sh/hook\": test spec: containers: - name: curl image: curlimages/curl command: ['curl', '--fail', 'http://mon-service:80'] restartPolicy: Never Lancez les tests : helm test mon-app","title":"Ajouter des tests"},{"location":"DevOps/helm/#bonnes-pratiques","text":"Versionnez vos charts et documentez les valeurs dans values.yaml . Utilisez des helpers pour factoriser les noms et labels. Testez vos charts en local avec helm template . Utilisez des sch\u00e9mas de validation ( values.schema.json ). Publiez vos charts sur un repository Helm pour les partager.","title":"Bonnes pratiques"},{"location":"DevOps/helm/#ressources-utiles","text":"Documentation officielle Helm Helm Hub (charts) Best practices Helm","title":"Ressources utiles"},{"location":"DevOps/krr/","text":"Dimensioner un cluster Kubernetes avec KRR KRR (Kubernetes Resource Recommender) est un outil open source qui analyse l\u2019utilisation r\u00e9elle des ressources (CPU, m\u00e9moire) de vos pods et propose des recommandations pour optimiser les requests/limits. Cela permet de r\u00e9duire la sur-allocation, d\u2019optimiser les co\u00fbts et d\u2019am\u00e9liorer la stabilit\u00e9 du cluster. Installation de KRR KRR peut \u00eatre install\u00e9 en tant que binaire ou via un conteneur Docker. Installation via binaire curl -L https://github.com/robusta-dev/krr/releases/latest/download/krr-linux-amd64 -o krr chmod +x krr sudo mv krr /usr/local/bin/ Installation via Docker docker pull ghcr.io/robusta-dev/krr:latest Connecter au monitoring Prometheus KRR se connecte \u00e0 Prometheus pour r\u00e9cup\u00e9rer les m\u00e9triques d\u2019utilisation des pods. Il faut fournir l\u2019URL de Prometheus (souvent accessible via un port-forward ou une URL interne du cluster). Exemple de lancement : krr recommend --prometheus-url http://localhost:9090 --namespace my-namespace Pour acc\u00e9der \u00e0 Prometheus depuis l\u2019ext\u00e9rieur du cluster : kubectl port-forward svc/prometheus-k8s 9090:9090 -n monitoring Vous pouvez cibler un namespace, un d\u00e9ploiement ou tout le cluster. KRR g\u00e9n\u00e8re un rapport avec les recommandations de requests/limits pour chaque pod analys\u00e9. Visualisation des donn\u00e9es dans k9s et Grafana k9s : Apr\u00e8s avoir appliqu\u00e9 les recommandations, utilisez k9s pour visualiser en temps r\u00e9el l\u2019\u00e9tat des pods, leur consommation et les \u00e9ventuels OOM ou throttling. Grafana : Connect\u00e9 \u00e0 Prometheus, Grafana permet de visualiser l\u2019\u00e9volution de la consommation CPU/m\u00e9moire, de comparer les requests/limits actuels et recommand\u00e9s, et de suivre l\u2019impact des optimisations. Exemple de dashboard Grafana Utilisez les dashboards communautaires (ex : Kubernetes / Compute Resources Namespace (Grafana.com) ) Ajoutez des panels pour suivre les m\u00e9triques : container_cpu_usage_seconds_total , container_memory_usage_bytes , etc. Bonnes pratiques Appliquez les recommandations KRR d\u2019abord en environnement de test. Surveillez l\u2019impact sur la stabilit\u00e9 et la performance apr\u00e8s modification. R\u00e9p\u00e9tez l\u2019analyse r\u00e9guli\u00e8rement pour adapter les ressources \u00e0 l\u2019\u00e9volution de la charge. Ressources utiles KRR GitHub Documentation officielle KRR Exemple d\u2019int\u00e9gration Prometheus/Grafana","title":"KRR"},{"location":"DevOps/krr/#dimensioner-un-cluster-kubernetes-avec-krr","text":"KRR (Kubernetes Resource Recommender) est un outil open source qui analyse l\u2019utilisation r\u00e9elle des ressources (CPU, m\u00e9moire) de vos pods et propose des recommandations pour optimiser les requests/limits. Cela permet de r\u00e9duire la sur-allocation, d\u2019optimiser les co\u00fbts et d\u2019am\u00e9liorer la stabilit\u00e9 du cluster.","title":"Dimensioner un cluster Kubernetes avec KRR"},{"location":"DevOps/krr/#installation-de-krr","text":"KRR peut \u00eatre install\u00e9 en tant que binaire ou via un conteneur Docker.","title":"Installation de KRR"},{"location":"DevOps/krr/#installation-via-binaire","text":"curl -L https://github.com/robusta-dev/krr/releases/latest/download/krr-linux-amd64 -o krr chmod +x krr sudo mv krr /usr/local/bin/","title":"Installation via binaire"},{"location":"DevOps/krr/#installation-via-docker","text":"docker pull ghcr.io/robusta-dev/krr:latest","title":"Installation via Docker"},{"location":"DevOps/krr/#connecter-au-monitoring-prometheus","text":"KRR se connecte \u00e0 Prometheus pour r\u00e9cup\u00e9rer les m\u00e9triques d\u2019utilisation des pods. Il faut fournir l\u2019URL de Prometheus (souvent accessible via un port-forward ou une URL interne du cluster). Exemple de lancement : krr recommend --prometheus-url http://localhost:9090 --namespace my-namespace Pour acc\u00e9der \u00e0 Prometheus depuis l\u2019ext\u00e9rieur du cluster : kubectl port-forward svc/prometheus-k8s 9090:9090 -n monitoring Vous pouvez cibler un namespace, un d\u00e9ploiement ou tout le cluster. KRR g\u00e9n\u00e8re un rapport avec les recommandations de requests/limits pour chaque pod analys\u00e9.","title":"Connecter au monitoring Prometheus"},{"location":"DevOps/krr/#visualisation-des-donnees-dans-k9s-et-grafana","text":"k9s : Apr\u00e8s avoir appliqu\u00e9 les recommandations, utilisez k9s pour visualiser en temps r\u00e9el l\u2019\u00e9tat des pods, leur consommation et les \u00e9ventuels OOM ou throttling. Grafana : Connect\u00e9 \u00e0 Prometheus, Grafana permet de visualiser l\u2019\u00e9volution de la consommation CPU/m\u00e9moire, de comparer les requests/limits actuels et recommand\u00e9s, et de suivre l\u2019impact des optimisations.","title":"Visualisation des donn\u00e9es dans k9s et Grafana"},{"location":"DevOps/krr/#exemple-de-dashboard-grafana","text":"Utilisez les dashboards communautaires (ex : Kubernetes / Compute Resources Namespace (Grafana.com) ) Ajoutez des panels pour suivre les m\u00e9triques : container_cpu_usage_seconds_total , container_memory_usage_bytes , etc.","title":"Exemple de dashboard Grafana"},{"location":"DevOps/krr/#bonnes-pratiques","text":"Appliquez les recommandations KRR d\u2019abord en environnement de test. Surveillez l\u2019impact sur la stabilit\u00e9 et la performance apr\u00e8s modification. R\u00e9p\u00e9tez l\u2019analyse r\u00e9guli\u00e8rement pour adapter les ressources \u00e0 l\u2019\u00e9volution de la charge.","title":"Bonnes pratiques"},{"location":"DevOps/krr/#ressources-utiles","text":"KRR GitHub Documentation officielle KRR Exemple d\u2019int\u00e9gration Prometheus/Grafana","title":"Ressources utiles"},{"location":"DevOps/kubejob/","text":"Cr\u00e9er et d\u00e9ployer un job kubernetes Un Job Kubernetes permet d\u2019ex\u00e9cuter une ou plusieurs t\u00e2ches de fa\u00e7on ponctuelle ou batch, jusqu\u2019\u00e0 leur compl\u00e9tion. Contrairement \u00e0 un Deployment ou un Pod classique, le Job garantit que la t\u00e2che sera ex\u00e9cut\u00e9e jusqu\u2019\u00e0 la r\u00e9ussite (ou l\u2019\u00e9chec apr\u00e8s un certain nombre de tentatives). Exemple de manifeste Job YAML apiVersion: batch/v1 kind: Job metadata: name: exemple-job spec: template: spec: containers: - name: mon-job image: mon-image:latest command: [\"sh\", \"-c\", \"echo Hello depuis un job Kubernetes!\"] restartPolicy: Never backoffLimit: 3 image : remplacez par l\u2019image de votre application (Python, Go, Java, Node, etc). command : la commande \u00e0 ex\u00e9cuter dans le conteneur. restartPolicy: Never : recommand\u00e9 pour les jobs batch. backoffLimit : nombre de tentatives avant de consid\u00e9rer le job en \u00e9chec. D\u00e9ployer le job kubectl apply -f job.yaml V\u00e9rifier l\u2019\u00e9tat du job : kubectl get jobs kubectl describe job exemple-job kubectl logs job/exemple-job Cas d\u2019usage courants Traitement de donn\u00e9es ponctuel (ETL, migration de base de donn\u00e9es) G\u00e9n\u00e9ration de rapports Ex\u00e9cution de scripts de maintenance Import/export de fichiers Bonnes pratiques Utilisez des variables d\u2019environnement pour la configuration (section env: ). Stockez les secrets dans des Secret ou ConfigMap Kubernetes. Pr\u00e9voyez une gestion des erreurs et des logs dans votre application. Nettoyez les jobs termin\u00e9s avec un ttlSecondsAfterFinished : spec: ttlSecondsAfterFinished: 3600 # Suppression automatique apr\u00e8s 1h Aller plus loin Pour des t\u00e2ches planifi\u00e9es, utilisez un CronJob Kubernetes. Pour des jobs parall\u00e8les, ajustez completions et parallelism : spec: completions: 5 parallelism: 2 Ressources utiles Documentation officielle Kubernetes Job Kubernetes CronJob","title":"Job Kubernetes"},{"location":"DevOps/kubejob/#creer-et-deployer-un-job-kubernetes","text":"Un Job Kubernetes permet d\u2019ex\u00e9cuter une ou plusieurs t\u00e2ches de fa\u00e7on ponctuelle ou batch, jusqu\u2019\u00e0 leur compl\u00e9tion. Contrairement \u00e0 un Deployment ou un Pod classique, le Job garantit que la t\u00e2che sera ex\u00e9cut\u00e9e jusqu\u2019\u00e0 la r\u00e9ussite (ou l\u2019\u00e9chec apr\u00e8s un certain nombre de tentatives).","title":"Cr\u00e9er et d\u00e9ployer un job kubernetes"},{"location":"DevOps/kubejob/#exemple-de-manifeste-job-yaml","text":"apiVersion: batch/v1 kind: Job metadata: name: exemple-job spec: template: spec: containers: - name: mon-job image: mon-image:latest command: [\"sh\", \"-c\", \"echo Hello depuis un job Kubernetes!\"] restartPolicy: Never backoffLimit: 3 image : remplacez par l\u2019image de votre application (Python, Go, Java, Node, etc). command : la commande \u00e0 ex\u00e9cuter dans le conteneur. restartPolicy: Never : recommand\u00e9 pour les jobs batch. backoffLimit : nombre de tentatives avant de consid\u00e9rer le job en \u00e9chec.","title":"Exemple de manifeste Job YAML"},{"location":"DevOps/kubejob/#deployer-le-job","text":"kubectl apply -f job.yaml V\u00e9rifier l\u2019\u00e9tat du job : kubectl get jobs kubectl describe job exemple-job kubectl logs job/exemple-job","title":"D\u00e9ployer le job"},{"location":"DevOps/kubejob/#cas-dusage-courants","text":"Traitement de donn\u00e9es ponctuel (ETL, migration de base de donn\u00e9es) G\u00e9n\u00e9ration de rapports Ex\u00e9cution de scripts de maintenance Import/export de fichiers","title":"Cas d\u2019usage courants"},{"location":"DevOps/kubejob/#bonnes-pratiques","text":"Utilisez des variables d\u2019environnement pour la configuration (section env: ). Stockez les secrets dans des Secret ou ConfigMap Kubernetes. Pr\u00e9voyez une gestion des erreurs et des logs dans votre application. Nettoyez les jobs termin\u00e9s avec un ttlSecondsAfterFinished : spec: ttlSecondsAfterFinished: 3600 # Suppression automatique apr\u00e8s 1h","title":"Bonnes pratiques"},{"location":"DevOps/kubejob/#aller-plus-loin","text":"Pour des t\u00e2ches planifi\u00e9es, utilisez un CronJob Kubernetes. Pour des jobs parall\u00e8les, ajustez completions et parallelism : spec: completions: 5 parallelism: 2","title":"Aller plus loin"},{"location":"DevOps/kubejob/#ressources-utiles","text":"Documentation officielle Kubernetes Job Kubernetes CronJob","title":"Ressources utiles"},{"location":"DevOps/pypi/","text":"Cr\u00e9er et d\u00e9ployer un package python sur PyPI Publier un package sur PyPI permet de le rendre accessible \u00e0 toute la communaut\u00e9 Python via pip install . Voici les \u00e9tapes d\u00e9taill\u00e9es pour cr\u00e9er, packager et publier votre module. Cr\u00e9er un package en python Organisez votre projet comme ceci : mon_package/ \u251c\u2500\u2500 mon_package/ \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 core.py \u251c\u2500\u2500 tests/ \u2502 \u2514\u2500\u2500 test_core.py \u251c\u2500\u2500 setup.py \u251c\u2500\u2500 README.md \u2514\u2500\u2500 LICENSE Mettre en place le setup.py Exemple minimal : from setuptools import setup, find_packages setup( name=\"mon_package\", version=\"0.1.0\", description=\"Un exemple de package Python\", author=\"Votre Nom\", packages=find_packages(), install_requires=[], python_requires=\">=3.7\", ) Ajoutez un fichier README.md pour la description longue, et un fichier LICENSE (MIT, Apache2, etc). Bonnes pratiques Ajoutez des tests unitaires dans le dossier tests/ . Utilisez un .gitignore adapt\u00e9 (voir github/gitignore/python ). Documentez vos fonctions avec des docstrings. Versionnez votre code avec git. Ajoutez un fichier pyproject.toml pour la compatibilit\u00e9 avec les outils modernes : [build-system] requires = [\"setuptools\", \"wheel\"] build-backend = \"setuptools.build_meta\" D\u00e9ploiement sur la plateforme Installez les outils n\u00e9cessaires : pip install build twine G\u00e9n\u00e9rez les artefacts : python -m build # ou python setup.py sdist bdist_wheel Publiez sur TestPyPI pour tester : twine upload --repository testpypi dist/* # puis v\u00e9rifiez sur https://test.pypi.org/project/mon_package/ Publiez sur PyPI : twine upload dist/* # puis v\u00e9rifiez sur https://pypi.org/project/mon_package/ Int\u00e9gration avec libraries.io libraries.io r\u00e9f\u00e9rence automatiquement les packages publi\u00e9s sur PyPI. Pour am\u00e9liorer la visibilit\u00e9 : - Ajoutez un lien vers le repo GitHub dans le champ url de setup.py . - Ajoutez des badges (PyPI version, build, etc) dans votre README.md . Ressources utiles Packaging Python Projects (officiel) TestPyPI Twine libraries.io","title":"PyPI"},{"location":"DevOps/pypi/#creer-et-deployer-un-package-python-sur-pypi","text":"Publier un package sur PyPI permet de le rendre accessible \u00e0 toute la communaut\u00e9 Python via pip install . Voici les \u00e9tapes d\u00e9taill\u00e9es pour cr\u00e9er, packager et publier votre module.","title":"Cr\u00e9er et d\u00e9ployer un package python sur PyPI"},{"location":"DevOps/pypi/#creer-un-package-en-python","text":"Organisez votre projet comme ceci : mon_package/ \u251c\u2500\u2500 mon_package/ \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 core.py \u251c\u2500\u2500 tests/ \u2502 \u2514\u2500\u2500 test_core.py \u251c\u2500\u2500 setup.py \u251c\u2500\u2500 README.md \u2514\u2500\u2500 LICENSE","title":"Cr\u00e9er un package en python"},{"location":"DevOps/pypi/#mettre-en-place-le-setuppy","text":"Exemple minimal : from setuptools import setup, find_packages setup( name=\"mon_package\", version=\"0.1.0\", description=\"Un exemple de package Python\", author=\"Votre Nom\", packages=find_packages(), install_requires=[], python_requires=\">=3.7\", ) Ajoutez un fichier README.md pour la description longue, et un fichier LICENSE (MIT, Apache2, etc).","title":"Mettre en place le setup.py"},{"location":"DevOps/pypi/#bonnes-pratiques","text":"Ajoutez des tests unitaires dans le dossier tests/ . Utilisez un .gitignore adapt\u00e9 (voir github/gitignore/python ). Documentez vos fonctions avec des docstrings. Versionnez votre code avec git. Ajoutez un fichier pyproject.toml pour la compatibilit\u00e9 avec les outils modernes : [build-system] requires = [\"setuptools\", \"wheel\"] build-backend = \"setuptools.build_meta\"","title":"Bonnes pratiques"},{"location":"DevOps/pypi/#deploiement-sur-la-plateforme","text":"Installez les outils n\u00e9cessaires : pip install build twine G\u00e9n\u00e9rez les artefacts : python -m build # ou python setup.py sdist bdist_wheel Publiez sur TestPyPI pour tester : twine upload --repository testpypi dist/* # puis v\u00e9rifiez sur https://test.pypi.org/project/mon_package/ Publiez sur PyPI : twine upload dist/* # puis v\u00e9rifiez sur https://pypi.org/project/mon_package/","title":"D\u00e9ploiement sur la plateforme"},{"location":"DevOps/pypi/#integration-avec-librariesio","text":"libraries.io r\u00e9f\u00e9rence automatiquement les packages publi\u00e9s sur PyPI. Pour am\u00e9liorer la visibilit\u00e9 : - Ajoutez un lien vers le repo GitHub dans le champ url de setup.py . - Ajoutez des badges (PyPI version, build, etc) dans votre README.md .","title":"Int\u00e9gration avec libraries.io"},{"location":"DevOps/pypi/#ressources-utiles","text":"Packaging Python Projects (officiel) TestPyPI Twine libraries.io","title":"Ressources utiles"},{"location":"DevOps/security-k8s/","text":"La s\u00e9curisation de Kubernetes S\u00e9curiser un cluster Kubernetes est essentiel pour prot\u00e9ger les applications, les donn\u00e9es et l\u2019infrastructure sous-jacente. Voici les principaux axes \u00e0 consid\u00e9rer pour renforcer la s\u00e9curit\u00e9 de vos d\u00e9ploiements Kubernetes. Contr\u00f4le d'acc\u00e8s bas\u00e9 sur les r\u00f4les (RBAC) RBAC permet de d\u00e9finir pr\u00e9cis\u00e9ment qui peut faire quoi dans le cluster. Exemple de r\u00f4le et binding : apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: namespace: dev name: lecture-pods rules: - apiGroups: [\"\"] resources: [\"pods\"] verbs: [\"get\", \"list\"] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: lecture-pods-binding namespace: dev subjects: - kind: User name: alice apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: lecture-pods apiGroup: rbac.authorization.k8s.io Utilisez le principe du moindre privil\u00e8ge : donnez uniquement les droits n\u00e9cessaires. Privil\u00e9giez les ServiceAccount pour les applications. S\u00e9curisation des secrets Stockez les secrets dans des objets Secret Kubernetes, jamais en clair dans les manifests. Utilisez le chiffrement au repos ( EncryptionConfiguration ). Exemple de cr\u00e9ation d\u2019un secret : kubectl create secret generic db-password --from-literal=password=SuperSecret123 Int\u00e9grez des solutions comme Sealed Secrets ou HashiCorp Vault pour une gestion avanc\u00e9e. S\u00e9curisation du r\u00e9seau Utilisez des NetworkPolicies pour restreindre la communication entre pods. Exemple : apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: deny-all namespace: prod spec: podSelector: {} policyTypes: - Ingress - Egress Isolez les namespaces sensibles. Activez le chiffrement des communications (TLS) entre les composants. Mise \u00e0 jour et patching Maintenez le cluster et les nodes \u00e0 jour (Kubernetes, OS, images Docker). Surveillez les CVE et appliquez les correctifs rapidement. Utilisez des images minimales et scann\u00e9es (ex : distroless , alpine ). Outils de s\u00e9curit\u00e9 kube-bench : v\u00e9rifie la conformit\u00e9 CIS de votre cluster. kube-hunter : d\u00e9tecte les failles de s\u00e9curit\u00e9. trivy : scanne les images Docker et les manifests. OPA/Gatekeeper : applique des politiques de s\u00e9curit\u00e9 personnalis\u00e9es. Bonnes pratiques g\u00e9n\u00e9rales D\u00e9sactivez l\u2019acc\u00e8s anonyme \u00e0 l\u2019API. Limitez l\u2019acc\u00e8s au dashboard Kubernetes. Activez l\u2019audit logging. Surveillez les logs et les alertes de s\u00e9curit\u00e9. Ressources utiles Kubernetes Security Best Practices (officiel) CIS Kubernetes Benchmark OWASP Kubernetes Top 10","title":"S\u00e9curit\u00e9 Kubernetes"},{"location":"DevOps/security-k8s/#la-securisation-de-kubernetes","text":"S\u00e9curiser un cluster Kubernetes est essentiel pour prot\u00e9ger les applications, les donn\u00e9es et l\u2019infrastructure sous-jacente. Voici les principaux axes \u00e0 consid\u00e9rer pour renforcer la s\u00e9curit\u00e9 de vos d\u00e9ploiements Kubernetes.","title":"La s\u00e9curisation de Kubernetes"},{"location":"DevOps/security-k8s/#controle-dacces-base-sur-les-roles-rbac","text":"RBAC permet de d\u00e9finir pr\u00e9cis\u00e9ment qui peut faire quoi dans le cluster. Exemple de r\u00f4le et binding : apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: namespace: dev name: lecture-pods rules: - apiGroups: [\"\"] resources: [\"pods\"] verbs: [\"get\", \"list\"] --- apiVersion: rbac.authorization.k8s.io/v1 kind: RoleBinding metadata: name: lecture-pods-binding namespace: dev subjects: - kind: User name: alice apiGroup: rbac.authorization.k8s.io roleRef: kind: Role name: lecture-pods apiGroup: rbac.authorization.k8s.io Utilisez le principe du moindre privil\u00e8ge : donnez uniquement les droits n\u00e9cessaires. Privil\u00e9giez les ServiceAccount pour les applications.","title":"Contr\u00f4le d'acc\u00e8s bas\u00e9 sur les r\u00f4les (RBAC)"},{"location":"DevOps/security-k8s/#securisation-des-secrets","text":"Stockez les secrets dans des objets Secret Kubernetes, jamais en clair dans les manifests. Utilisez le chiffrement au repos ( EncryptionConfiguration ). Exemple de cr\u00e9ation d\u2019un secret : kubectl create secret generic db-password --from-literal=password=SuperSecret123 Int\u00e9grez des solutions comme Sealed Secrets ou HashiCorp Vault pour une gestion avanc\u00e9e.","title":"S\u00e9curisation des secrets"},{"location":"DevOps/security-k8s/#securisation-du-reseau","text":"Utilisez des NetworkPolicies pour restreindre la communication entre pods. Exemple : apiVersion: networking.k8s.io/v1 kind: NetworkPolicy metadata: name: deny-all namespace: prod spec: podSelector: {} policyTypes: - Ingress - Egress Isolez les namespaces sensibles. Activez le chiffrement des communications (TLS) entre les composants.","title":"S\u00e9curisation du r\u00e9seau"},{"location":"DevOps/security-k8s/#mise-a-jour-et-patching","text":"Maintenez le cluster et les nodes \u00e0 jour (Kubernetes, OS, images Docker). Surveillez les CVE et appliquez les correctifs rapidement. Utilisez des images minimales et scann\u00e9es (ex : distroless , alpine ).","title":"Mise \u00e0 jour et patching"},{"location":"DevOps/security-k8s/#outils-de-securite","text":"kube-bench : v\u00e9rifie la conformit\u00e9 CIS de votre cluster. kube-hunter : d\u00e9tecte les failles de s\u00e9curit\u00e9. trivy : scanne les images Docker et les manifests. OPA/Gatekeeper : applique des politiques de s\u00e9curit\u00e9 personnalis\u00e9es.","title":"Outils de s\u00e9curit\u00e9"},{"location":"DevOps/security-k8s/#bonnes-pratiques-generales","text":"D\u00e9sactivez l\u2019acc\u00e8s anonyme \u00e0 l\u2019API. Limitez l\u2019acc\u00e8s au dashboard Kubernetes. Activez l\u2019audit logging. Surveillez les logs et les alertes de s\u00e9curit\u00e9.","title":"Bonnes pratiques g\u00e9n\u00e9rales"},{"location":"DevOps/security-k8s/#ressources-utiles","text":"Kubernetes Security Best Practices (officiel) CIS Kubernetes Benchmark OWASP Kubernetes Top 10","title":"Ressources utiles"},{"location":"DevOps/terraform/","text":"Terraform Terraform est un outil d\u2019Infrastructure as Code (IaC) permettant de d\u00e9crire, provisionner et g\u00e9rer des ressources cloud ou on-premise de fa\u00e7on d\u00e9clarative. Il fonctionne avec de nombreux fournisseurs (AWS, Azure, GCP, etc.) et facilite la reproductibilit\u00e9 et la tra\u00e7abilit\u00e9 de l\u2019infrastructure. Installation sur Linux T\u00e9l\u00e9chargez la derni\u00e8re version depuis terraform.io ou utilisez : sudo apt update sudo apt install -y wget unzip wget https://releases.hashicorp.com/terraform/1.8.5/terraform_1.8.5_linux_amd64.zip unzip terraform_1.8.5_linux_amd64.zip sudo mv terraform /usr/local/bin/ terraform version Op\u00e9rations classiques Cr\u00e9ation d'une infra Cr\u00e9ez un fichier main.tf : provider \"aws\" { region = \"eu-west-1\" } resource \"aws_s3_bucket\" \"bucket\" { bucket = \"mon-bucket-exemple\" } Initialisez le projet : terraform init Pr\u00e9visualisez les changements : terraform plan Appliquez la configuration : terraform apply Modification d'une infra Modifiez le fichier .tf (ex : changez le nom du bucket), puis : terraform plan terraform apply Ajout d'inputs et d'outputs Utilisez des variables pour rendre votre code r\u00e9utilisable : variables.tf : variable \"bucket_name\" { description = \"Nom du bucket S3\" type = string } main.tf : resource \"aws_s3_bucket\" \"bucket\" { bucket = var.bucket_name } outputs.tf : output \"bucket_arn\" { value = aws_s3_bucket.bucket.arn } Lancez : terraform apply -var=\"bucket_name=mon-bucket-demo\" Nettoyage d'une infra Pour supprimer toutes les ressources cr\u00e9\u00e9es : terraform destroy Stockage du state \u00e0 distance Le fichier terraform.tfstate contient l\u2019\u00e9tat de l\u2019infrastructure. Pour le travail en \u00e9quipe, stockez-le \u00e0 distance (ex : S3) : terraform { backend \"s3\" { bucket = \"mon-bucket-tfstate\" key = \"state/terraform.tfstate\" region = \"eu-west-1\" } } Initialisez le backend : terraform init G\u00e9n\u00e9ration d'un graphique Il est possible de g\u00e9n\u00e9rer un graphique \u00e0 l'aide de la librairie Graphviz Pour cela il faut installer Graphviz sudo apt install graphviz Puis, executer la commande suivante terraform graph | dot -Tsvg -Gfontcolor=blue -Glabel=\"My AWS infrastructure\" > graph.svg Bonnes pratiques Versionnez vos fichiers .tf avec git. Utilisez des workspaces pour g\u00e9rer plusieurs environnements (dev, prod). S\u00e9parez les variables sensibles (credentials) dans des fichiers non versionn\u00e9s. Relisez le plan ( terraform plan ) avant chaque apply . Utilisez des modules pour factoriser le code. Ressources utiles Documentation officielle Terraform Terraform Registry (modules) Best practices Terraform","title":"Terraform"},{"location":"DevOps/terraform/#terraform","text":"Terraform est un outil d\u2019Infrastructure as Code (IaC) permettant de d\u00e9crire, provisionner et g\u00e9rer des ressources cloud ou on-premise de fa\u00e7on d\u00e9clarative. Il fonctionne avec de nombreux fournisseurs (AWS, Azure, GCP, etc.) et facilite la reproductibilit\u00e9 et la tra\u00e7abilit\u00e9 de l\u2019infrastructure.","title":"Terraform"},{"location":"DevOps/terraform/#installation-sur-linux","text":"T\u00e9l\u00e9chargez la derni\u00e8re version depuis terraform.io ou utilisez : sudo apt update sudo apt install -y wget unzip wget https://releases.hashicorp.com/terraform/1.8.5/terraform_1.8.5_linux_amd64.zip unzip terraform_1.8.5_linux_amd64.zip sudo mv terraform /usr/local/bin/ terraform version","title":"Installation sur Linux"},{"location":"DevOps/terraform/#operations-classiques","text":"","title":"Op\u00e9rations classiques"},{"location":"DevOps/terraform/#creation-dune-infra","text":"Cr\u00e9ez un fichier main.tf : provider \"aws\" { region = \"eu-west-1\" } resource \"aws_s3_bucket\" \"bucket\" { bucket = \"mon-bucket-exemple\" } Initialisez le projet : terraform init Pr\u00e9visualisez les changements : terraform plan Appliquez la configuration : terraform apply","title":"Cr\u00e9ation d'une infra"},{"location":"DevOps/terraform/#modification-dune-infra","text":"Modifiez le fichier .tf (ex : changez le nom du bucket), puis : terraform plan terraform apply","title":"Modification d'une infra"},{"location":"DevOps/terraform/#ajout-dinputs-et-doutputs","text":"Utilisez des variables pour rendre votre code r\u00e9utilisable : variables.tf : variable \"bucket_name\" { description = \"Nom du bucket S3\" type = string } main.tf : resource \"aws_s3_bucket\" \"bucket\" { bucket = var.bucket_name } outputs.tf : output \"bucket_arn\" { value = aws_s3_bucket.bucket.arn } Lancez : terraform apply -var=\"bucket_name=mon-bucket-demo\"","title":"Ajout d'inputs et d'outputs"},{"location":"DevOps/terraform/#nettoyage-dune-infra","text":"Pour supprimer toutes les ressources cr\u00e9\u00e9es : terraform destroy","title":"Nettoyage d'une infra"},{"location":"DevOps/terraform/#stockage-du-state-a-distance","text":"Le fichier terraform.tfstate contient l\u2019\u00e9tat de l\u2019infrastructure. Pour le travail en \u00e9quipe, stockez-le \u00e0 distance (ex : S3) : terraform { backend \"s3\" { bucket = \"mon-bucket-tfstate\" key = \"state/terraform.tfstate\" region = \"eu-west-1\" } } Initialisez le backend : terraform init","title":"Stockage du state \u00e0 distance"},{"location":"DevOps/terraform/#generation-dun-graphique","text":"Il est possible de g\u00e9n\u00e9rer un graphique \u00e0 l'aide de la librairie Graphviz Pour cela il faut installer Graphviz sudo apt install graphviz Puis, executer la commande suivante terraform graph | dot -Tsvg -Gfontcolor=blue -Glabel=\"My AWS infrastructure\" > graph.svg","title":"G\u00e9n\u00e9ration d'un graphique"},{"location":"DevOps/terraform/#bonnes-pratiques","text":"Versionnez vos fichiers .tf avec git. Utilisez des workspaces pour g\u00e9rer plusieurs environnements (dev, prod). S\u00e9parez les variables sensibles (credentials) dans des fichiers non versionn\u00e9s. Relisez le plan ( terraform plan ) avant chaque apply . Utilisez des modules pour factoriser le code.","title":"Bonnes pratiques"},{"location":"DevOps/terraform/#ressources-utiles","text":"Documentation officielle Terraform Terraform Registry (modules) Best practices Terraform","title":"Ressources utiles"},{"location":"DevOps/test-charge/","text":"Faire des tests de charge avec k6 k6 est un outil open source moderne pour r\u00e9aliser des tests de charge et de performance sur des APIs ou des sites web. Il permet de simuler de nombreux utilisateurs virtuels, de mesurer la latence, le taux d\u2019erreur et d\u2019identifier les points de contention. Installation Sous Linux : sudo apt update sudo apt install -y gnupg2 ca-certificates curl -s https://dl.k6.io/key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/k6-archive-keyring.gpg echo \"deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main\" | sudo tee /etc/apt/sources.list.d/k6.list sudo apt update sudo apt install k6 Exemple de script de test Cr\u00e9ez un fichier script.js : import http from 'k6/http'; import { check, sleep } from 'k6'; export let options = { vus: 10, // nombre d'utilisateurs virtuels duration: '30s', // dur\u00e9e du test }; export default function () { let res = http.get('https://test-api.example.com/health'); check(res, { 'status is 200': (r) => r.status === 200, }); sleep(1); } Lancer un test de charge k6 run script.js Vous obtiendrez un rapport en temps r\u00e9el avec les m\u00e9triques principales : requ\u00eates/s, latence, taux d\u2019erreur, etc. Sc\u00e9narios avanc\u00e9s Augmenter progressivement la charge : export let options = { stages: [ { duration: '1m', target: 20 }, // mont\u00e9e en charge { duration: '3m', target: 20 }, // palier { duration: '1m', target: 0 }, // descente ], }; Tests sur endpoints prot\u00e9g\u00e9s : ajoutez des headers d\u2019authentification (Bearer, Basic, etc). Tests de POST : http.post('https://test-api.example.com/login', JSON.stringify({user: 'foo', pass: 'bar'}), { headers: { 'Content-Type': 'application/json' } }); Analyse des r\u00e9sultats Analysez les m\u00e9triques : latence moyenne, 95e percentile, taux d\u2019erreur. Exportez les r\u00e9sultats en JSON : k6 run --out json=r\u00e9sultats.json script.js Int\u00e9grez k6 dans vos pipelines CI/CD pour tester la robustesse \u00e0 chaque d\u00e9ploiement. Bonnes pratiques Commencez par des tests simples, puis complexifiez les sc\u00e9narios. Testez en environnement de pr\u00e9production pour \u00e9viter d\u2019impacter la prod. Surveillez les ressources du serveur cible pendant les tests (CPU, RAM, logs). Documentez vos scripts et r\u00e9sultats pour faciliter le suivi. Ressources utiles Documentation officielle k6 Exemples de scripts Int\u00e9gration CI/CD Automatiser le lancement des tests de charge Pour automatiser l\u2019ex\u00e9cution des tests de charge k6, vous pouvez int\u00e9grer le lancement dans vos scripts shell, Makefile ou pipelines CI/CD (GitLab CI, GitHub Actions, etc). Exemple avec un Makefile test-charge: k6 run script.js Lancez simplement : make test-charge Exemple avec GitLab CI Ajoutez un job dans .gitlab-ci.yml : test_performance: image: grafana/k6:latest script: - k6 run script.js only: - main Exemple avec GitHub Actions name: Test de charge k6 on: [push] jobs: k6: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - name: Installer k6 run: | sudo apt-get update && sudo apt-get install -y gnupg2 ca-certificates curl -s https://dl.k6.io/key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/k6-archive-keyring.gpg echo \"deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main\" | sudo tee /etc/apt/sources.list.d/k6.list sudo apt-get update && sudo apt-get install -y k6 - name: Lancer le test de charge run: k6 run script.js Automatiser les tests permet de garantir la performance \u00e0 chaque modification ou d\u00e9ploiement. Lancer des tests k6 avec helm test et r\u00e9cup\u00e9rer les r\u00e9sultats Helm permet d\u2019automatiser l\u2019ex\u00e9cution de tests de charge k6 lors du d\u00e9ploiement d\u2019un chart. Il suffit d\u2019ajouter un pod de test dans le dossier templates/tests/ de votre chart Helm : apiVersion: v1 kind: Pod metadata: name: \"k6-load-test\" annotations: \"helm.sh/hook\": test spec: containers: - name: k6 image: grafana/k6:latest command: [\"k6\", \"run\", \"/scripts/script.js\"] volumeMounts: - name: k6-scripts mountPath: /scripts restartPolicy: Never volumes: - name: k6-scripts configMap: name: k6-scripts Placez votre script k6 dans un ConfigMap nomm\u00e9 k6-scripts . Lancez les tests apr\u00e8s le d\u00e9ploiement : helm test mon-app R\u00e9cup\u00e9rez les logs du pod de test pour voir les r\u00e9sultats : kubectl logs pod/k6-load-test Cette m\u00e9thode permet d\u2019int\u00e9grer les tests de charge dans vos workflows Helm et d\u2019automatiser leur ex\u00e9cution \u00e0 chaque d\u00e9ploiement.","title":"Test de charge"},{"location":"DevOps/test-charge/#faire-des-tests-de-charge-avec-k6","text":"k6 est un outil open source moderne pour r\u00e9aliser des tests de charge et de performance sur des APIs ou des sites web. Il permet de simuler de nombreux utilisateurs virtuels, de mesurer la latence, le taux d\u2019erreur et d\u2019identifier les points de contention.","title":"Faire des tests de charge avec k6"},{"location":"DevOps/test-charge/#installation","text":"Sous Linux : sudo apt update sudo apt install -y gnupg2 ca-certificates curl -s https://dl.k6.io/key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/k6-archive-keyring.gpg echo \"deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main\" | sudo tee /etc/apt/sources.list.d/k6.list sudo apt update sudo apt install k6","title":"Installation"},{"location":"DevOps/test-charge/#exemple-de-script-de-test","text":"Cr\u00e9ez un fichier script.js : import http from 'k6/http'; import { check, sleep } from 'k6'; export let options = { vus: 10, // nombre d'utilisateurs virtuels duration: '30s', // dur\u00e9e du test }; export default function () { let res = http.get('https://test-api.example.com/health'); check(res, { 'status is 200': (r) => r.status === 200, }); sleep(1); }","title":"Exemple de script de test"},{"location":"DevOps/test-charge/#lancer-un-test-de-charge","text":"k6 run script.js Vous obtiendrez un rapport en temps r\u00e9el avec les m\u00e9triques principales : requ\u00eates/s, latence, taux d\u2019erreur, etc.","title":"Lancer un test de charge"},{"location":"DevOps/test-charge/#scenarios-avances","text":"Augmenter progressivement la charge : export let options = { stages: [ { duration: '1m', target: 20 }, // mont\u00e9e en charge { duration: '3m', target: 20 }, // palier { duration: '1m', target: 0 }, // descente ], }; Tests sur endpoints prot\u00e9g\u00e9s : ajoutez des headers d\u2019authentification (Bearer, Basic, etc). Tests de POST : http.post('https://test-api.example.com/login', JSON.stringify({user: 'foo', pass: 'bar'}), { headers: { 'Content-Type': 'application/json' } });","title":"Sc\u00e9narios avanc\u00e9s"},{"location":"DevOps/test-charge/#analyse-des-resultats","text":"Analysez les m\u00e9triques : latence moyenne, 95e percentile, taux d\u2019erreur. Exportez les r\u00e9sultats en JSON : k6 run --out json=r\u00e9sultats.json script.js Int\u00e9grez k6 dans vos pipelines CI/CD pour tester la robustesse \u00e0 chaque d\u00e9ploiement.","title":"Analyse des r\u00e9sultats"},{"location":"DevOps/test-charge/#bonnes-pratiques","text":"Commencez par des tests simples, puis complexifiez les sc\u00e9narios. Testez en environnement de pr\u00e9production pour \u00e9viter d\u2019impacter la prod. Surveillez les ressources du serveur cible pendant les tests (CPU, RAM, logs). Documentez vos scripts et r\u00e9sultats pour faciliter le suivi.","title":"Bonnes pratiques"},{"location":"DevOps/test-charge/#ressources-utiles","text":"Documentation officielle k6 Exemples de scripts Int\u00e9gration CI/CD","title":"Ressources utiles"},{"location":"DevOps/test-charge/#automatiser-le-lancement-des-tests-de-charge","text":"Pour automatiser l\u2019ex\u00e9cution des tests de charge k6, vous pouvez int\u00e9grer le lancement dans vos scripts shell, Makefile ou pipelines CI/CD (GitLab CI, GitHub Actions, etc).","title":"Automatiser le lancement des tests de charge"},{"location":"DevOps/test-charge/#exemple-avec-un-makefile","text":"test-charge: k6 run script.js Lancez simplement : make test-charge","title":"Exemple avec un Makefile"},{"location":"DevOps/test-charge/#exemple-avec-gitlab-ci","text":"Ajoutez un job dans .gitlab-ci.yml : test_performance: image: grafana/k6:latest script: - k6 run script.js only: - main","title":"Exemple avec GitLab CI"},{"location":"DevOps/test-charge/#exemple-avec-github-actions","text":"name: Test de charge k6 on: [push] jobs: k6: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - name: Installer k6 run: | sudo apt-get update && sudo apt-get install -y gnupg2 ca-certificates curl -s https://dl.k6.io/key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/k6-archive-keyring.gpg echo \"deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main\" | sudo tee /etc/apt/sources.list.d/k6.list sudo apt-get update && sudo apt-get install -y k6 - name: Lancer le test de charge run: k6 run script.js Automatiser les tests permet de garantir la performance \u00e0 chaque modification ou d\u00e9ploiement.","title":"Exemple avec GitHub Actions"},{"location":"DevOps/test-charge/#lancer-des-tests-k6-avec-helm-test-et-recuperer-les-resultats","text":"Helm permet d\u2019automatiser l\u2019ex\u00e9cution de tests de charge k6 lors du d\u00e9ploiement d\u2019un chart. Il suffit d\u2019ajouter un pod de test dans le dossier templates/tests/ de votre chart Helm : apiVersion: v1 kind: Pod metadata: name: \"k6-load-test\" annotations: \"helm.sh/hook\": test spec: containers: - name: k6 image: grafana/k6:latest command: [\"k6\", \"run\", \"/scripts/script.js\"] volumeMounts: - name: k6-scripts mountPath: /scripts restartPolicy: Never volumes: - name: k6-scripts configMap: name: k6-scripts Placez votre script k6 dans un ConfigMap nomm\u00e9 k6-scripts . Lancez les tests apr\u00e8s le d\u00e9ploiement : helm test mon-app R\u00e9cup\u00e9rez les logs du pod de test pour voir les r\u00e9sultats : kubectl logs pod/k6-load-test Cette m\u00e9thode permet d\u2019int\u00e9grer les tests de charge dans vos workflows Helm et d\u2019automatiser leur ex\u00e9cution \u00e0 chaque d\u00e9ploiement.","title":"Lancer des tests k6 avec helm test et r\u00e9cup\u00e9rer les r\u00e9sultats"},{"location":"backend/backend-golang/","text":"Cr\u00e9er et d\u00e9ployer un backend en go Initialisation du projet Pour d\u00e9marrer un projet Go, commencez par initialiser un module : go mod init github.com/mon-org/mon-backend Cr\u00e9ez un fichier principal main.go : package main import \"fmt\" func main() { fmt.Println(\"Hello, backend Go!\") } Installez les d\u00e9pendances n\u00e9cessaires (exemple avec Gin) : go get github.com/gin-gonic/gin Exemple d\u2019API REST avec Gin package main import ( \"github.com/gin-gonic/gin\" ) func main() { r := gin.Default() r.GET(\"/ping\", func(c *gin.Context) { c.JSON(200, gin.H{\"message\": \"pong\"}) }) r.Run() // \u00e9coute sur :8080 par d\u00e9faut } Lancez le serveur : go run main.go Cr\u00e9er une image Docker Cr\u00e9ez un fichier Dockerfile \u00e0 la racine du projet : FROM golang:1.22-alpine AS build WORKDIR /app COPY . . RUN go build -o app FROM alpine:latest WORKDIR /root/ COPY --from=build /app/app . EXPOSE 8080 CMD [\"./app\"] Construisez et lancez l\u2019image : docker build -t mon-backend-go . docker run -p 8080:8080 mon-backend-go D\u00e9ploiement (exemple avec Docker Compose) Cr\u00e9ez un fichier docker-compose.yml : version: '3.8' services: backend: build: . ports: - \"8080:8080\" Lancez le tout : docker-compose up --build D\u00e9ployer un backend Go sur Kubernetes (k8s) Pour d\u00e9ployer votre application Go sur Kubernetes, cr\u00e9ez un fichier de d\u00e9ploiement deployment.yaml : apiVersion: apps/v1 kind: Deployment metadata: name: go-backend spec: replicas: 2 selector: matchLabels: app: go-backend template: metadata: labels: app: go-backend spec: containers: - name: go-backend image: mon-backend-go:latest ports: - containerPort: 8080 env: - name: ENV value: \"production\" Exposez le service : apiVersion: v1 kind: Service metadata: name: go-backend-service spec: type: LoadBalancer selector: app: go-backend ports: - protocol: TCP port: 80 targetPort: 8080 D\u00e9ployez sur le cluster : kubectl apply -f deployment.yaml kubectl apply -f service.yaml Profiling et heap dump d\u2019un container Go sur k8s Go int\u00e8gre un outil de profiling tr\u00e8s puissant : pprof . Ajoutez-le \u00e0 votre application : import ( _ \"net/http/pprof\" \"log\" \"net/http\" ) func main() { go func() { log.Println(http.ListenAndServe(\"localhost:6060\", nil)) }() // ...votre code... } Exposez le port 6060 dans votre Dockerfile et dans le manifest k8s. Pour r\u00e9cup\u00e9rer un heap dump : kubectl port-forward <pod> 6060:6060 # Puis dans un autre terminal : curl http://localhost:6060/debug/pprof/heap > heap.out Analysez avec : go tool pprof heap.out Optimisation et bonnes pratiques avanc\u00e9es Utilisez pprof pour identifier les fuites m\u00e9moire ou les points chauds CPU. Ajoutez des m\u00e9triques Prometheus avec promhttp . Structurez votre projet avec /cmd , /pkg , /internal pour la maintenabilit\u00e9. Utilisez des contextes ( context.Context ) pour g\u00e9rer les timeouts et annulations. Ajoutez des probes liveness/readiness dans vos manifests k8s : livenessProbe: httpGet: path: /ping port: 8080 initialDelaySeconds: 5 periodSeconds: 10 readinessProbe: httpGet: path: /ping port: 8080 initialDelaySeconds: 2 periodSeconds: 5 Ressources utiles La doc officielle Go Gin Web Framework Go Docker Best Practices Go pprof guide Kubernetes Go example Prometheus Go client","title":"Go"},{"location":"backend/backend-golang/#creer-et-deployer-un-backend-en-go","text":"","title":"Cr\u00e9er et d\u00e9ployer un backend en go"},{"location":"backend/backend-golang/#initialisation-du-projet","text":"Pour d\u00e9marrer un projet Go, commencez par initialiser un module : go mod init github.com/mon-org/mon-backend Cr\u00e9ez un fichier principal main.go : package main import \"fmt\" func main() { fmt.Println(\"Hello, backend Go!\") } Installez les d\u00e9pendances n\u00e9cessaires (exemple avec Gin) : go get github.com/gin-gonic/gin","title":"Initialisation du projet"},{"location":"backend/backend-golang/#exemple-dapi-rest-avec-gin","text":"package main import ( \"github.com/gin-gonic/gin\" ) func main() { r := gin.Default() r.GET(\"/ping\", func(c *gin.Context) { c.JSON(200, gin.H{\"message\": \"pong\"}) }) r.Run() // \u00e9coute sur :8080 par d\u00e9faut } Lancez le serveur : go run main.go","title":"Exemple d\u2019API REST avec Gin"},{"location":"backend/backend-golang/#creer-une-image-docker","text":"Cr\u00e9ez un fichier Dockerfile \u00e0 la racine du projet : FROM golang:1.22-alpine AS build WORKDIR /app COPY . . RUN go build -o app FROM alpine:latest WORKDIR /root/ COPY --from=build /app/app . EXPOSE 8080 CMD [\"./app\"] Construisez et lancez l\u2019image : docker build -t mon-backend-go . docker run -p 8080:8080 mon-backend-go","title":"Cr\u00e9er une image Docker"},{"location":"backend/backend-golang/#deploiement-exemple-avec-docker-compose","text":"Cr\u00e9ez un fichier docker-compose.yml : version: '3.8' services: backend: build: . ports: - \"8080:8080\" Lancez le tout : docker-compose up --build","title":"D\u00e9ploiement (exemple avec Docker Compose)"},{"location":"backend/backend-golang/#deployer-un-backend-go-sur-kubernetes-k8s","text":"Pour d\u00e9ployer votre application Go sur Kubernetes, cr\u00e9ez un fichier de d\u00e9ploiement deployment.yaml : apiVersion: apps/v1 kind: Deployment metadata: name: go-backend spec: replicas: 2 selector: matchLabels: app: go-backend template: metadata: labels: app: go-backend spec: containers: - name: go-backend image: mon-backend-go:latest ports: - containerPort: 8080 env: - name: ENV value: \"production\" Exposez le service : apiVersion: v1 kind: Service metadata: name: go-backend-service spec: type: LoadBalancer selector: app: go-backend ports: - protocol: TCP port: 80 targetPort: 8080 D\u00e9ployez sur le cluster : kubectl apply -f deployment.yaml kubectl apply -f service.yaml","title":"D\u00e9ployer un backend Go sur Kubernetes (k8s)"},{"location":"backend/backend-golang/#profiling-et-heap-dump-dun-container-go-sur-k8s","text":"Go int\u00e8gre un outil de profiling tr\u00e8s puissant : pprof . Ajoutez-le \u00e0 votre application : import ( _ \"net/http/pprof\" \"log\" \"net/http\" ) func main() { go func() { log.Println(http.ListenAndServe(\"localhost:6060\", nil)) }() // ...votre code... } Exposez le port 6060 dans votre Dockerfile et dans le manifest k8s. Pour r\u00e9cup\u00e9rer un heap dump : kubectl port-forward <pod> 6060:6060 # Puis dans un autre terminal : curl http://localhost:6060/debug/pprof/heap > heap.out Analysez avec : go tool pprof heap.out","title":"Profiling et heap dump d\u2019un container Go sur k8s"},{"location":"backend/backend-golang/#optimisation-et-bonnes-pratiques-avancees","text":"Utilisez pprof pour identifier les fuites m\u00e9moire ou les points chauds CPU. Ajoutez des m\u00e9triques Prometheus avec promhttp . Structurez votre projet avec /cmd , /pkg , /internal pour la maintenabilit\u00e9. Utilisez des contextes ( context.Context ) pour g\u00e9rer les timeouts et annulations. Ajoutez des probes liveness/readiness dans vos manifests k8s : livenessProbe: httpGet: path: /ping port: 8080 initialDelaySeconds: 5 periodSeconds: 10 readinessProbe: httpGet: path: /ping port: 8080 initialDelaySeconds: 2 periodSeconds: 5","title":"Optimisation et bonnes pratiques avanc\u00e9es"},{"location":"backend/backend-golang/#ressources-utiles","text":"La doc officielle Go Gin Web Framework Go Docker Best Practices Go pprof guide Kubernetes Go example Prometheus Go client","title":"Ressources utiles"},{"location":"backend/backend-java/","text":"G\u00e9n\u00e9rer rapidement un backend en Java G\u00e9n\u00e9rer un projet Spring Boot avec Spring Initializer Se rendre sur https://start.spring.io/ . Choisissez les options suivantes : - Project : Gradle Project ou Maven Project - Language : Java - Spring Boot : version stable recommand\u00e9e - Group : com.example - Artifact : demo - Dependencies : Spring Web, Spring Data JPA, H2 Database (ou autres selon vos besoins) T\u00e9l\u00e9chargez et d\u00e9compressez le projet, puis ouvrez-le dans votre IDE. Exemple de contr\u00f4leur REST @RestController @RequestMapping(\"/api\") public class HelloController { @GetMapping(\"/hello\") public String hello() { return \"Hello, Spring Boot!\"; } } Lancez l\u2019application : ./gradlew bootRun Ou avec Maven : ./mvnw spring-boot:run Cr\u00e9er une image Docker Pour cr\u00e9er une image Docker compatible avec une application Spring, il faut surcharger l'image principale de gradle pour pouvoir g\u00e9n\u00e9rer le livrable et ensuite le copi\u00e9 et utilis\u00e9 l'image du JDK GraalVM pour le runtime. FROM gradle:8.1.1-jdk17-alpine AS build COPY --chown=gradle:gradle . /home/gradle/src WORKDIR /home/gradle/src RUN gradle build --no-daemon FROM ghcr.io/graalvm/jdk-community:17-ol9 EXPOSE 8080 COPY --from=build /home/gradle/src/build/libs/*.jar spring-boot-application.jar ENTRYPOINT [\"java\", \"-XX:+UnlockExperimentalVMOptions\", \"-Djava.security.egd=file:/dev/./urandom\",\"-jar\",\"spring-boot-application.jar\"] Construction et ex\u00e9cution de l\u2019image docker build -t spring-backend . docker run -p 8080:8080 spring-backend D\u00e9ployer un backend en Spring Boot sur AWS Pour d\u00e9ployer sur AWS, plusieurs options existent : - Elastic Beanstalk : d\u00e9ploiement simplifi\u00e9 d\u2019applications Java. - ECS (Elastic Container Service) : pour d\u00e9ployer des conteneurs Docker. - EKS (Elastic Kubernetes Service) : pour des architectures plus complexes. Exemple de d\u00e9ploiement sur Elastic Beanstalk Installez l\u2019interface AWS CLI et configurez vos identifiants. Initialisez un environnement Beanstalk : eb init -p java-17 spring-backend eb create spring-backend-env eb deploy Pour Docker, utilisez un fichier Dockerrun.aws.json ou d\u00e9ployez l\u2019image sur ECR puis sur ECS. Faire un heap dump d'un container light java d\u00e9ploy\u00e9 sur k8s On utilise l'utilitaire jcmd packag\u00e9 avec tout openjdk. Quand on a tr\u00e8s peu d'outils \u00e0 disposition on devient cr\u00e9atif. Pour copier des fichiers vers l'ext\u00e9rieur il faut avoir le binaire tar d'install\u00e9 dans le container pour pouvoir executer la commande kubectl cp <source> <destination> . Quand il n'est pas install\u00e9, on peut toujours utiliser la sortie standard et piper \u00e7a dans un fichier. On encode en base64 pour \u00e9viter de corrompre le fichier avec un mauvais affichage. kubectl exec <pod> -- bash -c \"jcmd 1 GC.run\" # Pour clean avant de record la m\u00e9moire sleep 10 kubectl exec <pod> -- bash -c \"jcmd 1 GC.heap_dump filename=/tmp/dump.hprof\" kubectl exec <pod> -- bash -c \"base64 /tmp/dump.hprof > /tmp/dump64.hprof\" kubectl exec <pod> -- bash -c \"cat /tmp/dump64.hprof\" | base64 -d > ~/dump.hprof Il ne vous reste plus qu'\u00e0 le loader dans VisualVM ou JProfiler. Faire un recording JFR d'un container light java d\u00e9ploy\u00e9 sur k8s M\u00eame process pour le transfert de fichier, il n'y a que la commande qui change. kubectl exec <pod> -- bash -c \"jcmd 1 JFR.start duration=1h delay=5s filename=/tmp/recording.jfr\" # Maintenant on fait nos op\u00e9rations pendant une heure kubectl exec <pod> -- bash -c \"base64 /tmp/recording.jfr > /tmp/recording64.jfr\" kubectl exec <pod> -- bash -c \"cat /tmp/recording64.jfr\" | base64 -d > ~/recording.jfr Et ensuite on le load dans VisualVM ou JProfiler. Bonnes pratiques Utilisez des variables d\u2019environnement pour la configuration (application.properties ou application.yml). Ajoutez des tests unitaires avec JUnit et MockMvc. Utilisez des profils Spring pour g\u00e9rer diff\u00e9rents environnements (dev, prod, test). Surveillez votre application avec Actuator et des outils APM (Elastic, Datadog, etc). Ressources utiles Documentation officielle Spring Boot Spring Initializr D\u00e9ployer sur AWS Elastic Beanstalk VisualVM JProfiler","title":"Java"},{"location":"backend/backend-java/#generer-rapidement-un-backend-en-java","text":"","title":"G\u00e9n\u00e9rer rapidement un backend en Java"},{"location":"backend/backend-java/#generer-un-projet-spring-boot-avec-spring-initializer","text":"Se rendre sur https://start.spring.io/ . Choisissez les options suivantes : - Project : Gradle Project ou Maven Project - Language : Java - Spring Boot : version stable recommand\u00e9e - Group : com.example - Artifact : demo - Dependencies : Spring Web, Spring Data JPA, H2 Database (ou autres selon vos besoins) T\u00e9l\u00e9chargez et d\u00e9compressez le projet, puis ouvrez-le dans votre IDE.","title":"G\u00e9n\u00e9rer un projet Spring Boot avec Spring Initializer"},{"location":"backend/backend-java/#exemple-de-controleur-rest","text":"@RestController @RequestMapping(\"/api\") public class HelloController { @GetMapping(\"/hello\") public String hello() { return \"Hello, Spring Boot!\"; } } Lancez l\u2019application : ./gradlew bootRun Ou avec Maven : ./mvnw spring-boot:run","title":"Exemple de contr\u00f4leur REST"},{"location":"backend/backend-java/#creer-une-image-docker","text":"Pour cr\u00e9er une image Docker compatible avec une application Spring, il faut surcharger l'image principale de gradle pour pouvoir g\u00e9n\u00e9rer le livrable et ensuite le copi\u00e9 et utilis\u00e9 l'image du JDK GraalVM pour le runtime. FROM gradle:8.1.1-jdk17-alpine AS build COPY --chown=gradle:gradle . /home/gradle/src WORKDIR /home/gradle/src RUN gradle build --no-daemon FROM ghcr.io/graalvm/jdk-community:17-ol9 EXPOSE 8080 COPY --from=build /home/gradle/src/build/libs/*.jar spring-boot-application.jar ENTRYPOINT [\"java\", \"-XX:+UnlockExperimentalVMOptions\", \"-Djava.security.egd=file:/dev/./urandom\",\"-jar\",\"spring-boot-application.jar\"]","title":"Cr\u00e9er une image Docker"},{"location":"backend/backend-java/#construction-et-execution-de-limage","text":"docker build -t spring-backend . docker run -p 8080:8080 spring-backend","title":"Construction et ex\u00e9cution de l\u2019image"},{"location":"backend/backend-java/#deployer-un-backend-en-spring-boot-sur-aws","text":"Pour d\u00e9ployer sur AWS, plusieurs options existent : - Elastic Beanstalk : d\u00e9ploiement simplifi\u00e9 d\u2019applications Java. - ECS (Elastic Container Service) : pour d\u00e9ployer des conteneurs Docker. - EKS (Elastic Kubernetes Service) : pour des architectures plus complexes.","title":"D\u00e9ployer un backend en Spring Boot sur AWS"},{"location":"backend/backend-java/#exemple-de-deploiement-sur-elastic-beanstalk","text":"Installez l\u2019interface AWS CLI et configurez vos identifiants. Initialisez un environnement Beanstalk : eb init -p java-17 spring-backend eb create spring-backend-env eb deploy Pour Docker, utilisez un fichier Dockerrun.aws.json ou d\u00e9ployez l\u2019image sur ECR puis sur ECS.","title":"Exemple de d\u00e9ploiement sur Elastic Beanstalk"},{"location":"backend/backend-java/#faire-un-heap-dump-dun-container-light-java-deploye-sur-k8s","text":"On utilise l'utilitaire jcmd packag\u00e9 avec tout openjdk. Quand on a tr\u00e8s peu d'outils \u00e0 disposition on devient cr\u00e9atif. Pour copier des fichiers vers l'ext\u00e9rieur il faut avoir le binaire tar d'install\u00e9 dans le container pour pouvoir executer la commande kubectl cp <source> <destination> . Quand il n'est pas install\u00e9, on peut toujours utiliser la sortie standard et piper \u00e7a dans un fichier. On encode en base64 pour \u00e9viter de corrompre le fichier avec un mauvais affichage. kubectl exec <pod> -- bash -c \"jcmd 1 GC.run\" # Pour clean avant de record la m\u00e9moire sleep 10 kubectl exec <pod> -- bash -c \"jcmd 1 GC.heap_dump filename=/tmp/dump.hprof\" kubectl exec <pod> -- bash -c \"base64 /tmp/dump.hprof > /tmp/dump64.hprof\" kubectl exec <pod> -- bash -c \"cat /tmp/dump64.hprof\" | base64 -d > ~/dump.hprof Il ne vous reste plus qu'\u00e0 le loader dans VisualVM ou JProfiler.","title":"Faire un heap dump d'un container light java d\u00e9ploy\u00e9 sur k8s"},{"location":"backend/backend-java/#faire-un-recording-jfr-dun-container-light-java-deploye-sur-k8s","text":"M\u00eame process pour le transfert de fichier, il n'y a que la commande qui change. kubectl exec <pod> -- bash -c \"jcmd 1 JFR.start duration=1h delay=5s filename=/tmp/recording.jfr\" # Maintenant on fait nos op\u00e9rations pendant une heure kubectl exec <pod> -- bash -c \"base64 /tmp/recording.jfr > /tmp/recording64.jfr\" kubectl exec <pod> -- bash -c \"cat /tmp/recording64.jfr\" | base64 -d > ~/recording.jfr Et ensuite on le load dans VisualVM ou JProfiler.","title":"Faire un recording JFR d'un container light java d\u00e9ploy\u00e9 sur k8s"},{"location":"backend/backend-java/#bonnes-pratiques","text":"Utilisez des variables d\u2019environnement pour la configuration (application.properties ou application.yml). Ajoutez des tests unitaires avec JUnit et MockMvc. Utilisez des profils Spring pour g\u00e9rer diff\u00e9rents environnements (dev, prod, test). Surveillez votre application avec Actuator et des outils APM (Elastic, Datadog, etc).","title":"Bonnes pratiques"},{"location":"backend/backend-java/#ressources-utiles","text":"Documentation officielle Spring Boot Spring Initializr D\u00e9ployer sur AWS Elastic Beanstalk VisualVM JProfiler","title":"Ressources utiles"},{"location":"data/postgres/","text":"Entretien d'une base PostgreSQL L\u2019entretien r\u00e9gulier d\u2019une base PostgreSQL est essentiel pour garantir de bonnes performances, \u00e9viter la saturation du disque et assurer la fiabilit\u00e9 des donn\u00e9es. Voici les principales op\u00e9rations et bonnes pratiques \u00e0 conna\u00eetre. R\u00e9cup\u00e9ration de l'espace disque apr\u00e8s suppression Quand une ligne est supprim\u00e9e, l'espace disque n'est pas directement rendue. Il y a un m\u00e9chanisme de d\u00e9fragmentation de la base s'appelant VACUUM permettant de lib\u00e9rer l'allocation disque Si vous ne poss\u00e8dez pas ou peu de place disque de base, les processus d'autovacuum ne se d\u00e9clencheront pas avant 200.000.000 transactions SQL. C'est beaucoup de transactions et pour la plupart des applications, ce seuil ne sera jamais atteint. Voici la requ\u00eate permettant de r\u00e9cup\u00e9rer les tables concern\u00e9es qui n\u00e9cessite une lib\u00e9ration m\u00e9moire SELECT relname FROM pg_stat_user_tables WHERE n_dead_tup > 0 Cette requ\u00eate r\u00e9cup\u00e9re tous les noms des tables ayant des lignes de donn\u00e9es mortes. Il vous suffit par la suite d'effectuer VACUUM ANALYSE <table_name> Les types de VACUUM Il existe 4 types de vacuum. Le VACUUM classique, il vient lancer un requ\u00eate de nettoyage. Le VACUUM FULL , \u00e0 d\u00e9conseiller si c'est une base en production car celui vient lock toutes les transactions sur la table ou la base cibl\u00e9e par le vacuum. Le VACUUM ANALYSE , il permet en m\u00eame temps de recalculer les donn\u00e9es inscrites dans les tables techniques du serveur PostgreSQL. Le VACUUM VERBOSE , affichant plus de d\u00e9tail concernant l'op\u00e9ration. Surveillance de l\u2019activit\u00e9 et de la sant\u00e9 de la base PostgreSQL fournit de nombreuses vues pour surveiller l\u2019\u00e9tat de la base : pg_stat_activity : affiche les connexions et requ\u00eates en cours. pg_stat_user_tables : donne des statistiques sur les tables (nombre de lignes mortes, etc). pg_locks : liste les verrous actifs. Exemple pour surveiller les requ\u00eates longues : SELECT pid, now() - pg_stat_activity.query_start AS duree, query FROM pg_stat_activity WHERE state = 'active' AND now() - pg_stat_activity.query_start > interval '5 minutes'; Gestion des index Les index acc\u00e9l\u00e8rent les requ\u00eates mais doivent \u00eatre entretenus : - V\u00e9rifiez les index inutilis\u00e9s : SELECT * FROM pg_stat_user_indexes WHERE idx_scan = 0; - Recr\u00e9ez les index fragment\u00e9s : REINDEX INDEX nom_de_l_index; - Supprimez les index obsol\u00e8tes pour \u00e9conomiser de l\u2019espace disque. Sauvegarde et restauration Utilisez pg_dump pour sauvegarder une base : pg_dump -U utilisateur -h hote -Fc nom_base > sauvegarde.dump Restaurez avec pg_restore : pg_restore -U utilisateur -h hote -d nouvelle_base sauvegarde.dump Automatisez les sauvegardes r\u00e9guli\u00e8res (cron, scripts, outils comme pgBackRest ). Bonnes pratiques Planifiez des VACUUM r\u00e9guliers si l\u2019autovacuum n\u2019est pas suffisant. Surveillez l\u2019espace disque et la croissance des tables. Mettez \u00e0 jour PostgreSQL pour b\u00e9n\u00e9ficier des derni\u00e8res optimisations et correctifs de s\u00e9curit\u00e9. Documentez les op\u00e9rations de maintenance dans un journal ou un outil de suivi. Ressources utiles Documentation officielle PostgreSQL pg_stat_statements pour l\u2019analyse des requ\u00eates lentes pgBackRest pour la sauvegarde avanc\u00e9e","title":"PostgreSQL"},{"location":"data/postgres/#entretien-dune-base-postgresql","text":"L\u2019entretien r\u00e9gulier d\u2019une base PostgreSQL est essentiel pour garantir de bonnes performances, \u00e9viter la saturation du disque et assurer la fiabilit\u00e9 des donn\u00e9es. Voici les principales op\u00e9rations et bonnes pratiques \u00e0 conna\u00eetre.","title":"Entretien d'une base PostgreSQL"},{"location":"data/postgres/#recuperation-de-lespace-disque-apres-suppression","text":"Quand une ligne est supprim\u00e9e, l'espace disque n'est pas directement rendue. Il y a un m\u00e9chanisme de d\u00e9fragmentation de la base s'appelant VACUUM permettant de lib\u00e9rer l'allocation disque Si vous ne poss\u00e8dez pas ou peu de place disque de base, les processus d'autovacuum ne se d\u00e9clencheront pas avant 200.000.000 transactions SQL. C'est beaucoup de transactions et pour la plupart des applications, ce seuil ne sera jamais atteint. Voici la requ\u00eate permettant de r\u00e9cup\u00e9rer les tables concern\u00e9es qui n\u00e9cessite une lib\u00e9ration m\u00e9moire SELECT relname FROM pg_stat_user_tables WHERE n_dead_tup > 0 Cette requ\u00eate r\u00e9cup\u00e9re tous les noms des tables ayant des lignes de donn\u00e9es mortes. Il vous suffit par la suite d'effectuer VACUUM ANALYSE <table_name>","title":"R\u00e9cup\u00e9ration de l'espace disque apr\u00e8s suppression"},{"location":"data/postgres/#les-types-de-vacuum","text":"Il existe 4 types de vacuum. Le VACUUM classique, il vient lancer un requ\u00eate de nettoyage. Le VACUUM FULL , \u00e0 d\u00e9conseiller si c'est une base en production car celui vient lock toutes les transactions sur la table ou la base cibl\u00e9e par le vacuum. Le VACUUM ANALYSE , il permet en m\u00eame temps de recalculer les donn\u00e9es inscrites dans les tables techniques du serveur PostgreSQL. Le VACUUM VERBOSE , affichant plus de d\u00e9tail concernant l'op\u00e9ration.","title":"Les types de VACUUM"},{"location":"data/postgres/#surveillance-de-lactivite-et-de-la-sante-de-la-base","text":"PostgreSQL fournit de nombreuses vues pour surveiller l\u2019\u00e9tat de la base : pg_stat_activity : affiche les connexions et requ\u00eates en cours. pg_stat_user_tables : donne des statistiques sur les tables (nombre de lignes mortes, etc). pg_locks : liste les verrous actifs. Exemple pour surveiller les requ\u00eates longues : SELECT pid, now() - pg_stat_activity.query_start AS duree, query FROM pg_stat_activity WHERE state = 'active' AND now() - pg_stat_activity.query_start > interval '5 minutes';","title":"Surveillance de l\u2019activit\u00e9 et de la sant\u00e9 de la base"},{"location":"data/postgres/#gestion-des-index","text":"Les index acc\u00e9l\u00e8rent les requ\u00eates mais doivent \u00eatre entretenus : - V\u00e9rifiez les index inutilis\u00e9s : SELECT * FROM pg_stat_user_indexes WHERE idx_scan = 0; - Recr\u00e9ez les index fragment\u00e9s : REINDEX INDEX nom_de_l_index; - Supprimez les index obsol\u00e8tes pour \u00e9conomiser de l\u2019espace disque.","title":"Gestion des index"},{"location":"data/postgres/#sauvegarde-et-restauration","text":"Utilisez pg_dump pour sauvegarder une base : pg_dump -U utilisateur -h hote -Fc nom_base > sauvegarde.dump Restaurez avec pg_restore : pg_restore -U utilisateur -h hote -d nouvelle_base sauvegarde.dump Automatisez les sauvegardes r\u00e9guli\u00e8res (cron, scripts, outils comme pgBackRest ).","title":"Sauvegarde et restauration"},{"location":"data/postgres/#bonnes-pratiques","text":"Planifiez des VACUUM r\u00e9guliers si l\u2019autovacuum n\u2019est pas suffisant. Surveillez l\u2019espace disque et la croissance des tables. Mettez \u00e0 jour PostgreSQL pour b\u00e9n\u00e9ficier des derni\u00e8res optimisations et correctifs de s\u00e9curit\u00e9. Documentez les op\u00e9rations de maintenance dans un journal ou un outil de suivi.","title":"Bonnes pratiques"},{"location":"data/postgres/#ressources-utiles","text":"Documentation officielle PostgreSQL pg_stat_statements pour l\u2019analyse des requ\u00eates lentes pgBackRest pour la sauvegarde avanc\u00e9e","title":"Ressources utiles"},{"location":"data/sql-joints/","text":"Jointures SQL Il y a plusieurs types de jointures que l'on peut faire lorsque deux ou plusieurs tables sont en relation. Il est facile de vite les confondre. C'est pourquoi j'\u00e9cris cette note pour \u00e9viter que cela m'arrive \u00e0 l'avenir. Voici la liste des diff\u00e9rentes techniques de jointure qui sont utilis\u00e9es : INNER JOIN : jointure interne pour retourner les enregistrements quand la condition est vraie dans les 2 tables. C\u2019est l\u2019une des jointures les plus communes. CROSS JOIN : jointure crois\u00e9e permettant de faire le produit cart\u00e9sien de 2 tables. En d\u2019autres mots, permet de joindre chaque ligne d\u2019une table avec chaque ligne d\u2019une seconde table. Attention, le nombre de r\u00e9sultats est en g\u00e9n\u00e9ral tr\u00e8s \u00e9lev\u00e9. LEFT JOIN (ou LEFT OUTER JOIN) : jointure externe pour retourner tous les enregistrements de la table de gauche (LEFT = gauche) m\u00eame si la condition n\u2019est pas v\u00e9rifi\u00e9e dans l\u2019autre table. RIGHT JOIN (ou RIGHT OUTER JOIN) : jointure externe pour retourner tous les enregistrements de la table de droite (RIGHT = droite) m\u00eame si la condition n\u2019est pas v\u00e9rifi\u00e9e dans l\u2019autre table. FULL JOIN (ou FULL OUTER JOIN) : jointure externe pour retourner les r\u00e9sultats quand la condition est vraie dans au moins une des 2 tables. SELF JOIN : permet d\u2019effectuer une jointure d\u2019une table avec elle-m\u00eame comme si c\u2019\u00e9tait une autre table. NATURAL JOIN : jointure naturelle entre 2 tables s\u2019il y a au moins une colonne qui porte le m\u00eame nom entre les 2 tables SQL. Exemples pratiques Supposons deux tables simples : -- Table utilisateurs CREATE TABLE utilisateurs ( id INT PRIMARY KEY, nom VARCHAR(50) ); -- Table commandes CREATE TABLE commandes ( id INT PRIMARY KEY, utilisateur_id INT, montant DECIMAL(10,2) ); INNER JOIN SELECT u.nom, c.montant FROM utilisateurs u INNER JOIN commandes c ON u.id = c.utilisateur_id; Retourne uniquement les utilisateurs ayant pass\u00e9 au moins une commande. LEFT JOIN SELECT u.nom, c.montant FROM utilisateurs u LEFT JOIN commandes c ON u.id = c.utilisateur_id; Retourne tous les utilisateurs, m\u00eame ceux sans commande (montant sera NULL). RIGHT JOIN SELECT u.nom, c.montant FROM utilisateurs u RIGHT JOIN commandes c ON u.id = c.utilisateur_id; Retourne toutes les commandes, m\u00eame si aucun utilisateur correspondant n\u2019existe (rare mais possible si donn\u00e9es orphelines). FULL OUTER JOIN SELECT u.nom, c.montant FROM utilisateurs u FULL OUTER JOIN commandes c ON u.id = c.utilisateur_id; Retourne tous les utilisateurs et toutes les commandes, m\u00eame s\u2019il n\u2019y a pas de correspondance. CROSS JOIN SELECT u.nom, c.montant FROM utilisateurs u CROSS JOIN commandes c; Produit cart\u00e9sien : chaque utilisateur est associ\u00e9 \u00e0 chaque commande. SELF JOIN SELECT a.nom AS nom1, b.nom AS nom2 FROM utilisateurs a INNER JOIN utilisateurs b ON a.id <> b.id; Exemple : trouver toutes les paires d\u2019utilisateurs diff\u00e9rents. NATURAL JOIN Supposons deux tables ayant une colonne commune id : SELECT * FROM table1 NATURAL JOIN table2; La jointure se fait automatiquement sur les colonnes de m\u00eame nom. Conseils et bonnes pratiques Pr\u00e9cisez toujours les conditions de jointure pour \u00e9viter les produits cart\u00e9siens involontaires. Utilisez des alias pour plus de lisibilit\u00e9. V\u00e9rifiez la cardinalit\u00e9 des r\u00e9sultats pour \u00e9viter les doublons inattendus. Testez vos requ\u00eates sur un sous-ensemble de donn\u00e9es avant de les ex\u00e9cuter en production. Ressources utiles SQL Joins Visualizer W3Schools SQL JOINs","title":"Jointures SQL"},{"location":"data/sql-joints/#jointures-sql","text":"Il y a plusieurs types de jointures que l'on peut faire lorsque deux ou plusieurs tables sont en relation. Il est facile de vite les confondre. C'est pourquoi j'\u00e9cris cette note pour \u00e9viter que cela m'arrive \u00e0 l'avenir. Voici la liste des diff\u00e9rentes techniques de jointure qui sont utilis\u00e9es : INNER JOIN : jointure interne pour retourner les enregistrements quand la condition est vraie dans les 2 tables. C\u2019est l\u2019une des jointures les plus communes. CROSS JOIN : jointure crois\u00e9e permettant de faire le produit cart\u00e9sien de 2 tables. En d\u2019autres mots, permet de joindre chaque ligne d\u2019une table avec chaque ligne d\u2019une seconde table. Attention, le nombre de r\u00e9sultats est en g\u00e9n\u00e9ral tr\u00e8s \u00e9lev\u00e9. LEFT JOIN (ou LEFT OUTER JOIN) : jointure externe pour retourner tous les enregistrements de la table de gauche (LEFT = gauche) m\u00eame si la condition n\u2019est pas v\u00e9rifi\u00e9e dans l\u2019autre table. RIGHT JOIN (ou RIGHT OUTER JOIN) : jointure externe pour retourner tous les enregistrements de la table de droite (RIGHT = droite) m\u00eame si la condition n\u2019est pas v\u00e9rifi\u00e9e dans l\u2019autre table. FULL JOIN (ou FULL OUTER JOIN) : jointure externe pour retourner les r\u00e9sultats quand la condition est vraie dans au moins une des 2 tables. SELF JOIN : permet d\u2019effectuer une jointure d\u2019une table avec elle-m\u00eame comme si c\u2019\u00e9tait une autre table. NATURAL JOIN : jointure naturelle entre 2 tables s\u2019il y a au moins une colonne qui porte le m\u00eame nom entre les 2 tables SQL.","title":"Jointures SQL"},{"location":"data/sql-joints/#exemples-pratiques","text":"Supposons deux tables simples : -- Table utilisateurs CREATE TABLE utilisateurs ( id INT PRIMARY KEY, nom VARCHAR(50) ); -- Table commandes CREATE TABLE commandes ( id INT PRIMARY KEY, utilisateur_id INT, montant DECIMAL(10,2) );","title":"Exemples pratiques"},{"location":"data/sql-joints/#inner-join","text":"SELECT u.nom, c.montant FROM utilisateurs u INNER JOIN commandes c ON u.id = c.utilisateur_id; Retourne uniquement les utilisateurs ayant pass\u00e9 au moins une commande.","title":"INNER JOIN"},{"location":"data/sql-joints/#left-join","text":"SELECT u.nom, c.montant FROM utilisateurs u LEFT JOIN commandes c ON u.id = c.utilisateur_id; Retourne tous les utilisateurs, m\u00eame ceux sans commande (montant sera NULL).","title":"LEFT JOIN"},{"location":"data/sql-joints/#right-join","text":"SELECT u.nom, c.montant FROM utilisateurs u RIGHT JOIN commandes c ON u.id = c.utilisateur_id; Retourne toutes les commandes, m\u00eame si aucun utilisateur correspondant n\u2019existe (rare mais possible si donn\u00e9es orphelines).","title":"RIGHT JOIN"},{"location":"data/sql-joints/#full-outer-join","text":"SELECT u.nom, c.montant FROM utilisateurs u FULL OUTER JOIN commandes c ON u.id = c.utilisateur_id; Retourne tous les utilisateurs et toutes les commandes, m\u00eame s\u2019il n\u2019y a pas de correspondance.","title":"FULL OUTER JOIN"},{"location":"data/sql-joints/#cross-join","text":"SELECT u.nom, c.montant FROM utilisateurs u CROSS JOIN commandes c; Produit cart\u00e9sien : chaque utilisateur est associ\u00e9 \u00e0 chaque commande.","title":"CROSS JOIN"},{"location":"data/sql-joints/#self-join","text":"SELECT a.nom AS nom1, b.nom AS nom2 FROM utilisateurs a INNER JOIN utilisateurs b ON a.id <> b.id; Exemple : trouver toutes les paires d\u2019utilisateurs diff\u00e9rents.","title":"SELF JOIN"},{"location":"data/sql-joints/#natural-join","text":"Supposons deux tables ayant une colonne commune id : SELECT * FROM table1 NATURAL JOIN table2; La jointure se fait automatiquement sur les colonnes de m\u00eame nom.","title":"NATURAL JOIN"},{"location":"data/sql-joints/#conseils-et-bonnes-pratiques","text":"Pr\u00e9cisez toujours les conditions de jointure pour \u00e9viter les produits cart\u00e9siens involontaires. Utilisez des alias pour plus de lisibilit\u00e9. V\u00e9rifiez la cardinalit\u00e9 des r\u00e9sultats pour \u00e9viter les doublons inattendus. Testez vos requ\u00eates sur un sous-ensemble de donn\u00e9es avant de les ex\u00e9cuter en production.","title":"Conseils et bonnes pratiques"},{"location":"data/sql-joints/#ressources-utiles","text":"SQL Joins Visualizer W3Schools SQL JOINs","title":"Ressources utiles"},{"location":"environnement-de-travail/chrome/","text":"Mettre \u00e0 jour Google Chrome sur linux Chrome n'ayant pas de solution cl\u00e9 en main pour se mettre \u00e0 jour de mani\u00e8re autonome sur linux, il faut le faire en ligne de commande. T\u00e9l\u00e9chargement du paquet Il faut en premier lieu r\u00e9cup\u00e9rer le nouveau paquet : wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb Cette URL varie rarement. Elle permet de t\u00e9l\u00e9charger la derni\u00e8re version stable de Chrome. Installation du paquet Par la suite il vous suffit juste de l'installer avec le gestionnaire de paquet bas niveau dpkg qui va venir surcharger les sources de votre Chrome install\u00e9 localement avec le nouveau paquet. sudo dpkg -i google-chrome-stable_current_amd64.deb Si des d\u00e9pendances sont manquantes, corrigez-les avec : sudo apt-get install -f Nettoyage Et enfin, n'oubliez pas de nettoyer ! rm google-chrome-stable_current_amd64.deb V\u00e9rifier la version install\u00e9e Pour v\u00e9rifier que la mise \u00e0 jour a bien \u00e9t\u00e9 prise en compte : google-chrome --version Astuce : mise \u00e0 jour via le d\u00e9p\u00f4t officiel Vous pouvez aussi ajouter le d\u00e9p\u00f4t officiel Google Chrome pour b\u00e9n\u00e9ficier des mises \u00e0 jour via apt : wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add - echo 'deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main' | sudo tee /etc/apt/sources.list.d/google-chrome.list sudo apt update sudo apt install google-chrome-stable Cas particuliers Sur Fedora ou CentOS, utilisez le paquet .rpm et la commande dnf ou yum . Pour Chromium (version open source), utilisez simplement : sudo apt install chromium-browser Bonnes pratiques Fermez toutes les fen\u00eatres Chrome avant la mise \u00e0 jour pour \u00e9viter les conflits. Sauvegardez vos sessions importantes. V\u00e9rifiez r\u00e9guli\u00e8rement les mises \u00e0 jour pour b\u00e9n\u00e9ficier des derniers correctifs de s\u00e9curit\u00e9. Ressources utiles Documentation officielle Google Chrome D\u00e9p\u00f4t Google Chrome","title":"Chrome"},{"location":"environnement-de-travail/chrome/#mettre-a-jour-google-chrome-sur-linux","text":"Chrome n'ayant pas de solution cl\u00e9 en main pour se mettre \u00e0 jour de mani\u00e8re autonome sur linux, il faut le faire en ligne de commande.","title":"Mettre \u00e0 jour Google Chrome sur linux"},{"location":"environnement-de-travail/chrome/#telechargement-du-paquet","text":"Il faut en premier lieu r\u00e9cup\u00e9rer le nouveau paquet : wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb Cette URL varie rarement. Elle permet de t\u00e9l\u00e9charger la derni\u00e8re version stable de Chrome.","title":"T\u00e9l\u00e9chargement du paquet"},{"location":"environnement-de-travail/chrome/#installation-du-paquet","text":"Par la suite il vous suffit juste de l'installer avec le gestionnaire de paquet bas niveau dpkg qui va venir surcharger les sources de votre Chrome install\u00e9 localement avec le nouveau paquet. sudo dpkg -i google-chrome-stable_current_amd64.deb Si des d\u00e9pendances sont manquantes, corrigez-les avec : sudo apt-get install -f","title":"Installation du paquet"},{"location":"environnement-de-travail/chrome/#nettoyage","text":"Et enfin, n'oubliez pas de nettoyer ! rm google-chrome-stable_current_amd64.deb","title":"Nettoyage"},{"location":"environnement-de-travail/chrome/#verifier-la-version-installee","text":"Pour v\u00e9rifier que la mise \u00e0 jour a bien \u00e9t\u00e9 prise en compte : google-chrome --version","title":"V\u00e9rifier la version install\u00e9e"},{"location":"environnement-de-travail/chrome/#astuce-mise-a-jour-via-le-depot-officiel","text":"Vous pouvez aussi ajouter le d\u00e9p\u00f4t officiel Google Chrome pour b\u00e9n\u00e9ficier des mises \u00e0 jour via apt : wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo apt-key add - echo 'deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main' | sudo tee /etc/apt/sources.list.d/google-chrome.list sudo apt update sudo apt install google-chrome-stable","title":"Astuce : mise \u00e0 jour via le d\u00e9p\u00f4t officiel"},{"location":"environnement-de-travail/chrome/#cas-particuliers","text":"Sur Fedora ou CentOS, utilisez le paquet .rpm et la commande dnf ou yum . Pour Chromium (version open source), utilisez simplement : sudo apt install chromium-browser","title":"Cas particuliers"},{"location":"environnement-de-travail/chrome/#bonnes-pratiques","text":"Fermez toutes les fen\u00eatres Chrome avant la mise \u00e0 jour pour \u00e9viter les conflits. Sauvegardez vos sessions importantes. V\u00e9rifiez r\u00e9guli\u00e8rement les mises \u00e0 jour pour b\u00e9n\u00e9ficier des derniers correctifs de s\u00e9curit\u00e9.","title":"Bonnes pratiques"},{"location":"environnement-de-travail/chrome/#ressources-utiles","text":"Documentation officielle Google Chrome D\u00e9p\u00f4t Google Chrome","title":"Ressources utiles"},{"location":"environnement-de-travail/nvim/","text":"Personnaliser NVIM WIP","title":"Neovim"},{"location":"environnement-de-travail/nvim/#personnaliser-nvim","text":"WIP","title":"Personnaliser NVIM"},{"location":"environnement-de-travail/terminal/","text":"Configurer ZSH sur linux ZSH est un interpr\u00e9teur de commande tout comme Bash. Il permet d'aller plus vite gr\u00e2ce \u00e0 des raccourcis de commandes que nous pouvons obtenir avec les plugins oh-my-zsh. Il faut en premier lieu installer zsh: sudo apt install zsh Une fois install\u00e9, nous pouvons installer oh-my-zsh depuis le r\u00e9pertoire GitHub: sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" Passons maintenant \u00e0 la configuration. Il existe de nombreuses configurations et plugins \u00e0 disposition. Vous pouvez les retrouver sur la documentation officielle de oh-my-zsh . Le fichier o\u00f9 est persist\u00e9 la configuration se trouve \u00e0 cet endroit: $HOME/.zshrc Si vous ne savez pas par o\u00f9 commencer, voici ma configuration que j'utilise au quotidien: # global environmental variables export LANG=fr_FR.UTF-8 export USR_LOCAL=\"/usr/local\" export ZSH=\"$HOME/.oh-my-zsh\" export ANDROID_HOME=\"$HOME/Android/Sdk\" export NVM_DIR=\"$HOME/.nvm\" export SDKMAN_DIR=\"$HOME/.sdkman\" export GO_DIR=\"$USR_LOCAL/go\" export JAVA_HOME=\"$HOME/.sdkman/candidates/java/current\" export HOME_LOCAL=\"$HOME/.local\" export PYENV_DIR=\"$HOME/.pyenv\" export DART_CACHE_DIR=\"$HOME/.pub-cache\" export PATH=$JAVA_HOME/bin:$ANDROID_HOME/platform-tools:$ANDROID_HOME/tools/bin:$HOME/bin:$HOME_LOCAL/bin:$USR_LOCAL/bin:$GO_DIR/bin:$DART_CACHE_DIR/bin:$PYENV_DIR/bin:$PATH # ohmyzsh configurations VSCODE=code # use \"snap install code --classic\" to install visual studio code ZSH_THEME=\"nicoulaj\" DISABLE_MAGIC_FUNCTIONS=\"true\" COMPLETION_WAITING_DOTS=\"true\" ZSH_WEB_SEARCH_ENGINES=( github \"https://github.com/search?q=\" stackoverflow \"https://stackoverflow.com/search?q=\" google \"https://www.google.com/search?q=\" ) plugins=( git # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/git python # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/python sudo # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/sudo adb # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/adb gitignore # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/gitignore flutter # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/flutter vscode # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/vscode kubectl # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/kubectl web-search # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/web-search ) # custom commands alias adb_show_layoutbounds='adb shell setprop debug.layout true ; adb shell service call activity 1599295570' alias adb_hide_layoutbounds='adb shell setprop debug.layout false ; adb shell service call activity 1599295570' alias adb_show_nav='adb shell settings put global policy_control null' alias adb_hide_nav='adb shell settings put global policy_control immersive.status=com.package1,com.package2:immersive.navigation=apps,-com.package3' alias adb_shutdown='adb shell reboot -p' alias adb_go_settings='adb shell am start -a android.settings.SETTINGS' alias adb_go_home='adb shell am start -a android.intent.action.MAIN -c android.intent.category.HOME' alias adb_go_wifi='adb shell am start -a android.intent.action.MAIN -n com.android.settings/.wifi.WifiSettings' init_pyenv () { eval \"$(pyenv init -)\" eval \"$(pyenv virtualenv-init -)\" } # Loading configurations [ -s \"$HOME/.config/envman/load.sh\" ] && source \"$HOME/.config/envman/load.sh\" [ -s \"$NVM_DIR/nvm.sh\" ] && \\. \"$NVM_DIR/nvm.sh\" # This loads nvm [ -s \"$NVM_DIR/bash_completion\" ] && \\. \"$NVM_DIR/bash_completion\" # This loads nvm bash_completion [[ -s \"$HOME/.sdkman/bin/sdkman-init.sh\" ]] && source \"$HOME/.sdkman/bin/sdkman-init.sh\" source $ZSH/oh-my-zsh.sh source <(kubectl completion zsh) Vous pouvez la copier ou vous en inspirer pour cr\u00e9er la votre. Une fois modifi\u00e9, il ne faut pas oublier de recharger l'interpr\u00e9teur actuel avec source ~/.zshrc , ou de tout simplement red\u00e9marrer le terminal. Il est possible de cr\u00e9er des touches personnalis\u00e9es sur le Moonlander ZSA. Il faut pour cela se rendre sur Oryx ou directement t\u00e9l\u00e9charger mes dotfiles qui contiennent le firmware du clavier qu'il ne reste plus qu'\u00e0 flash\u00e9.","title":"Terminal"},{"location":"environnement-de-travail/terminal/#configurer-zsh-sur-linux","text":"ZSH est un interpr\u00e9teur de commande tout comme Bash. Il permet d'aller plus vite gr\u00e2ce \u00e0 des raccourcis de commandes que nous pouvons obtenir avec les plugins oh-my-zsh. Il faut en premier lieu installer zsh: sudo apt install zsh Une fois install\u00e9, nous pouvons installer oh-my-zsh depuis le r\u00e9pertoire GitHub: sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" Passons maintenant \u00e0 la configuration. Il existe de nombreuses configurations et plugins \u00e0 disposition. Vous pouvez les retrouver sur la documentation officielle de oh-my-zsh . Le fichier o\u00f9 est persist\u00e9 la configuration se trouve \u00e0 cet endroit: $HOME/.zshrc Si vous ne savez pas par o\u00f9 commencer, voici ma configuration que j'utilise au quotidien: # global environmental variables export LANG=fr_FR.UTF-8 export USR_LOCAL=\"/usr/local\" export ZSH=\"$HOME/.oh-my-zsh\" export ANDROID_HOME=\"$HOME/Android/Sdk\" export NVM_DIR=\"$HOME/.nvm\" export SDKMAN_DIR=\"$HOME/.sdkman\" export GO_DIR=\"$USR_LOCAL/go\" export JAVA_HOME=\"$HOME/.sdkman/candidates/java/current\" export HOME_LOCAL=\"$HOME/.local\" export PYENV_DIR=\"$HOME/.pyenv\" export DART_CACHE_DIR=\"$HOME/.pub-cache\" export PATH=$JAVA_HOME/bin:$ANDROID_HOME/platform-tools:$ANDROID_HOME/tools/bin:$HOME/bin:$HOME_LOCAL/bin:$USR_LOCAL/bin:$GO_DIR/bin:$DART_CACHE_DIR/bin:$PYENV_DIR/bin:$PATH # ohmyzsh configurations VSCODE=code # use \"snap install code --classic\" to install visual studio code ZSH_THEME=\"nicoulaj\" DISABLE_MAGIC_FUNCTIONS=\"true\" COMPLETION_WAITING_DOTS=\"true\" ZSH_WEB_SEARCH_ENGINES=( github \"https://github.com/search?q=\" stackoverflow \"https://stackoverflow.com/search?q=\" google \"https://www.google.com/search?q=\" ) plugins=( git # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/git python # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/python sudo # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/sudo adb # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/adb gitignore # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/gitignore flutter # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/flutter vscode # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/vscode kubectl # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/kubectl web-search # https://github.com/ohmyzsh/ohmyzsh/tree/master/plugins/web-search ) # custom commands alias adb_show_layoutbounds='adb shell setprop debug.layout true ; adb shell service call activity 1599295570' alias adb_hide_layoutbounds='adb shell setprop debug.layout false ; adb shell service call activity 1599295570' alias adb_show_nav='adb shell settings put global policy_control null' alias adb_hide_nav='adb shell settings put global policy_control immersive.status=com.package1,com.package2:immersive.navigation=apps,-com.package3' alias adb_shutdown='adb shell reboot -p' alias adb_go_settings='adb shell am start -a android.settings.SETTINGS' alias adb_go_home='adb shell am start -a android.intent.action.MAIN -c android.intent.category.HOME' alias adb_go_wifi='adb shell am start -a android.intent.action.MAIN -n com.android.settings/.wifi.WifiSettings' init_pyenv () { eval \"$(pyenv init -)\" eval \"$(pyenv virtualenv-init -)\" } # Loading configurations [ -s \"$HOME/.config/envman/load.sh\" ] && source \"$HOME/.config/envman/load.sh\" [ -s \"$NVM_DIR/nvm.sh\" ] && \\. \"$NVM_DIR/nvm.sh\" # This loads nvm [ -s \"$NVM_DIR/bash_completion\" ] && \\. \"$NVM_DIR/bash_completion\" # This loads nvm bash_completion [[ -s \"$HOME/.sdkman/bin/sdkman-init.sh\" ]] && source \"$HOME/.sdkman/bin/sdkman-init.sh\" source $ZSH/oh-my-zsh.sh source <(kubectl completion zsh) Vous pouvez la copier ou vous en inspirer pour cr\u00e9er la votre. Une fois modifi\u00e9, il ne faut pas oublier de recharger l'interpr\u00e9teur actuel avec source ~/.zshrc , ou de tout simplement red\u00e9marrer le terminal. Il est possible de cr\u00e9er des touches personnalis\u00e9es sur le Moonlander ZSA. Il faut pour cela se rendre sur Oryx ou directement t\u00e9l\u00e9charger mes dotfiles qui contiennent le firmware du clavier qu'il ne reste plus qu'\u00e0 flash\u00e9.","title":"Configurer ZSH sur linux"},{"location":"environnement-de-travail/typescript/","text":"Installer le tooling de TypeScript TypeScript est un sur-ensemble de JavaScript qui ajoute le typage statique. Pour profiter pleinement de l\u2019\u00e9cosyst\u00e8me, il est recommand\u00e9 d\u2019installer et de configurer plusieurs outils pour le d\u00e9veloppement, la compilation et la qualit\u00e9 du code. Installation de TypeScript Installez TypeScript globalement ou localement dans votre projet : npm install -g typescript # global # ou npm install --save-dev typescript # local au projet V\u00e9rifiez l\u2019installation : tsc --version NVM pour switcher de version NodeJS NVM permet de g\u00e9rer plusieurs versions de Node.js sur la m\u00eame machine. Installation : curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash source ~/.bashrc Utilisation : nvm install 20 nvm use 20 nvm ls Initialisation du package.json Initialisez un projet Node.js : npm init -y Ajoutez TypeScript et d\u2019autres d\u00e9pendances : npm install --save-dev typescript @types/node Mise en place du tsconfig.json G\u00e9n\u00e9rez un fichier de configuration TypeScript : tsc --init Exemple minimal : { \"compilerOptions\": { \"target\": \"ES2020\", \"module\": \"commonjs\", \"outDir\": \"dist\", \"rootDir\": \"src\", \"strict\": true }, \"include\": [\"src\"] } Nodemon pour le hot reload Nodemon permet de relancer automatiquement votre application \u00e0 chaque modification. Installation : npm install --save-dev nodemon ts-node Ajoutez un script dans package.json : \"scripts\": { \"dev\": \"nodemon --watch src --exec ts-node src/index.ts\" } Lancez le mode d\u00e9veloppement : npm run dev ESLint ESLint permet d\u2019assurer la qualit\u00e9 et la coh\u00e9rence du code TypeScript. Installation : npm install --save-dev eslint @typescript-eslint/parser @typescript-eslint/eslint-plugin .eslintrc Exemple de configuration : { \"parser\": \"@typescript-eslint/parser\", \"plugins\": [\"@typescript-eslint\"], \"extends\": [ \"eslint:recommended\", \"plugin:@typescript-eslint/recommended\" ], \"env\": { \"node\": true, \"es2020\": true } } .eslintignore Ajoutez les dossiers \u00e0 ignorer : dist/ node_modules/ Bonnes pratiques Placez votre code source dans un dossier src/ . Compilez dans un dossier dist/ . Utilisez des types explicites et activez les options strictes dans tsconfig.json . Ajoutez des scripts npm pour automatiser les t\u00e2ches courantes (build, lint, dev). Ressources utiles TypeScript Handbook ESLint TypeScript Nodemon NVM","title":"TypeScript"},{"location":"environnement-de-travail/typescript/#installer-le-tooling-de-typescript","text":"TypeScript est un sur-ensemble de JavaScript qui ajoute le typage statique. Pour profiter pleinement de l\u2019\u00e9cosyst\u00e8me, il est recommand\u00e9 d\u2019installer et de configurer plusieurs outils pour le d\u00e9veloppement, la compilation et la qualit\u00e9 du code.","title":"Installer le tooling de TypeScript"},{"location":"environnement-de-travail/typescript/#installation-de-typescript","text":"Installez TypeScript globalement ou localement dans votre projet : npm install -g typescript # global # ou npm install --save-dev typescript # local au projet V\u00e9rifiez l\u2019installation : tsc --version","title":"Installation de TypeScript"},{"location":"environnement-de-travail/typescript/#nvm-pour-switcher-de-version-nodejs","text":"NVM permet de g\u00e9rer plusieurs versions de Node.js sur la m\u00eame machine. Installation : curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash source ~/.bashrc Utilisation : nvm install 20 nvm use 20 nvm ls","title":"NVM pour switcher de version NodeJS"},{"location":"environnement-de-travail/typescript/#initialisation-du-packagejson","text":"Initialisez un projet Node.js : npm init -y Ajoutez TypeScript et d\u2019autres d\u00e9pendances : npm install --save-dev typescript @types/node","title":"Initialisation du package.json"},{"location":"environnement-de-travail/typescript/#mise-en-place-du-tsconfigjson","text":"G\u00e9n\u00e9rez un fichier de configuration TypeScript : tsc --init Exemple minimal : { \"compilerOptions\": { \"target\": \"ES2020\", \"module\": \"commonjs\", \"outDir\": \"dist\", \"rootDir\": \"src\", \"strict\": true }, \"include\": [\"src\"] }","title":"Mise en place du tsconfig.json"},{"location":"environnement-de-travail/typescript/#nodemon-pour-le-hot-reload","text":"Nodemon permet de relancer automatiquement votre application \u00e0 chaque modification. Installation : npm install --save-dev nodemon ts-node Ajoutez un script dans package.json : \"scripts\": { \"dev\": \"nodemon --watch src --exec ts-node src/index.ts\" } Lancez le mode d\u00e9veloppement : npm run dev","title":"Nodemon pour le hot reload"},{"location":"environnement-de-travail/typescript/#eslint","text":"ESLint permet d\u2019assurer la qualit\u00e9 et la coh\u00e9rence du code TypeScript. Installation : npm install --save-dev eslint @typescript-eslint/parser @typescript-eslint/eslint-plugin","title":"ESLint"},{"location":"environnement-de-travail/typescript/#eslintrc","text":"Exemple de configuration : { \"parser\": \"@typescript-eslint/parser\", \"plugins\": [\"@typescript-eslint\"], \"extends\": [ \"eslint:recommended\", \"plugin:@typescript-eslint/recommended\" ], \"env\": { \"node\": true, \"es2020\": true } }","title":".eslintrc"},{"location":"environnement-de-travail/typescript/#eslintignore","text":"Ajoutez les dossiers \u00e0 ignorer : dist/ node_modules/","title":".eslintignore"},{"location":"environnement-de-travail/typescript/#bonnes-pratiques","text":"Placez votre code source dans un dossier src/ . Compilez dans un dossier dist/ . Utilisez des types explicites et activez les options strictes dans tsconfig.json . Ajoutez des scripts npm pour automatiser les t\u00e2ches courantes (build, lint, dev).","title":"Bonnes pratiques"},{"location":"environnement-de-travail/typescript/#ressources-utiles","text":"TypeScript Handbook ESLint TypeScript Nodemon NVM","title":"Ressources utiles"},{"location":"environnement-de-travail/vscode/","text":"Personnaliser VSCode Il est possible de facilement configurer l'environnement avec seulement un seul fichier. Ce fichier JSON doit avoir finir par l'extension <my_workspace>.code-workspace afin d'\u00eatre reconnu par l'\u00e9diteur. Environnement de travail multi-repo Au sein m\u00eame du fichier, il faut ins\u00e9rer sous la cl\u00e9 folders , les dossiers des multiples projets utilis\u00e9s dans votre environnement de travail. Voici un exemple: { \"folders\": [ { \"name\": \"Backend\", \"path\": \"back-end-folder-name\" }, { \"name\": \"Frontend\", \"path\": \"front-end-folder-name\" }, ] } L'id\u00e9al est d'avoir les dossiers des multiples projets sous un m\u00eame dossier parent lorsque vous les cloner, afin de faciliter la configuration. Automatisation des actions VSCode permet d\u2019automatiser des t\u00e2ches courantes via le fichier tasks.json dans le dossier .vscode/ de votre projet. Exemple pour lancer un build TypeScript : { \"version\": \"2.0.0\", \"tasks\": [ { \"label\": \"build-ts\", \"type\": \"shell\", \"command\": \"tsc\", \"group\": \"build\", \"problemMatcher\": \"$tsc\" } ] } Vous pouvez ensuite lancer la t\u00e2che via Ctrl+Maj+B ou la palette de commandes. Configuration du mode debug Le fichier .vscode/launch.json permet de configurer des sc\u00e9narios de d\u00e9bogage adapt\u00e9s \u00e0 chaque projet. Exemple pour Node.js : { \"version\": \"0.2.0\", \"configurations\": [ { \"type\": \"node\", \"request\": \"launch\", \"name\": \"Lancer le programme\", \"program\": \"${workspaceFolder}/src/index.ts\", \"preLaunchTask\": \"build-ts\", \"outFiles\": [\"${workspaceFolder}/dist/**/*.js\"] } ] } Pour d\u2019autres langages (Python, Go, Java\u2026), adaptez le type et les options selon l\u2019extension install\u00e9e. Configuration g\u00e9n\u00e9rales de l'\u00e9diteur Vous pouvez personnaliser l\u2019\u00e9diteur via le fichier settings.json (global ou par workspace). Exemple de r\u00e9glages utiles : { \"editor.tabSize\": 2, \"editor.formatOnSave\": true, \"files.exclude\": { \"node_modules\": true, \"dist\": true }, \"terminal.integrated.defaultProfile.linux\": \"bash\" } Utilisez la palette de commandes ( Ctrl+Maj+P ) pour acc\u00e9der rapidement aux r\u00e9glages. Les param\u00e8tres peuvent \u00eatre surcharg\u00e9s par workspace pour s\u2019adapter \u00e0 chaque projet. Extensions VSCode dispose d\u2019un marketplace tr\u00e8s riche. Quelques extensions recommand\u00e9es : Prettier : formatage automatique du code. ESLint : linting JavaScript/TypeScript. GitLens : outils avanc\u00e9s pour Git. Docker : gestion des conteneurs et images. Remote - Containers : d\u00e9veloppement dans des environnements Docker isol\u00e9s. Python : support complet pour Python. Markdown All in One : \u00e9dition avanc\u00e9e de Markdown. Pour installer une extension : code --install-extension ms-python.python Ou via l\u2019interface graphique (onglet Extensions). Bonnes pratiques Versionnez les fichiers .vscode/ utiles \u00e0 l\u2019\u00e9quipe (tasks, launch, settings sp\u00e9cifiques). Utilisez des snippets pour acc\u00e9l\u00e9rer la r\u00e9daction de code r\u00e9p\u00e9titif. Explorez les raccourcis clavier pour gagner en productivit\u00e9. Ressources utiles VSCode Docs Marketplace Extensions Exemples de configurations avanc\u00e9es","title":"VSCode"},{"location":"environnement-de-travail/vscode/#personnaliser-vscode","text":"Il est possible de facilement configurer l'environnement avec seulement un seul fichier. Ce fichier JSON doit avoir finir par l'extension <my_workspace>.code-workspace afin d'\u00eatre reconnu par l'\u00e9diteur.","title":"Personnaliser VSCode"},{"location":"environnement-de-travail/vscode/#environnement-de-travail-multi-repo","text":"Au sein m\u00eame du fichier, il faut ins\u00e9rer sous la cl\u00e9 folders , les dossiers des multiples projets utilis\u00e9s dans votre environnement de travail. Voici un exemple: { \"folders\": [ { \"name\": \"Backend\", \"path\": \"back-end-folder-name\" }, { \"name\": \"Frontend\", \"path\": \"front-end-folder-name\" }, ] } L'id\u00e9al est d'avoir les dossiers des multiples projets sous un m\u00eame dossier parent lorsque vous les cloner, afin de faciliter la configuration.","title":"Environnement de travail multi-repo"},{"location":"environnement-de-travail/vscode/#automatisation-des-actions","text":"VSCode permet d\u2019automatiser des t\u00e2ches courantes via le fichier tasks.json dans le dossier .vscode/ de votre projet. Exemple pour lancer un build TypeScript : { \"version\": \"2.0.0\", \"tasks\": [ { \"label\": \"build-ts\", \"type\": \"shell\", \"command\": \"tsc\", \"group\": \"build\", \"problemMatcher\": \"$tsc\" } ] } Vous pouvez ensuite lancer la t\u00e2che via Ctrl+Maj+B ou la palette de commandes.","title":"Automatisation des actions"},{"location":"environnement-de-travail/vscode/#configuration-du-mode-debug","text":"Le fichier .vscode/launch.json permet de configurer des sc\u00e9narios de d\u00e9bogage adapt\u00e9s \u00e0 chaque projet. Exemple pour Node.js : { \"version\": \"0.2.0\", \"configurations\": [ { \"type\": \"node\", \"request\": \"launch\", \"name\": \"Lancer le programme\", \"program\": \"${workspaceFolder}/src/index.ts\", \"preLaunchTask\": \"build-ts\", \"outFiles\": [\"${workspaceFolder}/dist/**/*.js\"] } ] } Pour d\u2019autres langages (Python, Go, Java\u2026), adaptez le type et les options selon l\u2019extension install\u00e9e.","title":"Configuration du mode debug"},{"location":"environnement-de-travail/vscode/#configuration-generales-de-lediteur","text":"Vous pouvez personnaliser l\u2019\u00e9diteur via le fichier settings.json (global ou par workspace). Exemple de r\u00e9glages utiles : { \"editor.tabSize\": 2, \"editor.formatOnSave\": true, \"files.exclude\": { \"node_modules\": true, \"dist\": true }, \"terminal.integrated.defaultProfile.linux\": \"bash\" } Utilisez la palette de commandes ( Ctrl+Maj+P ) pour acc\u00e9der rapidement aux r\u00e9glages. Les param\u00e8tres peuvent \u00eatre surcharg\u00e9s par workspace pour s\u2019adapter \u00e0 chaque projet.","title":"Configuration g\u00e9n\u00e9rales de l'\u00e9diteur"},{"location":"environnement-de-travail/vscode/#extensions","text":"VSCode dispose d\u2019un marketplace tr\u00e8s riche. Quelques extensions recommand\u00e9es : Prettier : formatage automatique du code. ESLint : linting JavaScript/TypeScript. GitLens : outils avanc\u00e9s pour Git. Docker : gestion des conteneurs et images. Remote - Containers : d\u00e9veloppement dans des environnements Docker isol\u00e9s. Python : support complet pour Python. Markdown All in One : \u00e9dition avanc\u00e9e de Markdown. Pour installer une extension : code --install-extension ms-python.python Ou via l\u2019interface graphique (onglet Extensions).","title":"Extensions"},{"location":"environnement-de-travail/vscode/#bonnes-pratiques","text":"Versionnez les fichiers .vscode/ utiles \u00e0 l\u2019\u00e9quipe (tasks, launch, settings sp\u00e9cifiques). Utilisez des snippets pour acc\u00e9l\u00e9rer la r\u00e9daction de code r\u00e9p\u00e9titif. Explorez les raccourcis clavier pour gagner en productivit\u00e9.","title":"Bonnes pratiques"},{"location":"environnement-de-travail/vscode/#ressources-utiles","text":"VSCode Docs Marketplace Extensions Exemples de configurations avanc\u00e9es","title":"Ressources utiles"},{"location":"front/archi-css/","text":"Architecture CSS Il existe diff\u00e9rentes mani\u00e8res d'organiser ses fichiers CSS dans les projets. Bien entendu, ces architectures peuvent \u00eatre impl\u00e9ment\u00e9es dans un m\u00eame projet en fonction du besoin. OOCSS L'approche orient\u00e9e objet CSS consiste \u00e0 \u00e9crire des blocks CSS uniques et r\u00e9utilisables. Le but est de les importer dans les balises concern\u00e9es sans dupliquer du code dans le fichier CSS pour une classe sp\u00e9cifique. On fonctionne par composition. Exemple : /* Block g\u00e9n\u00e9rique */ .box { border: 1px solid #ccc; padding: 1rem; } /* Extension r\u00e9utilisable */ .rounded { border-radius: 8px; } Utilisation : <div class=\"box rounded\">Contenu</div> BEM Block, Element & Modifiers. C'est une architecture permettant de traiter des cas sp\u00e9cifiques tels que des animations complexes tout en maintenant un niveau de lisibilit\u00e9 convenable. Exemple : .button { background: #007bff; color: white; } .button--large { font-size: 1.5rem; } .button__icon { margin-right: 0.5rem; } Utilisation : <button class=\"button button--large\"> <span class=\"button__icon\">\ud83d\udd0d</span> Rechercher </button> SMACSS Scalar and Modular Architecture for CSS. Cela consiste \u00e0 d\u00e9coupler un \u00e9l\u00e9ment afin d'appliquer des contraintes sur le conteneur de celui-ci et sur son bloc complet. Cela demande beaucoup plus de discipline que les deux autres m\u00e9thodes car il ne faut pas mettre de contraintes de padding/margin au sein du conteneur par exemple, cela pourrait interf\u00e9rer avec les autres cas d'utilisation de celui-ci. Exemple : /* Layouts */ .layout-header { background: #f5f5f5; padding: 1rem 0; } /* Modules */ .card { box-shadow: 0 2px 8px rgba(0,0,0,0.1); background: white; } /* States */ .is-active { border: 2px solid #007bff; } Utilisation : <header class=\"layout-header\"> <div class=\"card is-active\">Bienvenue</div> </header> Conseils pour structurer vos CSS Privil\u00e9giez la composition et la r\u00e9utilisabilit\u00e9. Documentez vos conventions de nommage dans le projet. Utilisez des pr\u00e9processeurs (Sass, Less) pour faciliter la modularit\u00e9. S\u00e9parez les fichiers par type (base, layout, modules, states, themes). Testez vos styles sur diff\u00e9rents navigateurs et tailles d\u2019\u00e9cran. Ressources utiles OOCSS BEM SMACSS CSS Tricks: CSS Architecture","title":"Archi CSS"},{"location":"front/archi-css/#architecture-css","text":"Il existe diff\u00e9rentes mani\u00e8res d'organiser ses fichiers CSS dans les projets. Bien entendu, ces architectures peuvent \u00eatre impl\u00e9ment\u00e9es dans un m\u00eame projet en fonction du besoin.","title":"Architecture CSS"},{"location":"front/archi-css/#oocss","text":"L'approche orient\u00e9e objet CSS consiste \u00e0 \u00e9crire des blocks CSS uniques et r\u00e9utilisables. Le but est de les importer dans les balises concern\u00e9es sans dupliquer du code dans le fichier CSS pour une classe sp\u00e9cifique. On fonctionne par composition. Exemple : /* Block g\u00e9n\u00e9rique */ .box { border: 1px solid #ccc; padding: 1rem; } /* Extension r\u00e9utilisable */ .rounded { border-radius: 8px; } Utilisation : <div class=\"box rounded\">Contenu</div>","title":"OOCSS"},{"location":"front/archi-css/#bem","text":"Block, Element & Modifiers. C'est une architecture permettant de traiter des cas sp\u00e9cifiques tels que des animations complexes tout en maintenant un niveau de lisibilit\u00e9 convenable. Exemple : .button { background: #007bff; color: white; } .button--large { font-size: 1.5rem; } .button__icon { margin-right: 0.5rem; } Utilisation : <button class=\"button button--large\"> <span class=\"button__icon\">\ud83d\udd0d</span> Rechercher </button>","title":"BEM"},{"location":"front/archi-css/#smacss","text":"Scalar and Modular Architecture for CSS. Cela consiste \u00e0 d\u00e9coupler un \u00e9l\u00e9ment afin d'appliquer des contraintes sur le conteneur de celui-ci et sur son bloc complet. Cela demande beaucoup plus de discipline que les deux autres m\u00e9thodes car il ne faut pas mettre de contraintes de padding/margin au sein du conteneur par exemple, cela pourrait interf\u00e9rer avec les autres cas d'utilisation de celui-ci. Exemple : /* Layouts */ .layout-header { background: #f5f5f5; padding: 1rem 0; } /* Modules */ .card { box-shadow: 0 2px 8px rgba(0,0,0,0.1); background: white; } /* States */ .is-active { border: 2px solid #007bff; } Utilisation : <header class=\"layout-header\"> <div class=\"card is-active\">Bienvenue</div> </header>","title":"SMACSS"},{"location":"front/archi-css/#conseils-pour-structurer-vos-css","text":"Privil\u00e9giez la composition et la r\u00e9utilisabilit\u00e9. Documentez vos conventions de nommage dans le projet. Utilisez des pr\u00e9processeurs (Sass, Less) pour faciliter la modularit\u00e9. S\u00e9parez les fichiers par type (base, layout, modules, states, themes). Testez vos styles sur diff\u00e9rents navigateurs et tailles d\u2019\u00e9cran.","title":"Conseils pour structurer vos CSS"},{"location":"front/archi-css/#ressources-utiles","text":"OOCSS BEM SMACSS CSS Tricks: CSS Architecture","title":"Ressources utiles"},{"location":"front/chrome-v8/","text":"Comprendre le fonctionnement de Chrome V8 Le moteur V8 est le moteur JavaScript open source d\u00e9velopp\u00e9 par Google, utilis\u00e9 dans Chrome et Node.js. Il compile le code JavaScript en code machine natif pour offrir des performances optimales. V8 g\u00e8re la m\u00e9moire, le garbage collector, l\u2019optimisation du code, et supporte les derni\u00e8res fonctionnalit\u00e9s ECMAScript. Promises Les Promises permettent de g\u00e9rer l\u2019asynchronisme de fa\u00e7on plus lisible que les callbacks imbriqu\u00e9s. function fetchData() { return new Promise((resolve, reject) => { setTimeout(() => resolve('Donn\u00e9es re\u00e7ues'), 1000); }); } fetchData().then(data => console.log(data)); Async/Await Async/Await est une syntaxe plus moderne pour travailler avec les Promises, rendant le code asynchrone plus lisible. async function main() { const data = await fetchData(); console.log(data); } main(); Callbacks Les callbacks sont des fonctions pass\u00e9es en argument pour \u00eatre ex\u00e9cut\u00e9es plus tard, souvent utilis\u00e9es avant l\u2019arriv\u00e9e des Promises. function fetchDataCallback(cb) { setTimeout(() => cb('Donn\u00e9es re\u00e7ues'), 1000); } fetchDataCallback(data => console.log(data)); Generators Les generators permettent de cr\u00e9er des fonctions qui peuvent \u00eatre interrompues et reprises, utiles pour g\u00e9rer des flux de donn\u00e9es ou de l\u2019asynchronisme contr\u00f4l\u00e9. function* compteur() { yield 1; yield 2; yield 3; } for (let n of compteur()) { console.log(n); } Observables Les Observables (ex: RxJS) permettent de g\u00e9rer des flux de donn\u00e9es asynchrones multiples (streams), avec la possibilit\u00e9 de s\u2019abonner, transformer et combiner les flux. import { Observable } from 'rxjs'; const obs = new Observable(subscriber => { subscriber.next(1); subscriber.next(2); subscriber.complete(); }); obs.subscribe({ next: v => console.log(v), complete: () => console.log('Fini') }); EventEmitter L\u2019EventEmitter (Node.js) permet de g\u00e9rer des \u00e9v\u00e9nements personnalis\u00e9s et d\u2019y r\u00e9agir via des listeners. const EventEmitter = require('events'); const emitter = new EventEmitter(); emitter.on('data', (msg) => console.log('Re\u00e7u:', msg)); emitter.emit('data', 'Hello Event!'); Async Iterators Les Async Iterators permettent d\u2019it\u00e9rer sur des donn\u00e9es asynchrones avec la syntaxe for await...of . async function* asyncGen() { yield 'A'; yield 'B'; } (async () => { for await (const val of asyncGen()) { console.log(val); } })(); Comparatif rapide Concept Usage principal Syntaxe moderne Gestion erreurs Multi-\u00e9v\u00e9nements Callback Asynchrone simple Non try/catch Non Promise Asynchrone, cha\u00eenage Oui catch() Non Async/Await Asynchrone, code lisible Oui try/catch Non Generator Flux contr\u00f4l\u00e9s, pausable Oui try/catch Non Observable Streams, multi-\u00e9v\u00e9nements Oui (RxJS) catchError Oui EventEmitter \u00c9v\u00e9nements personnalis\u00e9s Oui (Node.js) try/catch Oui Async Iterator It\u00e9ration asynchrone Oui try/catch Oui Quand utiliser chaque concept ? Cas d\u2019usage et recommandations Callback : \u00c0 \u00e9viter dans les nouveaux projets, car ils rendent le code difficile \u00e0 maintenir (callback hell). Utilisez-les uniquement pour des APIs anciennes ou des cas tr\u00e8s simples. // \u00c0 \u00e9viter pour du code moderne fs.readFile('file.txt', (err, data) => { /* ... */ }); Promise : \u00c0 privil\u00e9gier pour toute op\u00e9ration asynchrone moderne (requ\u00eates HTTP, acc\u00e8s fichiers, etc). Permet le cha\u00eenage et une gestion d\u2019erreur centralis\u00e9e. fetch('/api/data').then(res => res.json()).then(data => console.log(data)); Async/Await : Id\u00e9al pour \u00e9crire du code asynchrone lisible, notamment dans les fonctions m\u00e9tiers complexes ou les traitements s\u00e9quentiels. async function process() { const user = await fetchUser(); const posts = await fetchPosts(user.id); return posts; } Generator : \u00c0 utiliser pour cr\u00e9er des it\u00e9rateurs personnalis\u00e9s, des pipelines de traitement ou des flux pausable (ex : parsing, lazy loading). function* range(n) { for (let i = 0; i < n; i++) yield i; } for (let x of range(3)) console.log(x); // 0, 1, 2 Observable : Recommand\u00e9 pour g\u00e9rer des flux d\u2019\u00e9v\u00e9nements multiples, des WebSockets, ou des interfaces r\u00e9actives complexes (RxJS). Id\u00e9al pour les applications frontend avec beaucoup d\u2019interactions. // Ex : \u00e9coute d\u2019un flux de notifications notifications$.subscribe(msg => afficher(msg)); EventEmitter : \u00c0 utiliser c\u00f4t\u00e9 Node.js pour la communication entre modules, la gestion d\u2019\u00e9v\u00e9nements syst\u00e8me ou applicatifs (ex : serveur HTTP, file d\u2019attente). emitter.on('jobDone', () => console.log('Traitement termin\u00e9 !')); Async Iterator : Parfait pour consommer des flux de donn\u00e9es asynchrones (streams, API pagin\u00e9es, lecture de fichiers volumineux) avec une syntaxe moderne. for await (const chunk of readableStream) { traiter(chunk); } R\u00e9sum\u00e9 : - Privil\u00e9giez Promise et Async/Await pour la majorit\u00e9 des traitements asynchrones m\u00e9tier. - Utilisez Observable pour les flux complexes et EventEmitter pour la gestion d\u2019\u00e9v\u00e9nements c\u00f4t\u00e9 serveur. - Callback est \u00e0 \u00e9viter sauf contrainte technique. - Generator et Async Iterator sont utiles pour des cas avanc\u00e9s de flux ou de traitement pausable. Ressources utiles V8 Documentation MDN Promises MDN Async functions Node.js EventEmitter RxJS","title":"Chrome v8"},{"location":"front/chrome-v8/#comprendre-le-fonctionnement-de-chrome-v8","text":"Le moteur V8 est le moteur JavaScript open source d\u00e9velopp\u00e9 par Google, utilis\u00e9 dans Chrome et Node.js. Il compile le code JavaScript en code machine natif pour offrir des performances optimales. V8 g\u00e8re la m\u00e9moire, le garbage collector, l\u2019optimisation du code, et supporte les derni\u00e8res fonctionnalit\u00e9s ECMAScript.","title":"Comprendre le fonctionnement de Chrome V8"},{"location":"front/chrome-v8/#promises","text":"Les Promises permettent de g\u00e9rer l\u2019asynchronisme de fa\u00e7on plus lisible que les callbacks imbriqu\u00e9s. function fetchData() { return new Promise((resolve, reject) => { setTimeout(() => resolve('Donn\u00e9es re\u00e7ues'), 1000); }); } fetchData().then(data => console.log(data));","title":"Promises"},{"location":"front/chrome-v8/#asyncawait","text":"Async/Await est une syntaxe plus moderne pour travailler avec les Promises, rendant le code asynchrone plus lisible. async function main() { const data = await fetchData(); console.log(data); } main();","title":"Async/Await"},{"location":"front/chrome-v8/#callbacks","text":"Les callbacks sont des fonctions pass\u00e9es en argument pour \u00eatre ex\u00e9cut\u00e9es plus tard, souvent utilis\u00e9es avant l\u2019arriv\u00e9e des Promises. function fetchDataCallback(cb) { setTimeout(() => cb('Donn\u00e9es re\u00e7ues'), 1000); } fetchDataCallback(data => console.log(data));","title":"Callbacks"},{"location":"front/chrome-v8/#generators","text":"Les generators permettent de cr\u00e9er des fonctions qui peuvent \u00eatre interrompues et reprises, utiles pour g\u00e9rer des flux de donn\u00e9es ou de l\u2019asynchronisme contr\u00f4l\u00e9. function* compteur() { yield 1; yield 2; yield 3; } for (let n of compteur()) { console.log(n); }","title":"Generators"},{"location":"front/chrome-v8/#observables","text":"Les Observables (ex: RxJS) permettent de g\u00e9rer des flux de donn\u00e9es asynchrones multiples (streams), avec la possibilit\u00e9 de s\u2019abonner, transformer et combiner les flux. import { Observable } from 'rxjs'; const obs = new Observable(subscriber => { subscriber.next(1); subscriber.next(2); subscriber.complete(); }); obs.subscribe({ next: v => console.log(v), complete: () => console.log('Fini') });","title":"Observables"},{"location":"front/chrome-v8/#eventemitter","text":"L\u2019EventEmitter (Node.js) permet de g\u00e9rer des \u00e9v\u00e9nements personnalis\u00e9s et d\u2019y r\u00e9agir via des listeners. const EventEmitter = require('events'); const emitter = new EventEmitter(); emitter.on('data', (msg) => console.log('Re\u00e7u:', msg)); emitter.emit('data', 'Hello Event!');","title":"EventEmitter"},{"location":"front/chrome-v8/#async-iterators","text":"Les Async Iterators permettent d\u2019it\u00e9rer sur des donn\u00e9es asynchrones avec la syntaxe for await...of . async function* asyncGen() { yield 'A'; yield 'B'; } (async () => { for await (const val of asyncGen()) { console.log(val); } })();","title":"Async Iterators"},{"location":"front/chrome-v8/#comparatif-rapide","text":"Concept Usage principal Syntaxe moderne Gestion erreurs Multi-\u00e9v\u00e9nements Callback Asynchrone simple Non try/catch Non Promise Asynchrone, cha\u00eenage Oui catch() Non Async/Await Asynchrone, code lisible Oui try/catch Non Generator Flux contr\u00f4l\u00e9s, pausable Oui try/catch Non Observable Streams, multi-\u00e9v\u00e9nements Oui (RxJS) catchError Oui EventEmitter \u00c9v\u00e9nements personnalis\u00e9s Oui (Node.js) try/catch Oui Async Iterator It\u00e9ration asynchrone Oui try/catch Oui","title":"Comparatif rapide"},{"location":"front/chrome-v8/#quand-utiliser-chaque-concept-cas-dusage-et-recommandations","text":"Callback : \u00c0 \u00e9viter dans les nouveaux projets, car ils rendent le code difficile \u00e0 maintenir (callback hell). Utilisez-les uniquement pour des APIs anciennes ou des cas tr\u00e8s simples. // \u00c0 \u00e9viter pour du code moderne fs.readFile('file.txt', (err, data) => { /* ... */ }); Promise : \u00c0 privil\u00e9gier pour toute op\u00e9ration asynchrone moderne (requ\u00eates HTTP, acc\u00e8s fichiers, etc). Permet le cha\u00eenage et une gestion d\u2019erreur centralis\u00e9e. fetch('/api/data').then(res => res.json()).then(data => console.log(data)); Async/Await : Id\u00e9al pour \u00e9crire du code asynchrone lisible, notamment dans les fonctions m\u00e9tiers complexes ou les traitements s\u00e9quentiels. async function process() { const user = await fetchUser(); const posts = await fetchPosts(user.id); return posts; } Generator : \u00c0 utiliser pour cr\u00e9er des it\u00e9rateurs personnalis\u00e9s, des pipelines de traitement ou des flux pausable (ex : parsing, lazy loading). function* range(n) { for (let i = 0; i < n; i++) yield i; } for (let x of range(3)) console.log(x); // 0, 1, 2 Observable : Recommand\u00e9 pour g\u00e9rer des flux d\u2019\u00e9v\u00e9nements multiples, des WebSockets, ou des interfaces r\u00e9actives complexes (RxJS). Id\u00e9al pour les applications frontend avec beaucoup d\u2019interactions. // Ex : \u00e9coute d\u2019un flux de notifications notifications$.subscribe(msg => afficher(msg)); EventEmitter : \u00c0 utiliser c\u00f4t\u00e9 Node.js pour la communication entre modules, la gestion d\u2019\u00e9v\u00e9nements syst\u00e8me ou applicatifs (ex : serveur HTTP, file d\u2019attente). emitter.on('jobDone', () => console.log('Traitement termin\u00e9 !')); Async Iterator : Parfait pour consommer des flux de donn\u00e9es asynchrones (streams, API pagin\u00e9es, lecture de fichiers volumineux) avec une syntaxe moderne. for await (const chunk of readableStream) { traiter(chunk); } R\u00e9sum\u00e9 : - Privil\u00e9giez Promise et Async/Await pour la majorit\u00e9 des traitements asynchrones m\u00e9tier. - Utilisez Observable pour les flux complexes et EventEmitter pour la gestion d\u2019\u00e9v\u00e9nements c\u00f4t\u00e9 serveur. - Callback est \u00e0 \u00e9viter sauf contrainte technique. - Generator et Async Iterator sont utiles pour des cas avanc\u00e9s de flux ou de traitement pausable.","title":"Quand utiliser chaque concept ? Cas d\u2019usage et recommandations"},{"location":"front/chrome-v8/#ressources-utiles","text":"V8 Documentation MDN Promises MDN Async functions Node.js EventEmitter RxJS","title":"Ressources utiles"},{"location":"front/htmx/","text":"HTMX HTMX est une librairie JavaScript l\u00e9g\u00e8re qui permet d\u2019ajouter des interactions dynamiques \u00e0 vos pages HTML sans \u00e9crire de code JS complexe. Elle facilite la cr\u00e9ation d\u2019applications web r\u00e9actives en utilisant des attributs HTML pour d\u00e9clencher des requ\u00eates AJAX, du WebSocket, du SSE ou des requ\u00eates via le protocole HTTP standard. What is HTMX? HTMX permet de rendre n\u2019importe quel \u00e9l\u00e9ment HTML interactif en ajoutant des attributs sp\u00e9cifiques. Vous pouvez charger dynamiquement du contenu, soumettre des formulaires, ou mettre \u00e0 jour des parties de la page sans recharger l\u2019ensemble du document. Installation Ajoutez simplement la librairie dans votre page HTML : <script src=\"https://unpkg.com/htmx.org@1.9.12\"></script> Ou via npm : npm install htmx.org Usage Pour charger dynamiquement du contenu dans un \u00e9l\u00e9ment : <button hx-get=\"/hello\" hx-target=\"#result\">Dire bonjour</button> <div id=\"result\"></div> Quand l\u2019utilisateur clique sur le bouton, une requ\u00eate GET est envoy\u00e9e \u00e0 /hello et la r\u00e9ponse HTML est inject\u00e9e dans le div #result . Examples Soumettre un formulaire sans rechargement <form hx-post=\"/api/login\" hx-target=\"#message\" hx-swap=\"outerHTML\"> <input name=\"user\" /> <input name=\"pass\" type=\"password\" /> <button type=\"submit\">Connexion</button> </form> <div id=\"message\"></div> Pagination dynamique <a hx-get=\"/page/2\" hx-target=\"#content\" hx-push-url=\"true\">Page suivante</a> <div id=\"content\">...</div> HTMX Attributes hx-get , hx-post , hx-put , hx-delete : type de requ\u00eate HTTP \u00e0 envoyer. hx-target : \u00e9l\u00e9ment cible \u00e0 mettre \u00e0 jour avec la r\u00e9ponse. hx-swap : mode d\u2019injection du contenu ( innerHTML , outerHTML , beforebegin , etc). hx-trigger : \u00e9v\u00e9nement qui d\u00e9clenche la requ\u00eate (ex : click , change , load ). hx-vals : donn\u00e9es suppl\u00e9mentaires \u00e0 envoyer. hx-headers : headers personnalis\u00e9s. hx-push-url : met \u00e0 jour l\u2019URL du navigateur. HTMX Events HTMX \u00e9met de nombreux \u00e9v\u00e9nements personnalis\u00e9s pour r\u00e9agir \u00e0 chaque \u00e9tape du cycle de vie d\u2019une requ\u00eate : document.body.addEventListener('htmx:afterSwap', function(evt) { console.log('Contenu mis \u00e0 jour !'); }); Principaux \u00e9v\u00e9nements : - htmx:configRequest - htmx:beforeRequest - htmx:afterRequest - htmx:beforeSwap - htmx:afterSwap - htmx:responseError HTMX Extensions HTMX propose des extensions pour enrichir les fonctionnalit\u00e9s (par exemple, gestion de WebSocket, validation, etc). Exemple d\u2019utilisation : <script src=\"https://unpkg.com/htmx.org/dist/ext/ws.js\"></script> <div hx-ext=\"ws\" ws-connect=\"wss://example.com/socket\"></div> HTMX and Go templates HTMX s\u2019int\u00e8gre parfaitement avec les templates Go (html/template). Il suffit de g\u00e9n\u00e9rer des fragments HTML c\u00f4t\u00e9 serveur et de les retourner en r\u00e9ponse aux requ\u00eates HTMX. Exemple c\u00f4t\u00e9 Go : func HelloHandler(w http.ResponseWriter, r *http.Request) { tmpl := template.Must(template.ParseFiles(\"hello.html\")) tmpl.Execute(w, map[string]string{\"Name\": \"Arthur\"}) } Exemple c\u00f4t\u00e9 HTML : <button hx-get=\"/hello\" hx-target=\"#result\">Dire bonjour</button> <div id=\"result\"></div> Bonnes pratiques Privil\u00e9giez les fragments HTML pour les r\u00e9ponses serveur. Utilisez les \u00e9v\u00e9nements HTMX pour g\u00e9rer les loaders, erreurs, etc. Combinez HTMX avec Alpine.js pour des interactions avanc\u00e9es sans framework lourd. Ressources utiles Documentation officielle HTMX Liste des extensions HTMX Exemples HTMX + Go","title":"HTMX"},{"location":"front/htmx/#htmx","text":"HTMX est une librairie JavaScript l\u00e9g\u00e8re qui permet d\u2019ajouter des interactions dynamiques \u00e0 vos pages HTML sans \u00e9crire de code JS complexe. Elle facilite la cr\u00e9ation d\u2019applications web r\u00e9actives en utilisant des attributs HTML pour d\u00e9clencher des requ\u00eates AJAX, du WebSocket, du SSE ou des requ\u00eates via le protocole HTTP standard.","title":"HTMX"},{"location":"front/htmx/#what-is-htmx","text":"HTMX permet de rendre n\u2019importe quel \u00e9l\u00e9ment HTML interactif en ajoutant des attributs sp\u00e9cifiques. Vous pouvez charger dynamiquement du contenu, soumettre des formulaires, ou mettre \u00e0 jour des parties de la page sans recharger l\u2019ensemble du document.","title":"What is HTMX?"},{"location":"front/htmx/#installation","text":"Ajoutez simplement la librairie dans votre page HTML : <script src=\"https://unpkg.com/htmx.org@1.9.12\"></script> Ou via npm : npm install htmx.org","title":"Installation"},{"location":"front/htmx/#usage","text":"Pour charger dynamiquement du contenu dans un \u00e9l\u00e9ment : <button hx-get=\"/hello\" hx-target=\"#result\">Dire bonjour</button> <div id=\"result\"></div> Quand l\u2019utilisateur clique sur le bouton, une requ\u00eate GET est envoy\u00e9e \u00e0 /hello et la r\u00e9ponse HTML est inject\u00e9e dans le div #result .","title":"Usage"},{"location":"front/htmx/#examples","text":"","title":"Examples"},{"location":"front/htmx/#soumettre-un-formulaire-sans-rechargement","text":"<form hx-post=\"/api/login\" hx-target=\"#message\" hx-swap=\"outerHTML\"> <input name=\"user\" /> <input name=\"pass\" type=\"password\" /> <button type=\"submit\">Connexion</button> </form> <div id=\"message\"></div>","title":"Soumettre un formulaire sans rechargement"},{"location":"front/htmx/#pagination-dynamique","text":"<a hx-get=\"/page/2\" hx-target=\"#content\" hx-push-url=\"true\">Page suivante</a> <div id=\"content\">...</div>","title":"Pagination dynamique"},{"location":"front/htmx/#htmx-attributes","text":"hx-get , hx-post , hx-put , hx-delete : type de requ\u00eate HTTP \u00e0 envoyer. hx-target : \u00e9l\u00e9ment cible \u00e0 mettre \u00e0 jour avec la r\u00e9ponse. hx-swap : mode d\u2019injection du contenu ( innerHTML , outerHTML , beforebegin , etc). hx-trigger : \u00e9v\u00e9nement qui d\u00e9clenche la requ\u00eate (ex : click , change , load ). hx-vals : donn\u00e9es suppl\u00e9mentaires \u00e0 envoyer. hx-headers : headers personnalis\u00e9s. hx-push-url : met \u00e0 jour l\u2019URL du navigateur.","title":"HTMX Attributes"},{"location":"front/htmx/#htmx-events","text":"HTMX \u00e9met de nombreux \u00e9v\u00e9nements personnalis\u00e9s pour r\u00e9agir \u00e0 chaque \u00e9tape du cycle de vie d\u2019une requ\u00eate : document.body.addEventListener('htmx:afterSwap', function(evt) { console.log('Contenu mis \u00e0 jour !'); }); Principaux \u00e9v\u00e9nements : - htmx:configRequest - htmx:beforeRequest - htmx:afterRequest - htmx:beforeSwap - htmx:afterSwap - htmx:responseError","title":"HTMX Events"},{"location":"front/htmx/#htmx-extensions","text":"HTMX propose des extensions pour enrichir les fonctionnalit\u00e9s (par exemple, gestion de WebSocket, validation, etc). Exemple d\u2019utilisation : <script src=\"https://unpkg.com/htmx.org/dist/ext/ws.js\"></script> <div hx-ext=\"ws\" ws-connect=\"wss://example.com/socket\"></div>","title":"HTMX Extensions"},{"location":"front/htmx/#htmx-and-go-templates","text":"HTMX s\u2019int\u00e8gre parfaitement avec les templates Go (html/template). Il suffit de g\u00e9n\u00e9rer des fragments HTML c\u00f4t\u00e9 serveur et de les retourner en r\u00e9ponse aux requ\u00eates HTMX. Exemple c\u00f4t\u00e9 Go : func HelloHandler(w http.ResponseWriter, r *http.Request) { tmpl := template.Must(template.ParseFiles(\"hello.html\")) tmpl.Execute(w, map[string]string{\"Name\": \"Arthur\"}) } Exemple c\u00f4t\u00e9 HTML : <button hx-get=\"/hello\" hx-target=\"#result\">Dire bonjour</button> <div id=\"result\"></div>","title":"HTMX and Go templates"},{"location":"front/htmx/#bonnes-pratiques","text":"Privil\u00e9giez les fragments HTML pour les r\u00e9ponses serveur. Utilisez les \u00e9v\u00e9nements HTMX pour g\u00e9rer les loaders, erreurs, etc. Combinez HTMX avec Alpine.js pour des interactions avanc\u00e9es sans framework lourd.","title":"Bonnes pratiques"},{"location":"front/htmx/#ressources-utiles","text":"Documentation officielle HTMX Liste des extensions HTMX Exemples HTMX + Go","title":"Ressources utiles"},{"location":"front/react/","text":"React React est une librairie JS permettant de faire du rechargement r\u00e9actif \u00e0 l'aide d'un DOM virtuel. Cela permet d'avoir des applications web dynamiques sans rechargements de la page. C'est l'outil le plus utilis\u00e9 pour faire des sites en JS/TS d'apr\u00e8s NPM. G\u00e9n\u00e9ration d'un projet React en TypeScript npx create-react-app my-app --template typescript npm start Cr\u00e9ation d'un composant simple Avec TypeScript, on doit sp\u00e9cifier les types de chaques attributs/variables/fonctions. Il en va de m\u00eame pour les composants React. interface ComponentProps { text?: string } export function CustomComponent({ text }: ComponentProps) { return (<div>{text}</div>); } Utilisation au sein d'un autre composant : import { CustomComponent } from './CustomComponent.jsx'; export function App() { let innerText: string = \"Hello World!\"; return (<CustomComponent text={innerText}/>); } Typage avanc\u00e9 des props Vous pouvez typer finement les props, y compris les callbacks et les objets imbriqu\u00e9s : interface ButtonProps { label: string; onClick: (event: React.MouseEvent<HTMLButtonElement>) => void; style?: React.CSSProperties; } export function Button({ label, onClick, style }: ButtonProps) { return <button style={style} onClick={onClick}>{label}</button>; } Gestion des props par d\u00e9faut et children interface CardProps { title: string; children?: React.ReactNode; } export function Card({ title, children }: CardProps) { return ( <div className=\"card\"> <h2>{title}</h2> <div>{children}</div> </div> ); } Routing avec React Router Pour g\u00e9rer la navigation entre pages, utilisez react-router-dom : npm install react-router-dom Exemple d\u2019utilisation : import { BrowserRouter, Routes, Route, Link } from 'react-router-dom'; export function App() { return ( <BrowserRouter> <nav> <Link to=\"/\">Accueil</Link> <Link to=\"/about\">\u00c0 propos</Link> </nav> <Routes> <Route path=\"/\" element={<Home />} /> <Route path=\"/about\" element={<About />} /> </Routes> </BrowserRouter> ); } Gestion des formulaires Pour g\u00e9rer les formulaires, utilisez le state et les \u00e9v\u00e9nements : import { useState } from 'react'; export function ContactForm() { const [email, setEmail] = useState(\"\"); const [message, setMessage] = useState(\"\"); const handleSubmit = (e: React.FormEvent) => { e.preventDefault(); // Envoyer les donn\u00e9es }; return ( <form onSubmit={handleSubmit}> <input type=\"email\" value={email} onChange={e => setEmail(e.target.value)} /> <textarea value={message} onChange={e => setMessage(e.target.value)} /> <button type=\"submit\">Envoyer</button> </form> ); } Tests unitaires avec React Testing Library Pour tester vos composants : npm install --save-dev @testing-library/react @testing-library/jest-dom Exemple de test : import { render, screen } from '@testing-library/react'; import { Button } from './Button'; test('affiche le label', () => { render(<Button label=\"OK\" onClick={() => {}} />); expect(screen.getByText('OK')).toBeInTheDocument(); }); Bonnes pratiques Structurez votre projet avec des dossiers /components , /pages , /hooks , /utils . Utilisez des hooks personnalis\u00e9s pour factoriser la logique r\u00e9utilisable. Pr\u00e9f\u00e9rez les fonctions pures et le typage strict. Documentez les props et les hooks avec des commentaires JSDoc. Utilisez des outils comme ESLint et Prettier pour la qualit\u00e9 du code. Ressources utiles Documentation officielle React React TypeScript Cheatsheets React Router Testing Library","title":"React"},{"location":"front/react/#react","text":"React est une librairie JS permettant de faire du rechargement r\u00e9actif \u00e0 l'aide d'un DOM virtuel. Cela permet d'avoir des applications web dynamiques sans rechargements de la page. C'est l'outil le plus utilis\u00e9 pour faire des sites en JS/TS d'apr\u00e8s NPM.","title":"React"},{"location":"front/react/#generation-dun-projet-react-en-typescript","text":"npx create-react-app my-app --template typescript npm start","title":"G\u00e9n\u00e9ration d'un projet React en TypeScript"},{"location":"front/react/#creation-dun-composant-simple","text":"Avec TypeScript, on doit sp\u00e9cifier les types de chaques attributs/variables/fonctions. Il en va de m\u00eame pour les composants React. interface ComponentProps { text?: string } export function CustomComponent({ text }: ComponentProps) { return (<div>{text}</div>); } Utilisation au sein d'un autre composant : import { CustomComponent } from './CustomComponent.jsx'; export function App() { let innerText: string = \"Hello World!\"; return (<CustomComponent text={innerText}/>); }","title":"Cr\u00e9ation d'un composant simple"},{"location":"front/react/#typage-avance-des-props","text":"Vous pouvez typer finement les props, y compris les callbacks et les objets imbriqu\u00e9s : interface ButtonProps { label: string; onClick: (event: React.MouseEvent<HTMLButtonElement>) => void; style?: React.CSSProperties; } export function Button({ label, onClick, style }: ButtonProps) { return <button style={style} onClick={onClick}>{label}</button>; }","title":"Typage avanc\u00e9 des props"},{"location":"front/react/#gestion-des-props-par-defaut-et-children","text":"interface CardProps { title: string; children?: React.ReactNode; } export function Card({ title, children }: CardProps) { return ( <div className=\"card\"> <h2>{title}</h2> <div>{children}</div> </div> ); }","title":"Gestion des props par d\u00e9faut et children"},{"location":"front/react/#routing-avec-react-router","text":"Pour g\u00e9rer la navigation entre pages, utilisez react-router-dom : npm install react-router-dom Exemple d\u2019utilisation : import { BrowserRouter, Routes, Route, Link } from 'react-router-dom'; export function App() { return ( <BrowserRouter> <nav> <Link to=\"/\">Accueil</Link> <Link to=\"/about\">\u00c0 propos</Link> </nav> <Routes> <Route path=\"/\" element={<Home />} /> <Route path=\"/about\" element={<About />} /> </Routes> </BrowserRouter> ); }","title":"Routing avec React Router"},{"location":"front/react/#gestion-des-formulaires","text":"Pour g\u00e9rer les formulaires, utilisez le state et les \u00e9v\u00e9nements : import { useState } from 'react'; export function ContactForm() { const [email, setEmail] = useState(\"\"); const [message, setMessage] = useState(\"\"); const handleSubmit = (e: React.FormEvent) => { e.preventDefault(); // Envoyer les donn\u00e9es }; return ( <form onSubmit={handleSubmit}> <input type=\"email\" value={email} onChange={e => setEmail(e.target.value)} /> <textarea value={message} onChange={e => setMessage(e.target.value)} /> <button type=\"submit\">Envoyer</button> </form> ); }","title":"Gestion des formulaires"},{"location":"front/react/#tests-unitaires-avec-react-testing-library","text":"Pour tester vos composants : npm install --save-dev @testing-library/react @testing-library/jest-dom Exemple de test : import { render, screen } from '@testing-library/react'; import { Button } from './Button'; test('affiche le label', () => { render(<Button label=\"OK\" onClick={() => {}} />); expect(screen.getByText('OK')).toBeInTheDocument(); });","title":"Tests unitaires avec React Testing Library"},{"location":"front/react/#bonnes-pratiques","text":"Structurez votre projet avec des dossiers /components , /pages , /hooks , /utils . Utilisez des hooks personnalis\u00e9s pour factoriser la logique r\u00e9utilisable. Pr\u00e9f\u00e9rez les fonctions pures et le typage strict. Documentez les props et les hooks avec des commentaires JSDoc. Utilisez des outils comme ESLint et Prettier pour la qualit\u00e9 du code.","title":"Bonnes pratiques"},{"location":"front/react/#ressources-utiles","text":"Documentation officielle React React TypeScript Cheatsheets React Router Testing Library","title":"Ressources utiles"},{"location":"front/svelte/","text":"Faire un front avec Svelte + SvelteKit Svelte est un framework JavaScript moderne qui compile les composants en code natif tr\u00e8s performant. SvelteKit est le m\u00e9ta-framework officiel pour cr\u00e9er des applications web compl\u00e8tes (SSR, SSG, SPA) avec Svelte. Cr\u00e9ation d\u2019un projet SvelteKit Installez le CLI si besoin : npm create svelte@latest mon-projet-svelte cd mon-projet-svelte npm install npm run dev Structure d\u2019un projet SvelteKit src/routes/ : pages et endpoints (chaque fichier .svelte devient une route) src/lib/ : composants r\u00e9utilisables src/app.html : template HTML principal static/ : fichiers statiques (images, favicon, etc) Exemple de composant Svelte <script lang=\"ts\"> export let name: string = \"World\"; </script> <h1>Hello {name}!</h1> Utilisation : <!-- src/routes/+page.svelte --> <script> import Hello from '$lib/Hello.svelte'; </script> <Hello name=\"Arthur\" /> Routing et navigation Chaque fichier .svelte dans src/routes/ correspond \u00e0 une route. Exemple : - src/routes/+page.svelte \u2192 / - src/routes/about/+page.svelte \u2192 /about Pour naviguer : <a href=\"/about\">\u00c0 propos</a> Stores (\u00e9tat global) Svelte propose des stores pour partager l\u2019\u00e9tat entre composants : // src/lib/store.ts import { writable } from 'svelte/store'; export const count = writable(0); Utilisation : <script lang=\"ts\"> import { count } from '$lib/store'; </script> <button on:click={() => $count++}>{$count}</button> Appels API et chargement de donn\u00e9es Utilisez les fonctions load de SvelteKit pour charger des donn\u00e9es c\u00f4t\u00e9 serveur ou client : // src/routes/posts/+page.ts export async function load() { const res = await fetch('https://jsonplaceholder.typicode.com/posts'); const posts = await res.json(); return { posts }; } Dans le composant : <script lang=\"ts\"> export let data; </script> {#each data.posts as post} <div>{post.title}</div> {/each} Formulaires et actions SvelteKit facilite la gestion des formulaires avec les actions : <form method=\"POST\"> <input name=\"email\" type=\"email\" /> <button type=\"submit\">Envoyer</button> </form> Dans +page.server.ts : export const actions = { default: async ({ request }) => { const data = await request.formData(); const email = data.get('email'); // Traitement... return { success: true }; } }; Bonnes pratiques Utilisez TypeScript pour le typage des props et des stores. Structurez votre projet avec /lib pour les composants et stores partag\u00e9s. Privil\u00e9giez les endpoints SvelteKit pour la logique serveur/API. Utilisez les hooks ( onMount , beforeUpdate , etc) pour g\u00e9rer le cycle de vie. Testez vos composants avec Playwright ou Vitest . Ressources utiles Documentation Svelte Documentation SvelteKit Templates SvelteKit","title":"Svelte"},{"location":"front/svelte/#faire-un-front-avec-svelte-sveltekit","text":"Svelte est un framework JavaScript moderne qui compile les composants en code natif tr\u00e8s performant. SvelteKit est le m\u00e9ta-framework officiel pour cr\u00e9er des applications web compl\u00e8tes (SSR, SSG, SPA) avec Svelte.","title":"Faire un front avec Svelte + SvelteKit"},{"location":"front/svelte/#creation-dun-projet-sveltekit","text":"Installez le CLI si besoin : npm create svelte@latest mon-projet-svelte cd mon-projet-svelte npm install npm run dev","title":"Cr\u00e9ation d\u2019un projet SvelteKit"},{"location":"front/svelte/#structure-dun-projet-sveltekit","text":"src/routes/ : pages et endpoints (chaque fichier .svelte devient une route) src/lib/ : composants r\u00e9utilisables src/app.html : template HTML principal static/ : fichiers statiques (images, favicon, etc)","title":"Structure d\u2019un projet SvelteKit"},{"location":"front/svelte/#exemple-de-composant-svelte","text":"<script lang=\"ts\"> export let name: string = \"World\"; </script> <h1>Hello {name}!</h1> Utilisation : <!-- src/routes/+page.svelte --> <script> import Hello from '$lib/Hello.svelte'; </script> <Hello name=\"Arthur\" />","title":"Exemple de composant Svelte"},{"location":"front/svelte/#routing-et-navigation","text":"Chaque fichier .svelte dans src/routes/ correspond \u00e0 une route. Exemple : - src/routes/+page.svelte \u2192 / - src/routes/about/+page.svelte \u2192 /about Pour naviguer : <a href=\"/about\">\u00c0 propos</a>","title":"Routing et navigation"},{"location":"front/svelte/#stores-etat-global","text":"Svelte propose des stores pour partager l\u2019\u00e9tat entre composants : // src/lib/store.ts import { writable } from 'svelte/store'; export const count = writable(0); Utilisation : <script lang=\"ts\"> import { count } from '$lib/store'; </script> <button on:click={() => $count++}>{$count}</button>","title":"Stores (\u00e9tat global)"},{"location":"front/svelte/#appels-api-et-chargement-de-donnees","text":"Utilisez les fonctions load de SvelteKit pour charger des donn\u00e9es c\u00f4t\u00e9 serveur ou client : // src/routes/posts/+page.ts export async function load() { const res = await fetch('https://jsonplaceholder.typicode.com/posts'); const posts = await res.json(); return { posts }; } Dans le composant : <script lang=\"ts\"> export let data; </script> {#each data.posts as post} <div>{post.title}</div> {/each}","title":"Appels API et chargement de donn\u00e9es"},{"location":"front/svelte/#formulaires-et-actions","text":"SvelteKit facilite la gestion des formulaires avec les actions : <form method=\"POST\"> <input name=\"email\" type=\"email\" /> <button type=\"submit\">Envoyer</button> </form> Dans +page.server.ts : export const actions = { default: async ({ request }) => { const data = await request.formData(); const email = data.get('email'); // Traitement... return { success: true }; } };","title":"Formulaires et actions"},{"location":"front/svelte/#bonnes-pratiques","text":"Utilisez TypeScript pour le typage des props et des stores. Structurez votre projet avec /lib pour les composants et stores partag\u00e9s. Privil\u00e9giez les endpoints SvelteKit pour la logique serveur/API. Utilisez les hooks ( onMount , beforeUpdate , etc) pour g\u00e9rer le cycle de vie. Testez vos composants avec Playwright ou Vitest .","title":"Bonnes pratiques"},{"location":"front/svelte/#ressources-utiles","text":"Documentation Svelte Documentation SvelteKit Templates SvelteKit","title":"Ressources utiles"},{"location":"techniques-de-travail/eisenhower-matrix/","text":"Matrice d'eisenhower Quand on est seul dans une \u00e9quipe pendant les vacances ou que c'est le chaos total d'un point de vue organisationnel. Il est important de ne pas se d\u00e9courager et cat\u00e9goriser les t\u00e2ches pour ne pas s'\u00e9parpiller. Sinon on arrive \u00e0 rien et on fait du multi-tasking sans jamais arriver \u00e0 la fin de chaque t\u00e2che. Ce tableau permet de visualiser rapidement quelles sont les t\u00e2ches qui m\u00e9ritent toute notre attention. Il est important de prendre le temps de bien cat\u00e9goriser les t\u00e2ches pour \u00e9viter les rat\u00e9s. Aussi, \u00eatre accompagn\u00e9 d'un PO ou du client permet d'\u00e9viter le biais dans la cat\u00e9gorisation et rester align\u00e9 avec les objectifs. Principe de la matrice La matrice d'Eisenhower est un outil de gestion du temps qui permet de classer les t\u00e2ches selon deux axes : Urgence : la t\u00e2che doit-elle \u00eatre trait\u00e9e rapidement ? Importance : la t\u00e2che a-t-elle un impact significatif sur les objectifs ? On obtient ainsi 4 cat\u00e9gories : Important Pas important Urgent 1. Faire maintenant 3. D\u00e9l\u00e9guer Pas urgent 2. Planifier 4. \u00c9liminer D\u00e9tail des quadrants Important & Urgent : \u00c0 traiter imm\u00e9diatement. Ex : bug bloquant en production, deadline imminente. Important & Pas urgent : \u00c0 planifier. Ex : refonte technique, veille technologique, formation. Pas important & Urgent : \u00c0 d\u00e9l\u00e9guer si possible. Ex : demandes administratives, interruptions diverses. Pas important & Pas urgent : \u00c0 \u00e9liminer ou minimiser. Ex : t\u00e2ches routini\u00e8res sans valeur ajout\u00e9e, distractions. Exemple d'application T\u00e2che Cat\u00e9gorie Corriger un bug critique sur le site Important & Urgent (1) Pr\u00e9parer une pr\u00e9sentation pour la semaine pro Important & Pas urgent (2) R\u00e9pondre \u00e0 un email administratif Pas important & Urgent (3) Lire les derni\u00e8res news tech Pas important & Pas urgent (4) Conseils pratiques Prenez le temps chaque matin de cat\u00e9goriser vos t\u00e2ches dans la matrice. N'h\u00e9sitez pas \u00e0 revoir la cat\u00e9gorisation avec un coll\u00e8gue ou votre manager. Concentrez-vous sur le quadrant 1, planifiez le quadrant 2, d\u00e9l\u00e9guez le 3, \u00e9liminez le 4. Utilisez des outils num\u00e9riques (Trello, Notion, etc.) pour visualiser votre matrice. Ressources compl\u00e9mentaires Article Wikip\u00e9dia sur la matrice d'Eisenhower Outils en ligne pour cr\u00e9er sa matrice","title":"Matrice d'Eisenhower"},{"location":"techniques-de-travail/eisenhower-matrix/#matrice-deisenhower","text":"Quand on est seul dans une \u00e9quipe pendant les vacances ou que c'est le chaos total d'un point de vue organisationnel. Il est important de ne pas se d\u00e9courager et cat\u00e9goriser les t\u00e2ches pour ne pas s'\u00e9parpiller. Sinon on arrive \u00e0 rien et on fait du multi-tasking sans jamais arriver \u00e0 la fin de chaque t\u00e2che. Ce tableau permet de visualiser rapidement quelles sont les t\u00e2ches qui m\u00e9ritent toute notre attention. Il est important de prendre le temps de bien cat\u00e9goriser les t\u00e2ches pour \u00e9viter les rat\u00e9s. Aussi, \u00eatre accompagn\u00e9 d'un PO ou du client permet d'\u00e9viter le biais dans la cat\u00e9gorisation et rester align\u00e9 avec les objectifs.","title":"Matrice d'eisenhower"},{"location":"techniques-de-travail/eisenhower-matrix/#principe-de-la-matrice","text":"La matrice d'Eisenhower est un outil de gestion du temps qui permet de classer les t\u00e2ches selon deux axes : Urgence : la t\u00e2che doit-elle \u00eatre trait\u00e9e rapidement ? Importance : la t\u00e2che a-t-elle un impact significatif sur les objectifs ? On obtient ainsi 4 cat\u00e9gories : Important Pas important Urgent 1. Faire maintenant 3. D\u00e9l\u00e9guer Pas urgent 2. Planifier 4. \u00c9liminer","title":"Principe de la matrice"},{"location":"techniques-de-travail/eisenhower-matrix/#detail-des-quadrants","text":"Important & Urgent : \u00c0 traiter imm\u00e9diatement. Ex : bug bloquant en production, deadline imminente. Important & Pas urgent : \u00c0 planifier. Ex : refonte technique, veille technologique, formation. Pas important & Urgent : \u00c0 d\u00e9l\u00e9guer si possible. Ex : demandes administratives, interruptions diverses. Pas important & Pas urgent : \u00c0 \u00e9liminer ou minimiser. Ex : t\u00e2ches routini\u00e8res sans valeur ajout\u00e9e, distractions.","title":"D\u00e9tail des quadrants"},{"location":"techniques-de-travail/eisenhower-matrix/#exemple-dapplication","text":"T\u00e2che Cat\u00e9gorie Corriger un bug critique sur le site Important & Urgent (1) Pr\u00e9parer une pr\u00e9sentation pour la semaine pro Important & Pas urgent (2) R\u00e9pondre \u00e0 un email administratif Pas important & Urgent (3) Lire les derni\u00e8res news tech Pas important & Pas urgent (4)","title":"Exemple d'application"},{"location":"techniques-de-travail/eisenhower-matrix/#conseils-pratiques","text":"Prenez le temps chaque matin de cat\u00e9goriser vos t\u00e2ches dans la matrice. N'h\u00e9sitez pas \u00e0 revoir la cat\u00e9gorisation avec un coll\u00e8gue ou votre manager. Concentrez-vous sur le quadrant 1, planifiez le quadrant 2, d\u00e9l\u00e9guez le 3, \u00e9liminez le 4. Utilisez des outils num\u00e9riques (Trello, Notion, etc.) pour visualiser votre matrice.","title":"Conseils pratiques"},{"location":"techniques-de-travail/eisenhower-matrix/#ressources-complementaires","text":"Article Wikip\u00e9dia sur la matrice d'Eisenhower Outils en ligne pour cr\u00e9er sa matrice","title":"Ressources compl\u00e9mentaires"},{"location":"techniques-de-travail/first-principles-thinking/","text":"First principles thinking, ou pens\u00e9e par les premiers principes La pens\u00e9e par premiers principes est une m\u00e9thode d\u2019analyse et de r\u00e9solution de probl\u00e8mes qui consiste \u00e0 d\u00e9construire un probl\u00e8me complexe en ses \u00e9l\u00e9ments fondamentaux, puis \u00e0 reconstruire une solution \u00e0 partir de ces bases. Cette approche, popularis\u00e9e par des innovateurs comme Elon Musk, permet de sortir des sch\u00e9mas de pens\u00e9e traditionnels et d\u2019inventer des solutions originales. \u00c9tapes de la d\u00e9marche Identifier et \u00e9noncer le probl\u00e8me D\u00e9composer le probl\u00e8me en faits ou principes fondamentaux Recomposer la solution \u00e0 partir de ces principes, sans se limiter aux solutions existantes Exemple concret (d\u00e9veloppement logiciel) Probl\u00e8me : \u00ab Le d\u00e9ploiement de notre application prend trop de temps. \u00bb Suppositions courantes : - Il faut utiliser l\u2019outil X car tout le monde l\u2019utilise. - Les builds doivent toujours passer par notre pipeline actuel. D\u00e9composition en premiers principes : - Objectif : livrer du code fiable rapidement. - Contraintes : s\u00e9curit\u00e9, reproductibilit\u00e9, co\u00fbt. - Ressources : outils d\u2019automatisation, conteneurisation, scripts personnalis\u00e9s. Recomposition : - Peut-on automatiser davantage ? - Peut-on parall\u00e9liser certaines \u00e9tapes ? - Peut-on changer d\u2019outil ou de m\u00e9thode (ex : passer de VM \u00e0 des conteneurs) ? R\u00e9sultat : On d\u00e9couvre qu\u2019en utilisant Docker et en optimisant le pipeline CI/CD, on peut r\u00e9duire le temps de d\u00e9ploiement de 50%. Autre exemple (hors tech) Probl\u00e8me : \u00ab Les batteries de voitures \u00e9lectriques co\u00fbtent trop cher. \u00bb Suppositions courantes : Les batteries sont ch\u00e8res car les fournisseurs le disent. Premiers principes : - De quoi est compos\u00e9e une batterie ? - Quels sont les co\u00fbts des mati\u00e8res premi\u00e8res ? - Peut-on fabriquer diff\u00e9remment ? R\u00e9sultat : Recherche de nouveaux mat\u00e9riaux, nouvelles m\u00e9thodes de fabrication. Conseils pour appliquer la pens\u00e9e par premiers principes Remettez en question les \u00e9vidences et les habitudes. Posez-vous la question \u00ab Pourquoi ? \u00bb plusieurs fois de suite (m\u00e9thode des 5 pourquoi). Utilisez des sch\u00e9mas, des listes ou des tableaux pour visualiser la d\u00e9composition. Collaborez avec des personnes d\u2019horizons diff\u00e9rents pour enrichir l\u2019analyse. Ressources compl\u00e9mentaires First Principles Thinking (Farnam Street) Elon Musk: The World\u2019s Raddest Man (Wait But Why)","title":"Premiers principes"},{"location":"techniques-de-travail/first-principles-thinking/#first-principles-thinking-ou-pensee-par-les-premiers-principes","text":"La pens\u00e9e par premiers principes est une m\u00e9thode d\u2019analyse et de r\u00e9solution de probl\u00e8mes qui consiste \u00e0 d\u00e9construire un probl\u00e8me complexe en ses \u00e9l\u00e9ments fondamentaux, puis \u00e0 reconstruire une solution \u00e0 partir de ces bases. Cette approche, popularis\u00e9e par des innovateurs comme Elon Musk, permet de sortir des sch\u00e9mas de pens\u00e9e traditionnels et d\u2019inventer des solutions originales.","title":"First principles thinking, ou pens\u00e9e par les premiers principes"},{"location":"techniques-de-travail/first-principles-thinking/#etapes-de-la-demarche","text":"Identifier et \u00e9noncer le probl\u00e8me D\u00e9composer le probl\u00e8me en faits ou principes fondamentaux Recomposer la solution \u00e0 partir de ces principes, sans se limiter aux solutions existantes","title":"\u00c9tapes de la d\u00e9marche"},{"location":"techniques-de-travail/first-principles-thinking/#exemple-concret-developpement-logiciel","text":"Probl\u00e8me : \u00ab Le d\u00e9ploiement de notre application prend trop de temps. \u00bb Suppositions courantes : - Il faut utiliser l\u2019outil X car tout le monde l\u2019utilise. - Les builds doivent toujours passer par notre pipeline actuel. D\u00e9composition en premiers principes : - Objectif : livrer du code fiable rapidement. - Contraintes : s\u00e9curit\u00e9, reproductibilit\u00e9, co\u00fbt. - Ressources : outils d\u2019automatisation, conteneurisation, scripts personnalis\u00e9s. Recomposition : - Peut-on automatiser davantage ? - Peut-on parall\u00e9liser certaines \u00e9tapes ? - Peut-on changer d\u2019outil ou de m\u00e9thode (ex : passer de VM \u00e0 des conteneurs) ? R\u00e9sultat : On d\u00e9couvre qu\u2019en utilisant Docker et en optimisant le pipeline CI/CD, on peut r\u00e9duire le temps de d\u00e9ploiement de 50%.","title":"Exemple concret (d\u00e9veloppement logiciel)"},{"location":"techniques-de-travail/first-principles-thinking/#autre-exemple-hors-tech","text":"Probl\u00e8me : \u00ab Les batteries de voitures \u00e9lectriques co\u00fbtent trop cher. \u00bb Suppositions courantes : Les batteries sont ch\u00e8res car les fournisseurs le disent. Premiers principes : - De quoi est compos\u00e9e une batterie ? - Quels sont les co\u00fbts des mati\u00e8res premi\u00e8res ? - Peut-on fabriquer diff\u00e9remment ? R\u00e9sultat : Recherche de nouveaux mat\u00e9riaux, nouvelles m\u00e9thodes de fabrication.","title":"Autre exemple (hors tech)"},{"location":"techniques-de-travail/first-principles-thinking/#conseils-pour-appliquer-la-pensee-par-premiers-principes","text":"Remettez en question les \u00e9vidences et les habitudes. Posez-vous la question \u00ab Pourquoi ? \u00bb plusieurs fois de suite (m\u00e9thode des 5 pourquoi). Utilisez des sch\u00e9mas, des listes ou des tableaux pour visualiser la d\u00e9composition. Collaborez avec des personnes d\u2019horizons diff\u00e9rents pour enrichir l\u2019analyse.","title":"Conseils pour appliquer la pens\u00e9e par premiers principes"},{"location":"techniques-de-travail/first-principles-thinking/#ressources-complementaires","text":"First Principles Thinking (Farnam Street) Elon Musk: The World\u2019s Raddest Man (Wait But Why)","title":"Ressources compl\u00e9mentaires"},{"location":"techniques-de-travail/twelve-factor-app/","text":"The Twelve Factors App Le manifeste 12-Factor App d\u00e9finit 12 principes pour concevoir des applications web modernes, portables, maintenables et scalables, principalement destin\u00e9es au cloud. Voici un r\u00e9sum\u00e9 de chaque facteur, leur valeur ajout\u00e9e et un exemple d\u2019application respectant ces principes. Les 12 facteurs d\u00e9taill\u00e9s Codebase : Principe : Une seule base de code versionn\u00e9e (git, svn\u2026), d\u00e9ploy\u00e9e sur plusieurs environnements (dev, staging, prod). Valeur : Garantit la coh\u00e9rence, la tra\u00e7abilit\u00e9 et la facilit\u00e9 de maintenance. \u00c9vite la d\u00e9rive de versions entre environnements. Dependencies : Principe : D\u00e9clarer explicitement toutes les d\u00e9pendances dans un fichier d\u00e9di\u00e9 (ex : package.json , requirements.txt ). Valeur : Permet de reproduire l\u2019environnement partout, \u00e9vite les bugs li\u00e9s \u00e0 des d\u00e9pendances implicites ou manquantes. Config : Principe : Stocker la configuration (URL, cl\u00e9s, secrets) dans des variables d\u2019environnement, jamais en dur dans le code. Valeur : S\u00e9pare le code de la configuration, facilite le d\u00e9ploiement sur diff\u00e9rents environnements sans modifier le code. Backing services : Principe : Consid\u00e9rer les services externes (BDD, cache, file storage, mail) comme des ressources attach\u00e9es, accessibles via une URL/config. Valeur : Permet de remplacer ou d\u00e9placer un service sans modifier le code, favorise la portabilit\u00e9 et la r\u00e9silience. Build, release, run : Principe : S\u00e9parer les \u00e9tapes de build (compilation), release (assemblage de la config) et run (ex\u00e9cution du code). Valeur : Facilite les rollbacks, la reproductibilit\u00e9 et la tra\u00e7abilit\u00e9 des d\u00e9ploiements. Processes : Principe : L\u2019application s\u2019ex\u00e9cute comme un ou plusieurs processus stateless, sans stockage local persistant (pas de session en m\u00e9moire, pas de fichiers locaux). Valeur : Permet le scaling horizontal, la tol\u00e9rance aux pannes et la simplicit\u00e9 d\u2019architecture. Port binding : Principe : L\u2019application exporte ses services via un port (ex : serveur HTTP int\u00e9gr\u00e9), sans d\u00e9pendre d\u2019un serveur web externe (Apache, Nginx). Valeur : Rend l\u2019application autonome, facilite le d\u00e9ploiement dans des environnements vari\u00e9s (cloud, conteneurs). Concurrency : Principe : G\u00e9rer la scalabilit\u00e9 en multipliant les processus (workers, threads, etc.), chaque processus \u00e9tant ind\u00e9pendant. Valeur : Permet d\u2019adapter dynamiquement la capacit\u00e9 de l\u2019application \u00e0 la charge, favorise la haute disponibilit\u00e9. Disposability : Principe : Les processus doivent d\u00e9marrer et s\u2019arr\u00eater rapidement, \u00eatre robustes face aux interruptions. Valeur : Facilite le scaling, les d\u00e9ploiements continus, la r\u00e9silience et la r\u00e9cup\u00e9ration apr\u00e8s incident. Dev/prod parity : Principe : Garder les environnements de d\u00e9veloppement, staging et production aussi similaires que possible (m\u00eames versions, m\u00eames services). Valeur : R\u00e9duit les bugs li\u00e9s aux diff\u00e9rences d\u2019environnement, acc\u00e9l\u00e8re la livraison et la r\u00e9solution d\u2019incidents. Logs : Principe : Consid\u00e9rer les logs comme un flux d\u2019\u00e9v\u00e9nements, \u00e0 rediriger vers un syst\u00e8me d\u2019agr\u00e9gation externe (ELK, Datadog, etc.). Valeur : Permet l\u2019analyse centralis\u00e9e, la surveillance et l\u2019alerte sans modifier l\u2019application. Admin processes : Principe : Exposer les t\u00e2ches d\u2019administration (migrations, scripts ponctuels) comme des commandes s\u00e9par\u00e9es du runtime principal. Valeur : Facilite la maintenance, la reproductibilit\u00e9 et la s\u00e9curit\u00e9 des op\u00e9rations d\u2019administration. Exemple d\u2019application 12-Factor (Node.js/Express) Structure du projet myapp/ \u251c\u2500\u2500 src/ \u2502 \u2514\u2500\u2500 index.js \u251c\u2500\u2500 package.json \u251c\u2500\u2500 .env \u2514\u2500\u2500 README.md D\u00e9pendances explicites package.json : { \"name\": \"myapp\", \"version\": \"1.0.0\", \"main\": \"src/index.js\", \"dependencies\": { \"express\": \"^4.18.2\", \"dotenv\": \"^16.0.0\" } } Configuration via variables d\u2019environnement .env : PORT=3000 MESSAGE=Hello 12-Factor! Code principal src/index.js : require('dotenv').config(); const express = require('express'); const app = express(); app.get('/', (req, res) => { res.send(process.env.MESSAGE); }); const port = process.env.PORT || 8080; app.listen(port, () => console.log(`App listening on port ${port}`)); Lancement npm install npm start Logs : Les logs sont envoy\u00e9s sur la sortie standard (stdout), \u00e0 rediriger vers un agr\u00e9gateur (ex : ELK, Datadog). Backing services : Ajoutez une base de donn\u00e9es via une URL en variable d\u2019environnement (ex : DATABASE_URL ). Admin process : Ajoutez un script de migration dans package.json (ex : npm run migrate ). Bonnes pratiques Utilisez des outils comme Docker pour garantir la parit\u00e9 dev/prod. Stockez la configuration sensible hors du code source. Privil\u00e9giez les services manag\u00e9s et interchangeables. Ressources utiles 12factor.net (FR) Exemple Node.js 12-Factor","title":"The Twelve-Factor App"},{"location":"techniques-de-travail/twelve-factor-app/#the-twelve-factors-app","text":"Le manifeste 12-Factor App d\u00e9finit 12 principes pour concevoir des applications web modernes, portables, maintenables et scalables, principalement destin\u00e9es au cloud. Voici un r\u00e9sum\u00e9 de chaque facteur, leur valeur ajout\u00e9e et un exemple d\u2019application respectant ces principes.","title":"The Twelve Factors App"},{"location":"techniques-de-travail/twelve-factor-app/#les-12-facteurs-detailles","text":"Codebase : Principe : Une seule base de code versionn\u00e9e (git, svn\u2026), d\u00e9ploy\u00e9e sur plusieurs environnements (dev, staging, prod). Valeur : Garantit la coh\u00e9rence, la tra\u00e7abilit\u00e9 et la facilit\u00e9 de maintenance. \u00c9vite la d\u00e9rive de versions entre environnements. Dependencies : Principe : D\u00e9clarer explicitement toutes les d\u00e9pendances dans un fichier d\u00e9di\u00e9 (ex : package.json , requirements.txt ). Valeur : Permet de reproduire l\u2019environnement partout, \u00e9vite les bugs li\u00e9s \u00e0 des d\u00e9pendances implicites ou manquantes. Config : Principe : Stocker la configuration (URL, cl\u00e9s, secrets) dans des variables d\u2019environnement, jamais en dur dans le code. Valeur : S\u00e9pare le code de la configuration, facilite le d\u00e9ploiement sur diff\u00e9rents environnements sans modifier le code. Backing services : Principe : Consid\u00e9rer les services externes (BDD, cache, file storage, mail) comme des ressources attach\u00e9es, accessibles via une URL/config. Valeur : Permet de remplacer ou d\u00e9placer un service sans modifier le code, favorise la portabilit\u00e9 et la r\u00e9silience. Build, release, run : Principe : S\u00e9parer les \u00e9tapes de build (compilation), release (assemblage de la config) et run (ex\u00e9cution du code). Valeur : Facilite les rollbacks, la reproductibilit\u00e9 et la tra\u00e7abilit\u00e9 des d\u00e9ploiements. Processes : Principe : L\u2019application s\u2019ex\u00e9cute comme un ou plusieurs processus stateless, sans stockage local persistant (pas de session en m\u00e9moire, pas de fichiers locaux). Valeur : Permet le scaling horizontal, la tol\u00e9rance aux pannes et la simplicit\u00e9 d\u2019architecture. Port binding : Principe : L\u2019application exporte ses services via un port (ex : serveur HTTP int\u00e9gr\u00e9), sans d\u00e9pendre d\u2019un serveur web externe (Apache, Nginx). Valeur : Rend l\u2019application autonome, facilite le d\u00e9ploiement dans des environnements vari\u00e9s (cloud, conteneurs). Concurrency : Principe : G\u00e9rer la scalabilit\u00e9 en multipliant les processus (workers, threads, etc.), chaque processus \u00e9tant ind\u00e9pendant. Valeur : Permet d\u2019adapter dynamiquement la capacit\u00e9 de l\u2019application \u00e0 la charge, favorise la haute disponibilit\u00e9. Disposability : Principe : Les processus doivent d\u00e9marrer et s\u2019arr\u00eater rapidement, \u00eatre robustes face aux interruptions. Valeur : Facilite le scaling, les d\u00e9ploiements continus, la r\u00e9silience et la r\u00e9cup\u00e9ration apr\u00e8s incident. Dev/prod parity : Principe : Garder les environnements de d\u00e9veloppement, staging et production aussi similaires que possible (m\u00eames versions, m\u00eames services). Valeur : R\u00e9duit les bugs li\u00e9s aux diff\u00e9rences d\u2019environnement, acc\u00e9l\u00e8re la livraison et la r\u00e9solution d\u2019incidents. Logs : Principe : Consid\u00e9rer les logs comme un flux d\u2019\u00e9v\u00e9nements, \u00e0 rediriger vers un syst\u00e8me d\u2019agr\u00e9gation externe (ELK, Datadog, etc.). Valeur : Permet l\u2019analyse centralis\u00e9e, la surveillance et l\u2019alerte sans modifier l\u2019application. Admin processes : Principe : Exposer les t\u00e2ches d\u2019administration (migrations, scripts ponctuels) comme des commandes s\u00e9par\u00e9es du runtime principal. Valeur : Facilite la maintenance, la reproductibilit\u00e9 et la s\u00e9curit\u00e9 des op\u00e9rations d\u2019administration.","title":"Les 12 facteurs d\u00e9taill\u00e9s"},{"location":"techniques-de-travail/twelve-factor-app/#exemple-dapplication-12-factor-nodejsexpress","text":"","title":"Exemple d\u2019application 12-Factor (Node.js/Express)"},{"location":"techniques-de-travail/twelve-factor-app/#structure-du-projet","text":"myapp/ \u251c\u2500\u2500 src/ \u2502 \u2514\u2500\u2500 index.js \u251c\u2500\u2500 package.json \u251c\u2500\u2500 .env \u2514\u2500\u2500 README.md","title":"Structure du projet"},{"location":"techniques-de-travail/twelve-factor-app/#dependances-explicites","text":"package.json : { \"name\": \"myapp\", \"version\": \"1.0.0\", \"main\": \"src/index.js\", \"dependencies\": { \"express\": \"^4.18.2\", \"dotenv\": \"^16.0.0\" } }","title":"D\u00e9pendances explicites"},{"location":"techniques-de-travail/twelve-factor-app/#configuration-via-variables-denvironnement","text":".env : PORT=3000 MESSAGE=Hello 12-Factor!","title":"Configuration via variables d\u2019environnement"},{"location":"techniques-de-travail/twelve-factor-app/#code-principal","text":"src/index.js : require('dotenv').config(); const express = require('express'); const app = express(); app.get('/', (req, res) => { res.send(process.env.MESSAGE); }); const port = process.env.PORT || 8080; app.listen(port, () => console.log(`App listening on port ${port}`));","title":"Code principal"},{"location":"techniques-de-travail/twelve-factor-app/#lancement","text":"npm install npm start Logs : Les logs sont envoy\u00e9s sur la sortie standard (stdout), \u00e0 rediriger vers un agr\u00e9gateur (ex : ELK, Datadog). Backing services : Ajoutez une base de donn\u00e9es via une URL en variable d\u2019environnement (ex : DATABASE_URL ). Admin process : Ajoutez un script de migration dans package.json (ex : npm run migrate ).","title":"Lancement"},{"location":"techniques-de-travail/twelve-factor-app/#bonnes-pratiques","text":"Utilisez des outils comme Docker pour garantir la parit\u00e9 dev/prod. Stockez la configuration sensible hors du code source. Privil\u00e9giez les services manag\u00e9s et interchangeables.","title":"Bonnes pratiques"},{"location":"techniques-de-travail/twelve-factor-app/#ressources-utiles","text":"12factor.net (FR) Exemple Node.js 12-Factor","title":"Ressources utiles"}]}